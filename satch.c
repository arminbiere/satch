/*------------------------------------------------------------------------*/
//   Copyright (c) 2021, Armin Biere, Johannes Kepler University Linz     //
/*------------------------------------------------------------------------*/

// This is the library code for the SAT solver Satch with API in 'satch.h'.
//
// The full code of the library is contained in this file except for the
// header files 'satch.h', 'stack.h' and 'features.h', and the three
// functions 'satch_compile', 'satch_identifier', and 'satch_version}, which
// provide build information and are implemented in 'config.c', which in
// turn is automatically generated by 'mkconfig.sh'.  If you do not need
// those, nor the internal proof checking code in 'catch.[ch]', then you can
// either compile or just link against this file 'satch.c'.
//
// In order to disable proof checking and debugging (and avoid a link-time
// dependency on 'catch.o') compile with 'NDEBUG' defined.  Not defining
// 'NDEBUG' enables of course also assertion checking in general, also
// witness checking and includes logging code.  The latter still needs to be
// enabled at run-time through 'satch_enable_logging_messages' though.
//
// So again, if you do not want to use our build set-up, i.e., neither
// './configure' nor 'mkconfig.sh' but just want to link against this
// file instead of linking against the library and do not need proof
// checking in 'catch.c' (because you are not working on the 'satch' library
// itself) then just define 'NDEBUG' by for instance using '-DNDEBUG' as
// compiler option to compile this file and then link to it.
//
// We do not support assertion checking without internal proof checking (and
// witness checking).  These additional checks increase memory usage by a
// factor of two to four and solving times by up to a factor of five (due to
// simpler and thus slower checker data structures) but are worth to keep
// enabled in testing the library anyhow.  We are not aware of a scenario
// where production use of the solver would require to change this.

/*------------------------------------------------------------------------*/

#include "satch.h"		// API of the solver.

/*------------------------------------------------------------------------*/

#include <assert.h>
#include <math.h>
#include <inttypes.h>
#include <limits.h>
#include <stdarg.h>
#include <stdbool.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

/*------------------------------------------------------------------------*/

// System specific include files for 'getrusage', 'stat', and 'access'.

#include <sys/resource.h>
#include <sys/time.h>
#include <sys/types.h>
#include <unistd.h>

/*------------------------------------------------------------------------*/

// Rather complex and painful to implement checking of the compatibility of
// disabled features as well as disabling certain features based on other
// disabled features (e.g., if bumping is disabled with 'NBUMP' then VSIDS
// scores are disabled with 'NVSIDS' too).  Including this file also
// provides a consistent feature setting (of 'N...' macros).  If you want
// see which of these macros are actually defined use './configure -d'
// which in turn defines '-DIAGNOSE' and forces printing those definitions.

#include "features.h"

/*------------------------------------------------------------------------*/

// Hard coded options for simplicity.

#define slow_alpha              1e-5	// Exponential moving average decay.

#ifndef NSWITCH
#define initial_mode_conflicts_interval 1e3
#endif

#ifndef NSTABLE
#define stable_restart_interval 1024	// Basic stable restart interval.
#endif

#ifndef NMINIMIZE
#define minimize_depth          1e4	// Recursive minimization depth.
#endif

#ifndef NREDUCE
#define reduce_fraction         0.75	// Fraction of reduced clauses.
#ifndef NTIER1
#define tier1_glue_limit        2	// Kept clause glue limit (tier 1).
#ifndef NTIER2
#define tier2_glue_limit        6	// Delayed reduction glue (tier 2).
#endif
#endif
#define reduce_interval         300	// Reduce conflicts interval.
#endif

#ifndef NREPHASE
#define rephase_interval	1e3	// Rephase conflict interval.
#endif

#ifndef NRESTART
#define fast_alpha              3e-2	// Exponential moving average decay.
#define restart_interval        1	// Basic (focused) restart interval.
#define restart_margin          1.1	// Margin for fast_glue > slow_glue.
#endif

#ifndef NREASONS
#define bump_reason_decision_rate_limit		10
#endif

// Increase factors (inverse of decay) for exponential VSIDS.

#ifndef NVSIDS
#ifndef NFOCUSED
#define focused_score_increment_factor	1.15
#endif
#ifndef NSTABLE
#define stable_score_increment_factor	1.05
#endif
#endif

/*------------------------------------------------------------------------*/

// Local include files beside 'satch.h' and 'features.h'.

// As explained at the top of this file, there is a dependency on 'catch.h'
// at compile-time and thus 'catch.o' at link-time but only if 'NDEBUG' is
// undefined and thus assertion, proof and witness checking are enabled.
// Thus for production use you really want to define 'NDEBUG'.

#ifndef NDEBUG
#include "catch.h"		// Online proof checker for testing.
#endif

#include "stack.h"		// Generic stack implementation.

/*------------------------------------------------------------------------*/

// The basic clause data structure.  Note however that binary clauses are
// kept in watch lists by default if blocking literals are used (or
// equivalently 'NBLOCK' is kept undefined).

struct clause
{
  uint64_t id;			// From 'solver->statistics.added'
  // needed for stable sorting and logging.

  bool garbage:1;		// Collect clause at garbage collection.
  bool protected:1;		// Do not collect reason clauses.
  bool redundant:1;		// Redundant / learned (not irredundant).
#ifndef NUSED
#ifndef NTIER2
  unsigned used:2;		// Used since last clause reduction.
#else
  unsigned used:1;		// Used since last clause reduction.
#endif
#endif
#ifndef NGLUE
  unsigned glue;		// Glucose level (LBD).
#endif
#ifndef NCACHE
  unsigned search;		// Cached replacement search position.
#endif
  unsigned size;		// Size of clause (number of literals).

#ifndef NVARIADIC

  // This default version embeds the literals directly into the clause.
  // Then the literals follow the clause header directly in memory.  This
  // makes the actual memory block of a clause variadic.

  unsigned literals[2];
#else

  // This non-variadic version stores the literals separately which requires
  // another rather expensive pointer dereference accessing the literals. 

  unsigned *literals;
#endif
};

/*------------------------------------------------------------------------*/

// Stack of clause pointers.

struct clauses
{
  struct clause **begin, **end, **allocated;
};

/*------------------------------------------------------------------------*/

// Watches are made of a watch header and a clause unless blocking literals
// are disabled ('NBLOCK' defined).  If blocking literals are enabled
// ('NBLOCK' undefined) the blocking literal and thus the header is
// enough to watch a binary clause and the clause pointer can be omitted.
//
// Actually binary clauses can become 'virtual' and do have to be stored at
// all outside of the watch lists  Thus in the default compact compilation
// mode ('NVIRTUAL' undefined) we split watches into the two parts 'binary'
// and 'clause' and then use a 'union' type for 'watch' in order to be able
// to mix short watches for binary clauses (without clause pointer) with
// long watches for larger clauses on the same watcher stack.  This union
// type allows to push them independently, even though we always need to
// push a header, but can optionally omit the clause.  Code to traverse
// watcher stacks becomes slightly more complicated though.
//
// In order to avoid switching between 'union' and 'struct' with and without
// virtual binary clauses (w/o 'NVIRTUAL' undefined) we simply use this
// 'union' type in any case. The actual memory operations performed do not
// change anyhow.  As drawback one can consider that without blocking
// literals, i.e., 'NBLOCK' defined and thus also 'NVIRTUAL', watches are
// declared as unions with a single member 'clause', which clutters code
// slightly (requires to use 'watch.clause').

#ifndef NBLOCK

struct header
{
  bool binary;			// Binary clause.
#ifndef NVIRTUAL
  bool redundant;		// Relevant for statistics.
#endif
  unsigned blocking;		// Blocking literal of the clause.
};

#define long_clause_watch_size 2	// Two watches per long clause.

#else

#define long_clause_watch_size 1	// One without blocking literals.

#endif

// The actual watch data structure.

union watch
{
#ifndef NBLOCK
  struct header header;
#endif
  struct clause *clause;
};

// Stack of watches.

struct watches
{
  union watch *begin, *end, *allocated;
};

/*------------------------------------------------------------------------*/

// Conflict and other limits for restarts, reductions etc.

// We use the idiom to define an internal macro option 'NLIMITS' in case the
// 'limits' struct becomes empty.  Then it does not need to be declared in
// the solver.  There we can then only test 'NLIMITS'.  An empty 'struct'
// would trigger an error during pedantic compilation ('./configure -p').

#ifdef NREDUCE
#ifdef NREPHASE
#ifdef NRESTART
#ifdef NSWITCH
#define NLIMITS
#endif
#endif
#endif
#endif

#ifndef NLIMITS

struct limits
{
#ifndef NSWITCH
  struct
  {
    uint64_t conflicts;		// Conflict limit if non zero.
    struct
    {
      uint64_t limit;		// Ticks limit on mode switching.
      uint64_t interval;	// Ticks mode base interval (computed).
    } ticks;
  } mode;
#endif
#ifndef NREDUCE
  struct
  {
    uint64_t conflicts;		// Conflict limit on reducing.
    unsigned fixed;		// Root level fixed at reduction.
  } reduce;
#endif
#ifndef NREPHASE
  uint64_t rephase;		// Conflict limit on rephasing.
#endif
#ifndef NRESTART
  uint64_t restart;		// Conflict limit on restarting.
#endif
};

#endif

/*------------------------------------------------------------------------*/

// These are counters used for 'reluctant doubling' which is the way how
// Donald Knuth implements the computation of the 'Luby' sequence to control
// restart intervals. We only control restarts through reluctant doubling in
// stable mode though.

#if defined(NRESTART) || defined(NSTABLE)
#define NRELUCTANT
#endif

#ifndef NRELUCTANT

struct reluctant
{
  uint64_t u, v;
};

#endif

/*------------------------------------------------------------------------*/

// Relying on compile-time configuration, we have very few run-time options.

struct options			// Runtime options.
{
  bool ascii;			// Use ASCII proof format.
#ifndef NDEBUG
  bool logging;			// Print logging messages.
#endif
  unsigned verbose;		// Verbose level for messages 0..4.
};

/*------------------------------------------------------------------------*/

// Runtime statistics.

struct statistics
{
  uint64_t conflicts;		// Total number of conflicts.
  uint64_t decisions;		// Total number of decisions.
  uint64_t propagations;	// Propagated literals.
#ifndef NREDUCE
  uint64_t reductions;		// Number of reductions.
#endif
#ifndef NREPHASE
  uint64_t rephased;		// Number of resetting saved phases.
#endif
#ifndef NVSIDS
  uint64_t rescored;		// Rescored EVSIDS scores.
#endif
#ifndef NVMTF
  uint64_t restamped;		// Restamped VMTF timestamps.
#endif
#ifndef NRESTART
  uint64_t restarts;		// Number of restarts.
#endif
#ifndef NSWITCH
  uint64_t switched;		// Number of mode switches.
#endif
#ifndef NTARGET
  uint64_t targets;		// Number of saved target trails.
#endif
#ifndef NBEST
  uint64_t bests;		// Number of saved best trails.
#endif
  uint64_t ticks;		// Propagation ticks.

  uint64_t added;		// Number of added clauses.
  uint64_t deleted;		// Number of deleted clauses.
  uint64_t irredundant;		// Current number of irredundant clauses.
  uint64_t redundant;		// Current number of redundant clauses.

#ifndef NBUMP
  uint64_t bumped;		// Bumped literals.
#endif
#ifndef NVSIDS
  uint64_t incremented;		// Bumped by incrementing score.
#endif
#ifndef NVMTF
  uint64_t moved;		// Bumped by moving to front.
#endif
#ifndef NREASONS
  uint64_t reasons;		// Additionally bumped reason side literals.
#endif

  uint64_t deduced;		// Deduced literals.
  uint64_t learned;		// Learned literals.
#ifndef NMINIMIZE
  uint64_t minimized;		// Minimized literals.
#endif

  uint64_t sections;		// Number of calls to 'section'.
  uint64_t reported;		// Number of calls to 'report'.

#ifndef NACTIVE
  uint64_t activated[2];	// Activated variables.
#else
  uint64_t filled[2];		// Filled variables.
#endif
  unsigned active;		// Remaining variables.
  unsigned fixed;		// Root level assigned variables (units).
};

/*------------------------------------------------------------------------*/

#ifndef NQUEUE

// Links for doubly linked variable decision queue.

struct link
{
  unsigned prev;
  unsigned next;
  unsigned stamp;		// Enqueue time stamp.
};

/*------------------------------------------------------------------------*/

// Variable move-to-front doubly-linked decision queue.

struct queue
{
  struct link *links;		// Variable links in decision queue.
  unsigned size;		// Size of queue (when last used).
  unsigned first;		// First (enqueued) variable index.
  unsigned last;		// Last (enqueued) variable index.
  unsigned search;		// Cache search in 'decide'.
  unsigned stamp;		// Enqueue time stamp.
};

#endif

/*------------------------------------------------------------------------*/

#ifndef NHEAP

// Priority queue which (E)VSIDS scores implemented as binary heap.

struct heap
{
  unsigned *begin, *end;	// Pre-allocated stack of variables.
  unsigned *pos;		// Pre-allocated variable to position map.
  double *score;		// The actual score of the variable.
  unsigned size;		// Size of heap (when last used).
  double increment;		// Exponentially increasing score increment.
  double factor;		// Increased by this factor.
};

#endif

/*------------------------------------------------------------------------*/

// Analyzed / seen variables (enables sorting with respect to stamps).

struct analyzed
{
  unsigned idx;
#ifndef NSORT
  unsigned stamp;		// Needed for sorting bumped variables only.
#endif
};

/*------------------------------------------------------------------------*/

struct analyzed_stack		// Stack of analyzed indices with stamps.
{
  struct analyzed *begin, *end, *allocated;
};

/*------------------------------------------------------------------------*/

// Pre-allocated stack of literals with 'propagate' for breath-first search
// over assigned literals on the trail during propagation.

struct trail
{
  unsigned *begin, *end;	// As in 'stack' (can use stack macros).
  unsigned *propagate;		// Position of next literal to propagate.
};

/*------------------------------------------------------------------------*/

// Exponential moving averages (for 'exp' see below).

struct averages
{
  double conflict_level;	// Slow moving average of conflict level.
  double slow_glue;		// Slow moving average of glue.
  double slow_exp;		// Cached 'slow_beta^n'.
  double trail_filled;		// Slow moving relative trail size average.
  double decision_rate;		// Slow decisions per conflict rate.
  uint64_t saved_decisions;
#ifndef NRESTART
  double fast_glue;		// Fast moving average of glue.
  double fast_exp;		// Cached 'fast_beta^n'.
#endif
};

/*------------------------------------------------------------------------*/

// We use this idiom of defining at compile-time a list of code parameters
// multiple times (here 'PROFILES', but also see 'REPORTS' below and
// 'SIGNALS' in 'main.c').  The idea is that the parameter list contains the
// variations of some common code, that is compile-time parameters of that
// code.  Here for example the common code will be in the 'PROFILE' macro
// (singular) which then is instantiated with its single parameter (we use
// 'NAME') if just write 'PROFILES' (plural).  The point is that we can use
// that parameter in 'PROFILE' at compile both as symbol as well as string
// (with '#NAME'), or even generate new symbols (see 'SIGNALS' in 'main.c').

// *INDENT-OFF*

#define PROFILES \
PROFILE_IF_FOCUSED (focused)    /* Time spent in focused mode. */ \
PROFILE (parse)                 /* Time spent parsing.         */ \
PROFILE_IF_REDUCE (reduce)      /* Time spent reduce.          */ \
PROFILE (solve)                 /* Time spent solving.         */ \
PROFILE_IF_STABLE (stable)      /* Time spent in stable mode.  */ \
PROFILE (total)			/* Total time spent.           */

#define DO_NOT_PROFILE(ARG) /**/
#ifndef NFOCUSED
#define PROFILE_IF_FOCUSED PROFILE
#else
#define PROFILE_IF_FOCUSED DO_NOT_PROFILE
#endif
#ifndef NREDUCE
#define PROFILE_IF_REDUCE PROFILE
#else
#define PROFILE_IF_REDUCE DO_NOT_PROFILE
#endif
#ifndef NSTABLE
#define PROFILE_IF_STABLE PROFILE
#else
#define PROFILE_IF_STABLE DO_NOT_PROFILE
#endif

// *INDENT-ON*

struct profile
{
  double start, time;		// Start time, and total time.
  const char *name;		// Used in 'print_profiles'.
};				// Initialized in 'init_profiles'.

#define MAX_PROFILES            16

struct profiles
{
#define PROFILE(NAME) \
  struct profile NAME;		// Declare all the profiles.
  PROFILES
#undef PROFILE
  struct profile *begin[MAX_PROFILES];
  struct profile **end;
};

/*------------------------------------------------------------------------*/

// The full solver state is captured in this structure.

struct satch
{
  int status;			// UNKNOWN, SATISFIABLE, UNSATISFIABLE.
  bool inconsistent;		// Empty clause found or derived.
  bool iterate;			// Report unit learned.
  bool stable;			// Stable mode (fewer restarts).
  unsigned level;		// Current decision level.
  unsigned size;		// Number of variables.
  size_t capacity;		// Allocated variables.
  unsigned unassigned;		// Number of unassigned variables.
  unsigned *levels;		// Decision levels of variables.
  signed char *values;		// Current assignment of literals.
#ifndef NSAVE
  signed char *saved;		// Saved assignments of variables.
#endif
#ifndef NTARGET
  signed char *targets;		// Target phases.
  unsigned target;		// Maximum trail size.
#endif
#ifndef NBEST
  signed char *bests;		// Best phases.
  unsigned best;		// Best trail size.
#endif
  signed char *marks;		// Mark flags of variables.
#ifndef NACTIVE
  bool *active;			// Active flags of variables.
  struct unsigned_stack put[2];	// To be put on decision queue / heap.
#endif
#ifndef NMINIMIZE
  struct unsigned_stack marked;	// Marked variables.
#endif
  signed char *frames;		// Analyzed flag for each level.
#ifndef NQUEUE
  struct queue queue[2];	// Variable decision queue (stable=1).
#endif
#ifndef NHEAP
  struct heap scores[2];	// Variable decision heap (stable=1).
#endif
  struct clause **reasons;	// Reason clauses of a variable.
#ifndef NBLOCK
  struct clause binary;		// Temporary binary conflict.
#endif
  struct watches *watches;	// Watches of a literal.
  struct trail trail;		// Assigned literals.
  struct analyzed_stack seen;	// Analyzed literals.
  struct unsigned_stack clause;	// Temporary clause.
  struct unsigned_stack blocks;	// Analyzed decision levels.
  struct clauses irredundant;	// Current irredundant clauses.
#ifndef NLEARN
  struct clauses redundant;	// Current redundant clauses.
#endif
#ifndef NLIMITS
  struct limits limits;		// Limits on restart.
#endif
#ifndef NRELUCTANT
  struct reluctant reluctant;	// Doubling for stable restart (Luby).
#endif
  struct options options;	// Few runtime options.
  struct averages averages[2];	// Exponential moving averages (stable=1).
  struct statistics statistics;	// Statistic counters.
  struct profiles profiles;	// Built in run-time profiling.
#ifndef NDEBUG
  struct int_stack original;	// Copy of all original clauses.
  struct checker *checker;	// Internal proof checker.
#endif
  struct int_stack added;	// Added external clause.
  FILE *proof;			// Trace to this file if non-zero.
};

// The main point of this extensive configurability is to be able to strip
// down (disable) parts of the solver state if a feature which does not need
// it is disabled. For instance if reluctant doubling is not needed
// ('--no-stable' or '--no-restart'), then we do not want to initialize it
// during mode switching.   If we do not even have a 'reluctant' member in
// this case, the compiler will catch accidental usage.

// This way we can reduce the code really needed for a feature and as
// described removes accidental run-time overhead related to code for a
// disabled feature.

// This approach is almost straight-forward except for the various variants
// of using VSIDS or VMTF in focused and stable mode (or if one of the
// latter is disabled), which requires two averages in the default
// configuration and maybe two queues or two heaps (or a queue in stable
// mode for '--no-focused --no-vsids').  Therefore we do have some fields
// duplicated (the arrays '..[2]' above) but we make sure that we really
// only use one if the configuration only needs one instance.

/*------------------------------------------------------------------------*/

// We use 'unsigned (int)' as type for internal literals and variable
// indices.  Our internal variable indices start at zero and literals are
// variable indices multiplied by two. The lowest bit of a literal denotes
// its sign.  The following function maps variable indices to literals.

static unsigned
LITERAL (unsigned idx)
{
  assert (idx < (1u << 31));	// Check for overflow.
  return idx << 1;
}

// Vice-versa this function maps literals to their variable index.

static unsigned
INDEX (unsigned lit)
{
  return lit >> 1;
}

// The least significant bit of a literal is its sign.

static unsigned
SIGN_BIT (unsigned lit)
{
  return lit & 1;
}

// Values of type 'signed char' are ternary and this function translate an
// (unsigned) literal bit into a (binary) 'true' or 'false' ('1' or '-1').

static int
INT_SIGN (unsigned lit)
{
  return SIGN_BIT (lit) ? -1 : 1;
}

// Negating a literal amounts to flipping its least significant bit.

static unsigned
NOT (unsigned lit)
{
  return lit ^ 1;
}

// Note that the API uses signed integers for literals.  These signed
// external DIMACS variable indices are in the range '1..INT_MAX' and are
// mapped to internal variable indices '0..(INT_MAX-1)'.  Regarding literals
// the mapping between internal and external literals is as follows.
//
// +----------------------------------------+----------------------------+
// | External signed DIMACS literals        | Internal unsigned literals |
// +----------------------------------------+----------------------------+
// |     1                                  |    0                       |
// |    -1                                  |    1                       |
// |     2                                  |    2                       |
// |    -2                                  |    3                       |
// |    ...                                 |   ...                      |
// |  INT_MAX =   (1u<<31)-1  =  2147483647 | (1u<<32)-4 = 4294967292    |
// | -INT_MAX = -((1u<<31)-1) = -2147483647 | (1u<<32)-3 = 4294967293    |
// +----------------------------------------+----------------------------+
//
// We use the following two invalid values as sentinel to terminate a
// clause externally or as invalid literal or invalid variable internally.
//
// +----------------------------------------+----------------------------+
// |     0                                  | INVALID    = (1u<<32)-1    |
// |                                        |            = 4294967295    |
// |                                        |            = UINT_MAX      |
// +----------------------------------------+----------------------------+
//
// There is one unused value in each case.
//
// +----------------------------------------+----------------------------+
// | INT_MIN = -(1u<<31)      = -2147483648 | (1u<<32)-2 = 4294967294    |
// +----------------------------------------+----------------------------+
//
// Here we assume that 'sizeof (unsigned) == sizeof (int)', signed integers
// are encoded in two-complement and thus 'INT_MAX == (1u<<31)-1'.
//
// It would be possible to also use 'int' for literals internally, but then
// iterator code would become much more complicated.  Access to positively
// and negatively indexed arrays, i.e., watches and values, would be strange
// and requires complex reallocation code too (for incremental usage).
//
// Thus we allow up to 'INT_MAX' variables and use the all-bits-one number
// 'INVALID' to denote invalid literals and variable indices '(1u<<32)-1'.
//
// By default (as long 'NBLOCK' is not defined) we use 'bit-stuffing' to
// distinguish binary clause reasons (the other literal) from real large
// clause reasons (pointer to the clause).  This technique requires that
// we use the least significant bit of a pointer as flag to distinguish this
// case and accordingly reduces the number of variables on a 32-bit system
// to '2^30' (which will not be reachable on such a system anyhow) but on
// 64-bit systems does not impose any restriction.

#define INVALID UINT_MAX

/*------------------------------------------------------------------------*/

// Increase and decrease statistic counters with over/under-flow checking.

// For those readers not familiar with this style of C macros, note that
// that this 'do { ... } while (0)' idiom makes sure that the macro almost
// acts like a procedure (function without any return value), allows local
// variables (not here but see the macros in 'stack.h'), and still can be
// used with a semicolon after it in an 'if-then-else' statement such as
//
//   if (c->redundant) DEC (redundant); else DEC (irredundant);
//
// which would become a syntax error if we only use a block of curly
// parenthesis.  We can also 'return' early with a 'break' statement
// (instead of 'return').  An alternative consists of statement expressions,
// which however are a GCC extension and (pedantic) compilation fails for
// '-W -Wall -Werror -pedantic' on these extensions (as with 'typeof').

#define DEC(NAME) \
do { \
  assert (solver->statistics.NAME > 0); \
  solver->statistics.NAME--; \
} while (0)

// For this macro we want to produce a 'return' value which requires a more
// sophisticated use of the 'comma' operator. Again 'statement expressions'
// would be an alternative but we do not want to use those.  This technique
// breaks down if you need more sophisticated control flow, i.e., loops.
// See 'COVER' for another use of 'comma' as well as how we define the
// anticipated loop condition in the 'all_...' iterator macros below.

#define INC(NAME) \
  ( \
    assert (solver->statistics.NAME < UINT64_MAX), \
    ++solver->statistics.NAME \
  )

#define ADD(NAME,DELTA) \
do { \
  assert (UINT64_MAX - (DELTA) >= solver->statistics.NAME); \
  solver->statistics.NAME += (DELTA); \
} while (0)

/*------------------------------------------------------------------------*/

// The number of variables and literals.

#define VARIABLES (solver->size)
#define LITERALS (2u*VARIABLES)

// We also often need the number of conflicts, decisions and ticks.

#define CONFLICTS (solver->statistics.conflicts)
#define DECISIONS (solver->statistics.decisions)
#define TICKS (solver->statistics.ticks)

/*------------------------------------------------------------------------*/

// Iterators for global solver data.  They can be used in a similar way as
// range-based for-loops in C++-11.  For instance the idiom
//
//   for (all_variables (idx))
//     ...
//
// goes over all variable indices 'idx'.

// The features of C'99 we use here are local declarations in for-loops and
// the comma-operator to assign the range variable 'idx' as side effect of a
// 'true' expression.  Similar code in 'stack.h' allows to iterate over
// generic stacks.

#define all_variables(IDX) \
  unsigned IDX = 0, END_VARIABLES = VARIABLES; IDX < END_VARIABLES; IDX++

#define all_literals(LIT) \
  unsigned LIT = 0, END_LITERALS = LITERALS; LIT < END_LITERALS; LIT++

#define all_literals_in_clause(LIT,C) \
  unsigned LIT, * P_ ## LIT = (C)->literals, \
                * const END_ ## LIT = P_ ## LIT + (C)->size; \
  (P_ ## LIT != END_ ## LIT) && (LIT = *P_ ## LIT, true); ++P_ ## LIT

#define all_irredundant_clauses(C) \
  all_pointers_on_stack (struct clause, C, solver->irredundant)

#define all_redundant_clauses(C) \
  all_pointers_on_stack (struct clause, C, solver->redundant)

/*------------------------------------------------------------------------*/

// The 'COVER' macro is used for testing and debugging, more precisely for
// the case where full assertion checking (and proof checking) is not
// feasible, but you still want to figure out whether a certain situation
// can happen.  Those conditions 'COND' are thus 'coverage goals', i.e.,
// conditions you want to hit, or situations where you are almost 100% sure
// that they can never happen, but you want to make sure that it does not
// happen maybe accidentally during a full run on a competition set.  Trying
// to cover a certain condition during fuzzing with full optimization and no
// other (assertion) checking switched on is another common use case.

// Now to the macro itself.  This is in essence the same what you want if
// you are implementing 'assert' yourself.  The main point is that it should
// be an expression of type 'void' such that you can use it as part of a
// 'comma' list.  For other examples see 'TOP' and 'POP' in 'stack.h'.

#define COVER(COND) \
( \
  (COND) \
  ? \
  \
    ( \
      fflush (stdout), \
      fprintf (stderr, "%s:%ld: %s: Coverage goal `%s' reached.\n", \
        __FILE__, (long) __LINE__, __func__, #COND), \
      abort (), \
      (void) 0 \
    ) \
  : \
    (void) 0 \
)

/*------------------------------------------------------------------------*/

// These declarations provide nice warnings messages if these functions are
// used with format strings which do not match the type of an argument.

static void fatal_error (const char *fmt, ...)
  __attribute__((format (printf, 1, 2)));

// As with 'NLIMITS' above we want to have central place where we filter
// out cases where message code is not included and then define 'NMESSAGE.

#ifdef NBUMP
#ifdef NSWITCH
#ifdef NREDUCE
#ifdef NREPHASE
#ifdef NRESTART
#define NMESSAGE
#endif
#endif
#endif
#endif
#endif

#ifndef NMESSAGE

static void message (struct satch *,
		     unsigned level, const char *name, uint64_t count,
		     const char *fmt, ...)
  __attribute__((format (printf, 5, 6)));

#endif

#ifndef NDEBUG

static void logging_message (struct satch *, const char *fmt, ...)
  __attribute__((format (printf, 2, 3)));

#ifndef NVIRTUAL

static void logging_binary (struct satch *solver,
			    bool redundant, unsigned lit, unsigned other,
			    const char *fmt, ...)
  __attribute__((format (printf, 5, 6)));

#endif

static void logging_clause (struct satch *, struct clause *,
			    const char *fmt, ...)
  __attribute__((format (printf, 3, 4)));

static void logging_temporary (struct satch *, const char *fmt, ...)
  __attribute__((format (printf, 2, 3)));

#endif

/*------------------------------------------------------------------------*/

// This section contains error, verbose and logging messages.

// Fatal error message printed to '<stderr>' followed by an 'abort' call.

static void
fatal_error (const char *fmt, ...)
{
  va_list ap;
  fputs ("libsatch: fatal error: ", stderr);
  va_start (ap, fmt);
  vfprintf (stderr, fmt, ap);
  va_end (ap);
  fputc ('\n', stderr);
  fflush (stderr);
  abort ();
}

// Running out-of-memory is a common fatal error message.

static void
out_of_memory (size_t bytes)
{
  fatal_error ("out-of-memory allocating %zu bytes", bytes);
}

#ifndef NMESSAGE

// Print a verbose message with the given verbose level.

static void
message (struct satch *solver,
	 unsigned level, const char *name, uint64_t count,
	 const char *fmt, ...)
{
  if (solver->options.verbose < level)
    return;
  fputs ("c ", stdout);
  printf ("[%s-%" PRIu64 "] ", name, count);
  va_list ap;
  va_start (ap, fmt);
  vprintf (fmt, ap);
  va_end (ap);
  fputc ('\n', stdout);
  fflush (stdout);
}

#endif

// Print nicely formatted 'c ---- [ <name> ] ----- ... ' section start line.

static void
section (struct satch *solver, const char *name)
{
  assert (solver);
  if (solver->statistics.sections)
    fputs ("c\n", stdout);
  INC (sections);
  fputs ("c ---- [ ", stdout);
  fputs (name, stdout);
  fputs (" ] ", stdout);
  for (size_t i = strlen (name); i < 66; i++)
    putc ('-', stdout);
  fputs ("\nc\n", stdout);
  fflush (stdout);
}

#ifndef NDEBUG

// Logging functions are only compiled in debugging mode and then still need
// to be enabled at run-time (with '-l' or 'satch_enable_logging_messages').

static void
logging_prefix (struct satch *solver)
{
  assert (solver->options.logging);
  printf ("c LOG %u ", solver->level);
}

#define logging_format(fmt) \
do { \
  va_list ap; \
  va_start (ap, fmt); \
  vprintf (fmt, ap); \
  va_end (ap); \
} while (0)

static void
logging_suffix (void)
{
  fputc ('\n', stdout);
  fflush (stdout);
}

// This is the function for default log messages from the 'LOG' macro.
// It prints the SAT-competition comment-line prefix 'c', the string 'LOG',
// then the decision level and finally the actual logging message, all
// separated by spaces.

static void
logging_message (struct satch *solver, const char *fmt, ...)
{
  logging_prefix (solver);
  logging_format (fmt);
  logging_suffix ();
}

#ifndef NVIRTUAL

// For virtual binary clauses we need special logging functions too.

static void
logging_binary (struct satch *solver,
		bool redundant, unsigned lit, unsigned other,
		const char *fmt, ...)
{
  logging_prefix (solver);
  logging_format (fmt);
  if (redundant)
    printf (" redundant");
  else
    printf (" irredundant");
  printf ("binary clause %u %u", lit, other);
  logging_suffix ();
}

#endif

// After printing in essence the same message as the basic logging function
// above this clause logging function conveniently prints the type of the
// clause given as argument, its glue (if redundant), its size and literals.

static void
logging_clause (struct satch *solver, struct clause *c, const char *fmt, ...)
{
  logging_prefix (solver);
  logging_format (fmt);
#ifndef NBLOCK
  // With blocking literals enabled we use the temporary binary clause for
  // binary reasons and binary conflicts.  This clause needs special
  // treatment here since its identifier is invalid (always zero).
  if (c == &solver->binary)
    printf (" binary clause");
  else
#endif
    {
      if (c->redundant)
	{
	  printf (" redundant");
#ifndef NGLUE
	  printf (" glue %u", c->glue);
#endif
	}
      else
	printf (" irredundant");
      printf (" size %u clause[%" PRIu64 "]", c->size, c->id);
    }
  for (all_literals_in_clause (lit, c))
    printf (" %u", lit);
  logging_suffix ();
}

// The temporary clause 'solver->clause' is logged here.

static void
logging_temporary (struct satch *solver, const char *fmt, ...)
{
  logging_prefix (solver);
  logging_format (fmt);
  printf (" size %zu temporary clause", SIZE (solver->clause));
  for (all_elements_on_stack (unsigned, lit, solver->clause))
      printf (" %u", lit);
  logging_suffix ();
}

// Log the temporary clause 'solver->clause'.

#define LOG(...) \
do { \
  if (solver->options.logging) \
    logging_message (solver, __VA_ARGS__); \
} while (0)

#ifndef NVIRTUAL

// Log binary clauses (give the two literals first).

#define LOGBIN(...) \
do { \
  if (solver->options.logging) \
    logging_binary (solver, __VA_ARGS__); \
} while (0)

#endif

// Log large clauses (first argument is the clause).

#define LOGCLS(...) \
do { \
  if (solver->options.logging) \
    logging_clause (solver, __VA_ARGS__); \
} while (0)

// Log the temporary clause in the solver.

#define LOGTMP(...) \
do { \
  if (solver->options.logging) \
    logging_temporary (solver, __VA_ARGS__); \
} while (0)

#else

// Make sure not to include logging code if 'NDEBUG' is defined.

#define LOG(...) do { (void) solver; } while(0)
#define LOGBIN(...) do { (void) solver; } while(0)
#define LOGCLS(...) do { (void) solver; } while(0)
#define LOGTMP(...) do { (void) solver; } while(0)

#endif

/*------------------------------------------------------------------------*/

// This is a section of rather Unix specific code which might require some
// porting effort if building on other operating systems.  On the other hand
// it is only used for diagnostic purposes and in principle can be removed.

// Process time since starting the process.

static double
process_time (void)
{
  struct rusage u;
  double res;
  if (getrusage (RUSAGE_SELF, &u))
    return 0;
  res = u.ru_utime.tv_sec + 1e-6 * u.ru_utime.tv_usec;
  res += u.ru_stime.tv_sec + 1e-6 * u.ru_stime.tv_usec;
  return res;
}

// The maximum amount of memory used by this process as seen by the system.

static uint64_t
maximum_resident_set_size (void)
{
  struct rusage u;
  if (getrusage (RUSAGE_SELF, &u))
    return 0;
  return ((uint64_t) u.ru_maxrss) << 10;
}

// Current memory used by this process as seen by the system.  This is
// very Linux specific and will not work even on other Unix systems.

uint64_t
current_resident_set_size (void)
{
  char path[48];
  sprintf (path, "/proc/%" PRIu64 "/statm", (uint64_t) getpid ());
  FILE *file = fopen (path, "r");
  if (!file)
    return 0;
  uint64_t dummy, rss;
  int scanned = fscanf (file, "%" PRIu64 " %" PRIu64 "", &dummy, &rss);
  fclose (file);
  return scanned == 2 ? rss * sysconf (_SC_PAGESIZE) : 0;
}

/*------------------------------------------------------------------------*/

// Computing the percentage or 'relative' average between two numbers is
// very common and always needs to be guarded against division by zero.
// Therefore we factor out this check into two simple functions which also
// makes the caller code (usually) more readable.

static double
percent (double a, double b)
{
  return b ? 100.0 * a / b : 0;
}

static double
relative (double a, double b)
{
  return b ? a / b : 0;
}

/*------------------------------------------------------------------------*/

// Macros and functions to 'START' and 'STOP' profiling a function.
// References to profiles are pushed on the profile stack in order to
// include time spent in a function in case that function is interrupted
// ('START' issued but interrupted without the corresponding 'STOP').

// Having this profiling information printed in optimized code running on a
// full set of benchmarks is very important to find performance regressions.

#define START(NAME) \
  start_profiling (solver, &solver->profiles.NAME)

#define STOP(NAME) \
  stop_profiling (solver, &solver->profiles.NAME, process_time ())

static void
init_profiles (struct satch *solver)
{
  struct profiles *profiles = &solver->profiles;
  profiles->end = profiles->begin;
#define PROFILE(NAME) \
  profiles->NAME.name = #NAME;
  PROFILES
#undef PROFILE
}

static void
start_profiling (struct satch *solver, struct profile *profile)
{
  struct profiles *profiles = &solver->profiles;
  const double start = process_time ();
  profile->start = start;
  assert (profiles->end < profiles->begin + MAX_PROFILES);
  *profiles->end++ = profile;
}

// Starting and stopping a profile has to follow a block structure, i.e.,
// the corresponding 'STOP' has be to called in reverse order of 'START'.
// For instance 'START (A); START (B); ...; STOP (A); STOP (B);' is correct
// but interleaving not ('START (A); START (B); ...; STOP (A); STOP (B);').
// In order to simplify testing and debugging violations of this rule we
// explicitly ask the caller to specify the stopped profile, even though in
// principle it could be derived from the top of the profile stack.

static double
stop_profiling (struct satch *solver, struct profile *profile, double stop)
{
  struct profiles *profiles = &solver->profiles;
  assert (TOP (*profiles) == profile);
  const double time = stop - profile->start;
  profile->time += time;
  (void) POP (*profiles);
  return time;
}

// If interrupted flush all pending unfinished profiles with the current
// process time.  In order to avoid calling 'getrusage' too often in this
// (often critical time constrained) situation we have the current time as
// argument to 'stop_profiling'.

static double
flush_profiles (struct satch *solver)
{
  struct profiles *profiles = &solver->profiles;
  const double stop = process_time ();
  while (!EMPTY (*profiles))
    stop_profiling (solver, TOP (*profiles), stop);
  profiles->total.time = profiles->parse.time + profiles->solve.time;
  return stop;
}

// Printing the profile information first sorts them according to time.
// We use our own bubble-sort since first the number of profiles is small
// and more importantly we do not want to allocate heap memory (usually
// required by implementations of 'qsort') because this function should only
// work with already existing memory. Consider for instance the case where
// it was called from an interrupt handler catching a segmentation fault due
// to out-of-memory.  Then calling an external sorting function might
// trigger another segmentation fault and we will not see the profiling
// information.  This is bad because for an out-of-memory run the profiling
// information might be particularly useful.

static double
print_profiles (struct satch *solver)
{
  // First flush all timing information (stop all pending profiles).

  const double stop = flush_profiles (solver);

  section (solver, "profiling");	// As early as possible.

  // Then add all profiles to the (pre-allocated!) profiles stack skipping
  // those without any time spent in it (unless verbose level is larger 1).

  struct profiles *profiles = &solver->profiles;
  const bool verbose = solver->options.verbose > 1;
  assert (EMPTY (*profiles));

// *INDENT-OFF*

#define PROFILE(NAME) \
do { \
    struct profile * profile = &profiles->NAME; \
    if (profile == &profiles->total) \
      break; \
    if (!verbose && !profile->time) \
      break; \
    assert (profiles->end < profiles->begin + MAX_PROFILES); \
    *profiles->end++ =  &profiles->NAME; \
} while (0);

  PROFILES
#undef PROFILE

// *INDENT-ON*

  // Sort profiles with respect to time used and name as tie breaker.

  const size_t size = SIZE (*profiles);
  for (size_t i = 0; i < size; i++)
    {
      struct profile *p = profiles->begin[i];
      for (size_t j = i + 1; j < size; j++)
	{
	  struct profile *q = profiles->begin[j];
	  if (p->time < q->time ||
	      (p->time == q->time && strcmp (p->name, q->name) > 0))
	    {
	      profiles->begin[i] = q;
	      profiles->begin[j] = p;
	      p = q;
	    }
	}
    }

  // Finally print the profile information in sorted order.

  const double total = profiles->total.time;
  for (size_t i = 0; i < size; i++)
    {
      struct profile *p = profiles->begin[i];
      printf ("c %14.2f  %6.2f %%  %s\n",
	      p->time, percent (p->time, total), p->name);

    }
  fputs ("c =============================================\n", stdout);
  printf ("c %14.2f  %6.2f %%  total\n", total, 100.0);

  return stop;
}

/*------------------------------------------------------------------------*/

static void
print_statistics (struct satch *solver, double seconds)
{
  section (solver, "statistics");
  struct statistics s = solver->statistics;
#if 0
  const bool verbose = solver->options.verbose > 1;
#else
  const bool verbose = true;	// For now complete statistics.
#endif

  // Factored out parts of the formatting string.
  //
#define F1 "c %-27s"		// Prefix plus left justified name.
#define L2 "17"			// First number column (absolute values).
#define L3 "17"			// Second number column (absolute values).
#define P3 "14"			// Second number column (relative / percent).

  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 "s clauses\n", "added:", s.added, "");
#ifndef NBEST
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "bests:",
	  s.bests, relative (s.conflicts, s.bests));
#endif
#ifndef NBUMP
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f literals\n", "bumped:",
	    s.bumped, relative (s.bumped, s.conflicts));
#endif
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f per second\n", "conflicts:",
	  s.conflicts, relative (s.conflicts, seconds));
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f per conflict\n", "decisions:",
	  s.decisions, relative (s.decisions, s.conflicts));
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f literals\n", "deduced:",
	    s.deduced, relative (s.deduced, s.conflicts));
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  added\n", "deleted:",
	    s.deleted, percent (s.deleted, s.added));
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f literals\n", "learned:",
	  s.learned, relative (s.learned, s.conflicts));
#ifndef NVSIDS
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  bumped\n", "incremented:",
	    s.incremented, percent (s.incremented, s.bumped));
#endif
#ifndef NMINIMIZE
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  deduced\n", "minimized:",
	    s.minimized, percent (s.minimized, s.deduced));
#endif
#ifndef NVMTF
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  bumped\n", "moved:",
	    s.moved, percent (s.moved, s.bumped));
#endif
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f per second\n", "propagations:",
	  s.propagations, relative (s.propagations, seconds));
#ifndef NREASONS
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  bumped\n", "reasons:",
	    s.reasons, percent (s.reasons, s.bumped));
#endif
#ifndef NREDUCE
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "reductions:",
	  s.reductions, relative (s.conflicts, s.reductions));
#endif
#ifndef NREPHASE
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "rephased:",
	  s.rephased, relative (s.conflicts, s.rephased));
#endif
#ifndef NVSIDS
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "rescored:",
	  s.rescored, relative (s.conflicts, s.rescored));
#endif
#ifndef NVMTF
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "restamped:",
	  s.restamped, relative (s.conflicts, s.restamped));
#endif
#ifndef NRESTART
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "restarts:",
	  s.restarts, relative (s.conflicts, s.restarts));
#endif
#ifndef NSWITCH
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "switched:",
	  s.switched, relative (s.conflicts, s.switched));
#endif
#ifndef NTARGET
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "targets:",
	  s.targets, relative (s.conflicts, s.targets));
#endif
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f per prop\n", "ticks:",
	    s.ticks, relative (s.ticks, s.propagations));
}

static void
print_resource_usage (struct satch *solver, double seconds)
{
  section (solver, "resources");
  const uint64_t memory = maximum_resident_set_size ();
  printf ("c %-27s %17" PRIu64 " bytes %11.2f MB\n",
	  "memory:", memory, memory / (double) (1 << 20));
  printf ("c %-27s %17s %17.2f seconds\n", "time:", "", seconds);
}

/*------------------------------------------------------------------------*/

// Export internal unsigned literals as external signed literals.

static unsigned
export_literal (unsigned ilit)
{
  const unsigned iidx = INDEX (ilit);
  assert (iidx < (unsigned) INT_MAX - 1);
  const int eidx = iidx + 1;
  const int elit = SIGN_BIT (ilit) ? -eidx : eidx;
  return elit;
}

/*------------------------------------------------------------------------*/

// Print DRAT (actually DRUP) proof lines in ASCII or binary format to the
// given proof file. These lines are either clause additions or clause
// deletions.  The binary format distinguishes them by a leading 'a' or 'd'
// (ASCII) character, while the ASCII format just adds a "d " prefix for
// clause deletion;  then literals are printed.  The binary format uses a
// dynamic word length for numbers while the ASCII format looks like the
// DIMACS format. The end of a proof line is indicated by zero (number in
// the ASCII format and byte in the binary format).

static void
start_addition_proof_line (struct satch *solver)
{
  assert (solver->proof);
  if (!solver->options.ascii)
    fputc ('a', solver->proof);
}

static void
start_deletion_proof_line (struct satch *solver)
{
  assert (solver->proof);
  fputc ('d', solver->proof);
  if (solver->options.ascii)
    fputc (' ', solver->proof);
}

static void
add_external_literal_to_proof_line (struct satch *solver, int elit)
{
  assert (solver->proof);
  if (solver->options.ascii)
    fprintf (solver->proof, "%d ", elit);
  else
    {
      // This is almost like our internal literal encoding except that it is
      // shifted by two, since zero is used as sentinel of a proof line.

      assert (2u * INT_MAX + 1 == UINT_MAX);	// Overflow for 'INT_MAX'.

      const unsigned plit = 2u * abs (elit) + (elit < 0);

      // Now this proof literal 'plit' is written 7-bit wise to the file.
      // The 8th most significant bit of the actual written byte denotes
      // whether further non-zero bits, so at least one more byte, follow.

      unsigned rest = plit;

      while (rest & ~0x7f)
	{
	  const unsigned char byte = (rest & 0x7f) | 0x80;
	  fputc (byte, solver->proof);
	  rest >>= 7;
	}

      fputc ((unsigned char) rest, solver->proof);
    }
}

static void
add_internal_literal_to_proof_line (struct satch *solver, unsigned ilit)
{
  const int elit = export_literal (ilit);
  add_external_literal_to_proof_line (solver, elit);
}

static void
end_proof_line (struct satch *solver)
{
  assert (solver->proof);
  if (solver->options.ascii)
    fputs ("0\n", solver->proof);
  else
    fputc (0, solver->proof);
  fflush (solver->proof);
}

static void
add_internal_clause_to_proof (struct satch *solver)
{
  start_addition_proof_line (solver);
  for (all_elements_on_stack (unsigned, lit, solver->clause))
      add_internal_literal_to_proof_line (solver, lit);
  end_proof_line (solver);
}

/*------------------------------------------------------------------------*/

// Allocate the actual clause data memory and depending on whether we embed
// the literals directly into the clause using a variadic array member just
// allocate one chunk of memory or otherwise the literals separately.

#ifndef NVARIADIC

static size_t
bytes_clause (size_t size)
{
  assert (size > 1);
  return sizeof (struct clause) + (size - 2) * sizeof (unsigned);
}

// This default variadic variant just allocates one chunk of memory.

static struct clause *
allocate_clause (size_t size)
{
  const size_t bytes = bytes_clause (size);
  struct clause *res = malloc (bytes);
  if (!res)
    out_of_memory (bytes);
  return res;
}

static size_t
deallocate_clause (struct clause *c)
{
  const size_t bytes = bytes_clause (c->size);
  free (c);
  return bytes;
}

#else

// The non-variadic variant has to allocate two memory blocks.

static struct clause *
allocate_clause (size_t size)
{
  const size_t header_bytes = sizeof (struct clause);
  struct clause *res = malloc (header_bytes);
  if (!res)
    out_of_memory (header_bytes);
  const size_t literals_bytes = size * sizeof (unsigned);
  res->literals = malloc (literals_bytes);
  if (!res->literals)
    out_of_memory (literals_bytes);
  return res;
}

static size_t
deallocate_clause (struct clause *c)
{
  const size_t header_bytes = sizeof (struct clause);
  const size_t literals_bytes = c->size * sizeof (unsigned);
  free (c->literals);
  free (c);
  return header_bytes + literals_bytes;
}

#endif

/*------------------------------------------------------------------------*/

static struct clause *
add_clause (struct satch *solver, bool redundant, unsigned glue)
{
  const uint64_t added = INC (added);
  const size_t size = SIZE (solver->clause);
#ifdef NVIRTUAL
  assert (size > 1);		// Units and empty clauses are implicit.
#else
  assert (size > 2);		// No binary clauses allocated at all!
#endif
  struct clause *res = allocate_clause (size);

  res->id = added;

  res->garbage = false;
  res->protected = false;
  res->redundant = redundant;
#ifndef NUSED
  res->used = 0;
#endif
#ifndef NGLUE
  res->glue = glue;
#else
  (void) glue;
#endif
#ifndef NCACHE
  res->search = 0;
#endif
  res->size = size;
  memcpy (res->literals, solver->clause.begin, size * sizeof (unsigned));
  return res;
}

static struct clause *
new_irredundant_clause (struct satch *solver)
{
  struct clause *res = add_clause (solver, false, 0);
  PUSH (solver->irredundant, res);
  INC (irredundant);
  return res;
}

static struct clause *
new_redundant_clause (struct satch *solver, unsigned glue)
{
  struct clause *res = add_clause (solver, true, glue);
#ifndef NLEARN
  PUSH (solver->redundant, res);
#endif
  INC (redundant);
  return res;
}

static size_t
delete_clause (struct satch *solver, struct clause *c)
{
  INC (deleted);
  LOGCLS (c, "delete");
  if (solver->proof)
    {
      start_deletion_proof_line (solver);
      for (all_literals_in_clause (lit, c))
	add_internal_literal_to_proof_line (solver, lit);
      end_proof_line (solver);
    }
#if !defined(NDEBUG) && !defined(NLEARN)
  for (all_literals_in_clause (lit, c))
    checker_add_literal (solver->checker, export_literal (lit));
  checker_delete_clause (solver->checker);
#endif
  if (c->redundant)
    DEC (redundant);
  else
    DEC (irredundant);
  return deallocate_clause (c);
}

/*------------------------------------------------------------------------*/

// Watch a literal 'lit' in a clause with blocking literal 'other'.

static void
watch_literal (struct satch *solver, unsigned lit,
	       unsigned blocking, struct clause *c)
{
  struct watches *watches = solver->watches + lit;
  union watch watch;
#ifndef NBLOCK
  watch.header.binary = (c->size == 2);
  watch.header.blocking = blocking;
  LOGCLS (c, "watching %u blocking %u in", lit, blocking);
  PUSH (*watches, watch);
#else
  (void) blocking;		// Prevent 'unused parameter' warning.
  LOGCLS (c, "watching %u in", lit);
#endif
  watch.clause = c;		// In any case watch the clause.
  PUSH (*watches, watch);
}

// Watch first two literals in the clause.

static void
watch_clause (struct satch *solver, struct clause *c)
{
  assert (c->size > 1);
  const unsigned lit = c->literals[0];
  const unsigned other = c->literals[1];
  watch_literal (solver, lit, other, c);
  watch_literal (solver, other, lit, c);
}

/*------------------------------------------------------------------------*/

#ifndef NBLOCK

// With blocking literals we do not have to store clauses as reasons. At the
// same time (since this is used for compact watch data structures anyhow)
// we also use the temporary binary clause for conflicting binary clauses.

static void
init_binary (struct satch *solver)
{
  solver->binary.size = 2;
#ifdef NVARIADIC
  const size_t bytes = 2 * sizeof (unsigned);
  solver->binary.literals = malloc (bytes);
  if (!solver->binary.literals)
    out_of_memory (bytes);
#endif
}

static void
release_binary (struct satch *solver)
{
#ifdef NVARIADIC
  free (solver->binary.literals);
#else
  (void) solver;
#endif
}

// Copy 'lit' and 'other' to the (single) temporary binary clause in the
// solver.  This is used for generating a binary clause conflict (if
// 'NBLOCK' is undefined) and indirectly through 'binary_reason_to_clause'
// to unify the conflict analysis code with and without 'NBLOCK'.

static struct clause *
binary_clause (struct satch *solver, unsigned lit, unsigned other)
{
  solver->binary.literals[0] = lit;
  solver->binary.literals[1] = other;
  return &solver->binary;
}

// We want to only have one global 'reason' array in which we store both
// binary clause reasons (which consists of just the other literal) as well
// as pointers to large clause.  We distinguish those with stuffing a bit
// into the clause pointer.  In case the least-significant bit is one then
// the rest of the 'reason' pointer forms the other literal.  Otherwise it
// is the actual pointer to a large clause.  Note that the least significant
// bit is zero on all systems we have seen and this is a common idiom anyhow
// (for instance for AIG and BDD packages).

// Some technical details follow on why this scheme works perfectly well on
// 64-bit machines.  On such machines pointer size is twice the size of
// 'unsigned' literals and the 32-bit variable-index easily fits into the
// upper 63 bits of a reason pointer.  On 32-bit machines this might break
// for literals larger equal to 2^31 which is however prevented by raising
// an API contract violation, when trying to import a variable of size
// larger than 2^30.  Thus on 32-bit machines we 'only' have 2^30 variables.
// Trying to reach this limit on a 32-bit machine would probably lead to
// memory overflow much earlier anyhow.

static bool
is_binary_reason (const struct clause *const c)
{
  uintptr_t word = (uintptr_t) c;
  return word & 1;
}

static struct clause *
binary_reason (uintptr_t other)
{
  const uintptr_t tmp = (other << 1) | 1;
  struct clause *res = (struct clause *) tmp;
  assert (is_binary_reason (res));
  return res;
}

static unsigned
binary_reason_to_literal (const struct clause *reason)
{
  assert (is_binary_reason (reason));
  const uintptr_t tmp = (uintptr_t) reason;
  const unsigned res = tmp >> 1;
  return res;
}

static struct clause *
binary_reason_to_clause (struct satch *solver,
			 unsigned lit, const struct clause *reason)
{
  assert (is_binary_reason (reason));
  const unsigned other = binary_reason_to_literal (reason);
  return binary_clause (solver, lit, other);
}

#endif

/*------------------------------------------------------------------------*/

#ifndef NVIRTUAL

// This section handles virtual binary clauses which only reside reside in
// watch lists but are not actually allocated. This feature (disabled if
// 'NVIRTUAL' is defined) can save up to a factor of four in memory usage.

static inline void
watch_binary (struct satch *solver,
	      bool redundant, unsigned lit, unsigned blocking)
{
  union watch watch;
  watch.header.binary = true;
  watch.header.redundant = redundant;
  watch.header.blocking = blocking;
  PUSH (solver->watches[lit], watch);
  LOGBIN (redundant, lit, blocking,
	  "watching %u blocking %u in", lit, blocking);
}

static void
new_binary (struct satch *solver, bool redundant)
{
  assert (SIZE (solver->clause) == 2);
  const unsigned lit = ACCESS (solver->clause, 0);
  const unsigned other = ACCESS (solver->clause, 1);
  watch_binary (solver, redundant, lit, other);
  watch_binary (solver, redundant, other, lit);
  if (redundant)
    INC (redundant);
  else
    INC (irredundant);
}

#if !defined(NREDUCE) || (!defined(NDEBUG) && !defined(NVIRTUAL))

static void
delete_binary (struct satch *solver,
	       bool redundant, unsigned lit, unsigned other)
{
  // We watch 'lit' in the watch list of 'other' and vice versa. Thus when
  // we delete these virtual binary clauses (residing only in watch lists)
  // we do not know which of the two cases we encounter first but both
  // occurrences should trigger 'delete_binary'.  Thus we delete the virtual
  // binary clause only once when 'lit' is smaller than 'other'.

  if (lit > other)
    return;

  LOGBIN (redundant, lit, other, "delete");
  if (solver->proof)
    {
      start_deletion_proof_line (solver);
      add_internal_literal_to_proof_line (solver, lit);
      add_internal_literal_to_proof_line (solver, other);
      end_proof_line (solver);
    }
#if !defined(NDEBUG) && !defined(NLEARN)
  checker_add_literal (solver->checker, export_literal (lit));
  checker_add_literal (solver->checker, export_literal (other));
  checker_delete_clause (solver->checker);
#endif
  if (redundant)
    DEC (redundant);
  else
    DEC (irredundant);
}

#endif

#ifndef NDEBUG

static void
delete_header (struct satch *solver, unsigned lit, struct header header)
{
  const bool redundant = header.redundant;
  const unsigned blocking = header.blocking;
  delete_binary (solver, redundant, lit, blocking);
}

#endif

#endif

/*------------------------------------------------------------------------*/

static void
assign (struct satch *solver, unsigned lit, struct clause *reason)
{
#ifndef NDEBUG
#ifndef NBLOCK
  if (is_binary_reason (reason))
    LOG ("assign %u reason temporary binary reason %u %u",
	 lit, lit, binary_reason_to_literal (reason));
  else
#endif
  if (reason)
    LOGCLS (reason, "assign %u reason", lit);
  else if (!solver->level)
    LOG ("assign %u through unit clause %u", lit, lit);
  else
    LOG ("assign %u decision", lit);
#endif

  if (!solver->level)
    {
      solver->statistics.fixed++;	// Root-level fixed literal (unit).
      assert (solver->statistics.active);
      solver->statistics.active--;
      reason = 0;
    }

  const unsigned not_lit = NOT (lit);
  assert (!solver->values[lit]);
  assert (!solver->values[not_lit]);

  // Set value of 'lit' and 'not-lit' independently in order to turn the
  // code for accessing the value of a literal into a simple array look-up
  // as well. This makes it simpler and branch-less too

  solver->values[lit] = 1;
  solver->values[not_lit] = -1;

  const unsigned idx = INDEX (lit);

#ifndef NSAVE
  // Save value for next decision phase selection of 'idx'.
  solver->saved[idx] = INT_SIGN (lit);
#endif
  solver->reasons[idx] = reason;	// Remember reason clause.
  solver->levels[idx] = solver->level;	// Remember decision level.

  // Add literal to the partial assignment in the pre-allocated 'trail'.

  assert (solver->trail.end < solver->trail.begin + VARIABLES);
  *solver->trail.end++ = lit;

  // Used for fast termination check on 'satisfiable' instances.

  assert (solver->unassigned);
  solver->unassigned--;
}

/*------------------------------------------------------------------------*/

// The following macro increases the array given as argument which either
// comes as variable indexed array ('FACTOR==1') or literal indexed array
// ('FACTOR==2'). This reallocation would be more complex to code for signed
// 'int' literals and is one of the reasons we use 'unsigned' literals.

// The last argument is for 'frames' which should be of size 'size + 1'
// since both are accessed through the solver level which can reach 'size'
// even though probably not in the situation where 'frames' is accessed.
// Nevertheless we accommodate for this potential off-by-one allocation by
// adding 'ADJUST' to the size.

#define RESIZE_UNINITIALIZED(P) \
do { \
  const size_t new_bytes = (size_t) new_capacity * sizeof *(P); \
  (P) = realloc ((P), new_bytes); \
  if (!(P)) \
    out_of_memory (new_bytes); \
} while (0)

#define RESIZE_ZERO_INITIALIZED(FACTOR,P,ADJUST) \
do { \
  const size_t size = sizeof *(P); \
  const size_t old_bytes = \
    old_capacity ? FACTOR * (size_t) (old_capacity + ADJUST) * size : 0; \
  const size_t new_bytes = FACTOR * (size_t) (new_capacity + ADJUST) * size; \
  void * chunk = calloc (new_bytes, 1); \
  if (!chunk) \
    out_of_memory (new_bytes); \
  memcpy (chunk, (P), old_bytes); \
  free ((P)); \
  (P) = chunk; \
} while (0)

/*------------------------------------------------------------------------*/

// Facilitates to activate variables in the order they appear in the input
// by putting them on each of the two 'put' stacks, which allows to delay
// initialization of the decision queue / heap and only when the queue or
// the heap is queried through 'get_queue' resp. 'get_scores' it is filled
// in the order in which the variables have been activated.

#ifndef NACTIVE

static void
activate_literals (struct satch *solver)
{
  bool *active = solver->active;
  for (all_elements_on_stack (unsigned, lit, solver->clause))
    {
      const unsigned idx = INDEX (lit);
      if (active[idx])
	continue;
      active[idx] = true;
      LOG ("activated variable %u", idx);
#ifndef NFOCUSED
      PUSH (solver->put[0], idx);
#endif
#ifndef NSTABLE
      PUSH (solver->put[1], idx);
#endif
      solver->statistics.active++;
      solver->unassigned++;
    }
}

#endif

/*------------------------------------------------------------------------*/
#ifndef NQUEUE
/*------------------------------------------------------------------------*/

// Functions to implement a doubly linked variable decision queue.

#ifndef NBUMP

// We use 32-bit enqueue time stamps which overflow rather frequently after
// roughly 4 billion enqueue operations.  In this case we just go over all
// variable links in order of the decision queue and assign fresh stamps.
// Even for many variables (the maximum variable index is '(1u<<31) - 2') we
// still need a billion enqueue operations before this triggers and thus the
// accumulated complexity for this operation can be ignored.  The memory is
// still allocated in 'increase_capacity' though through 'resize_queue'.

static void
restamp_queue (struct satch *solver, struct queue *queue)
{
  const uint64_t restamped = INC (restamped);
  message (solver, 2, "restamp", restamped,
	   "restamping indices in decision queue");
  struct link *links = queue->links, *link;
  unsigned stamp = 0;
  for (unsigned idx = queue->first; idx != INVALID; idx = link->next)
    {
      link = links + idx;
      assert (stamp < UINT_MAX);
      link->stamp = ++stamp;
    }
  queue->search = queue->last;
  queue->stamp = stamp;
}

#endif

// Simple doubly linked list enqueue operation at the end of the queue with
// time stamping, where the time is the 'enqueue time'.  The 'search' index
// of the queue is also updated if this variable is unassigned.

static void
enqueue (struct satch *solver, struct queue *queue, unsigned idx)
{
  LOG ("enqueue %u", idx);
  struct link *const links = queue->links;
  struct link *const link = links + idx;
  const unsigned last = queue->last;
  if (last == INVALID)
    {
      assert (queue->first == INVALID);
      queue->first = idx;
    }
  else
    {
      struct link *const prev = links + last;
      assert (prev->next == INVALID);
      prev->next = idx;
    }
  link->prev = last;
  queue->last = idx;
  link->next = INVALID;

  // Now comes the 'stamping' trick from our SAT'2015 paper which makes sure
  // that time stamps respect queue order and can thus be used to compare in
  // constant time whether an element is to the left or right of the cached
  // search index, which during searching for unassigned decision variables
  // is set to the last decision variable index first and then updated in
  // case a variable right to the cached search index becomes unassigned
  // during backtracking.  This technique makes sure that right to the
  // search index all variables are assigned in the decision queue.  See
  // also the code involving stamps in 'backtrack' and in 'decide'.

  link->stamp = ++queue->stamp;
#ifdef NBUMP
  assert (link->stamp);
#else
  if (link->stamp)		// Check for overflow.
#endif
    {
      LOG ("enqueued variable %u stamped %u", idx, link->stamp);
      const unsigned lit = LITERAL (idx);
      if (!solver->values[lit])
	queue->search = idx;
    }
#ifndef NBUMP
  else
    restamp_queue (solver, queue);
#endif
}

#ifndef NVMTF

// Simple doubly linked list dequeue operation (no stamping involved).

static void
dequeue (struct satch *solver, struct queue *queue, unsigned idx)
{
  LOG ("dequeue %u", idx);
  struct link *const links = queue->links;
  struct link *const link = links + idx;
  const unsigned prev_idx = link->prev;
  const unsigned next_idx = link->next;
  if (prev_idx == INVALID)
    {
      assert (queue->first == idx);
      queue->first = next_idx;
    }
  else
    {
      struct link *const prev = links + prev_idx;
      assert (prev->next == idx);
      prev->next = next_idx;
    }
  if (next_idx == INVALID)
    {
      assert (queue->last == idx);
      queue->last = prev_idx;
    }
  else
    {
      struct link *next = links + next_idx;
      assert (next->prev == idx);
      next->prev = prev_idx;
    }
}

#endif

/*------------------------------------------------------------------------*/

// The solver might have actually two of these (by default only one in
// stable mode though).  This could in principle be figured out at compile
// time but is extremely complex.  Instead we simply initialize the queue
// on-demand if 'size' is not big enough.

static void
resize_queue (struct queue *queue, size_t new_capacity)
{
  RESIZE_UNINITIALIZED (queue->links);
}

static void
init_queue (struct satch *solver, struct queue *queue)
{
  if (!queue->size)
    queue->first = queue->last = queue->search = INVALID;
  if (!queue->links)
    resize_queue (queue, solver->capacity);
}

#ifndef NACTIVE

// Put variables on the decision queue in the order in which the variables
// are activated (found in the input). Since the last activated variables is
// enqueued last, reverse activation order gives initial decision order.

static void
activate_queue (struct satch *solver, struct queue *queue,
		struct unsigned_stack *activate)
{
  init_queue (solver, queue);
  const unsigned stable = solver->stable;
  LOG ("activating %zu variables on queue[%u]", SIZE (*activate), stable);
  for (all_elements_on_stack (unsigned, idx, *activate))
    {
      INC (activated[stable]);
      enqueue (solver, queue, idx);
    }
  RELEASE (*activate);
  queue->size = solver->size;
}

#else

// Put variables on the decision queue in index order.  Since the variable
// with the largest index is enqueued last, reverse index order gives
// initial decision order.

static void
fill_queue (struct satch *solver, struct queue *queue)
{
  init_queue (solver, queue);
  const unsigned stable = solver->stable;
  LOG ("filling queue[%u] with %zu variables",
       stable, (size_t) (solver->size - queue->size));
  while (queue->size < solver->size)
    {
      INC (filled[stable]);
      enqueue (solver, queue, queue->size++);
    }
}

#endif

static struct queue *
get_queue (struct satch *solver)
{
  const unsigned stable = solver->stable;
  struct queue *queue = &solver->queue[stable];
#ifndef NACTIVE
  struct unsigned_stack *activate = &solver->put[stable];
  if (!EMPTY (*activate))
    activate_queue (solver, queue, activate);
#else
  if (queue->size < solver->size)
    fill_queue (solver, queue);
#endif
  assert (queue->size == solver->size);
  return queue;
}

#ifndef NVMTF

static void
move_variable_to_front (struct satch *solver, unsigned idx)
{
  INC (moved);
  LOG ("moving variable %u to front of decision queue", idx);
  struct queue *queue = get_queue (solver);
  dequeue (solver, queue, idx);
  enqueue (solver, queue, idx);
}

#endif

static void
release_queue (struct queue *queue)
{
  free (queue->links);
}

/*------------------------------------------------------------------------*/
#endif
/*------------------------------------------------------------------------*/

/*------------------------------------------------------------------------*/
#ifndef NHEAP
/*------------------------------------------------------------------------*/

// Functions to implement a binary heap with embedded scores and update
// function used for the priority queue for decision variables, i.e., the
// EVSIDS scheme.  As with queues this heap might have two instances in the
// solver but in default compilation only one for stable mode is actually
// used and initialized on-demand, i.e., by comparing the solver size with
// the zero initialized 'size'.

#if 0
static void
check_heap (struct heap *heap)
{
#ifndef NDEBUG
  const unsigned size = SIZE (*heap);
  const unsigned *const begin = heap->begin;
  const unsigned *const pos = heap->pos;
  const double *const score = heap->score;
  for (unsigned i = 0; i < size; i++)
    {
      const unsigned idx = begin[i];
      const unsigned idx_pos = pos[idx];
      assert (idx_pos == i);
      unsigned child_pos = 2 * idx_pos + 1;
      unsigned parent_pos = (child_pos - 1) / 2;
      assert (parent_pos == idx_pos);
      if (child_pos < size)
	{
	  unsigned child = begin[child_pos];
	  assert (score[idx] >= score[child]);
	  if (++child_pos < size)
	    {
	      parent_pos = (child_pos - 1) / 2;
	      assert (parent_pos == idx_pos);
	      child = begin[child_pos];
	      assert (score[idx] >= score[child]);
	    }
	}
    }
#endif
}

#else
#define check_heap(...) do { } while (0)
#endif

static void
bubble_up (struct satch *solver, struct heap *heap, unsigned idx)
{
  unsigned *stack = heap->begin;
  unsigned *pos = heap->pos;
  unsigned idx_pos = pos[idx];
  const double *const score = heap->score;
  const double idx_score = score[idx];
  while (idx_pos)
    {
      const unsigned parent_pos = (idx_pos - 1) / 2;
      const unsigned parent = stack[parent_pos];
      const double parent_score = score[parent];
      if (parent_score >= idx_score)
	break;

      LOG ("swap heap[%u] = %u (%g) with heap[%u] = %u (%g)",
	   idx_pos, idx, idx_score, parent_pos, parent, parent_score);

      stack[idx_pos] = parent;
      pos[parent] = idx_pos;
      idx_pos = parent_pos;
    }
  stack[idx_pos] = idx;
  pos[idx] = idx_pos;
  LOG ("settled to heap[%u] = %u (%g)", idx_pos, idx, idx_score);
  check_heap (heap);
}

static void
bubble_down (struct satch *solver, struct heap *heap, unsigned idx)
{
  const double *score = heap->score;
  unsigned *begin = heap->begin;
  unsigned *pos = heap->pos;

  const unsigned size = SIZE (*heap);

  const double idx_score = score[idx];
  unsigned idx_pos = pos[idx];

  for (;;)
    {
      unsigned child_pos = 2 * idx_pos + 1;
      if (child_pos >= size)
	break;

      unsigned child = begin[child_pos];
      double child_score = score[child];

      const unsigned sibling_pos = child_pos + 1;
      if (sibling_pos < size)
	{
	  const unsigned sibling = begin[sibling_pos];
	  const double sibling_score = score[sibling];
	  if (sibling_score > child_score)
	    {
	      child = sibling;
	      child_pos = sibling_pos;
	      child_score = sibling_score;
	    }
	}

      if (child_score <= idx_score)
	break;

      assert (idx_pos < child_pos);
      LOG ("swap heap[%u] = %u (%g) with heap[%u] = %u (%g)",
	   idx_pos, idx, idx_score, child_pos, child, child_score);

      begin[idx_pos] = child;
      pos[child] = idx_pos;
      idx_pos = child_pos;
    }
  begin[idx_pos] = idx;
  pos[idx] = idx_pos;
  LOG ("settled to heap[%u] = %u (%g)", idx_pos, idx, idx_score);
  check_heap (heap);
}

static void
push_heap (struct satch *solver, struct heap *heap, unsigned idx)
{
  const unsigned size = SIZE (*heap);
  assert (size < solver->size);
  unsigned *pos = heap->pos;
  assert (pos[idx] == INVALID);
  pos[idx] = size;
  *heap->end++ = idx;
  LOG ("push heap[%u] = %u (%g)", size, idx, heap->score[idx]);
  bubble_up (solver, heap, idx);
}

static unsigned
max_heap (struct heap *heap)
{
  return ACCESS (*heap, 0);
}

static void
pop_heap (struct satch *solver, struct heap *heap)
{
  check_heap (heap);
  const unsigned res = max_heap (heap);
  LOG ("pop heap[0] = %u (%g)", res, heap->score[res]);
  unsigned *pos = heap->pos;
  assert (!pos[res]);
  pos[res] = INVALID;
  const unsigned last = POP (*heap);
  if (last == res)
    return;
  pos[last] = 0;
  heap->begin[0] = last;
  bubble_down (solver, heap, last);
}

#ifndef NVSIDS

static double
heap_score (struct heap *heap, unsigned idx)
{
  return heap->score[idx];
}

static void
update_heap (struct satch *solver, struct heap *heap,
	     unsigned idx, double new_score)
{
  check_heap (heap);
  double *score = heap->score;
  const double old_score = score[idx];
  if (old_score < new_score)
    {
      score[idx] = new_score;
      if (heap->pos[idx] != INVALID)
	bubble_up (solver, heap, idx);
    }
  else if (old_score > new_score)
    {
      if (heap->pos[idx] != INVALID)
	bubble_down (solver, heap, idx);
    }
}

static void
rescore_scores (struct satch *solver, struct heap *scores)
{
  const uint64_t rescored = INC (rescored);
  const unsigned size = solver->size;
  double *score = scores->score;
  assert (size);
  double max_score = score[0];
  for (unsigned idx = 1; idx < size; idx++)
    {
      const double tmp_score = score[idx];
      if (tmp_score > max_score)
	max_score = tmp_score;
    }
  assert (max_score);
  message (solver, 2, "rescore", rescored,
	   "rescoring heap with maximum score %g", max_score);
  for (unsigned idx = 0; idx < size; idx++)
    score[idx] /= max_score;
  scores->increment /= max_score;
  message (solver, 3, "rescore", rescored,
	   "new score increment %g", scores->increment);
}

#endif

/*------------------------------------------------------------------------*/

static void
resize_heap (struct heap *heap, size_t old_capacity, size_t new_capacity)
{
  const size_t size = SIZE (*heap);
  RESIZE_UNINITIALIZED (heap->begin);
  heap->end = heap->begin + size;
  RESIZE_UNINITIALIZED (heap->pos);
  RESIZE_ZERO_INITIALIZED (1, heap->score, 0);
}

static void
release_heap (struct heap *heap)
{
  free (heap->begin);
  free (heap->pos);
  free (heap->score);
}

static void
init_scores (struct satch *solver, struct heap *scores)
{
  if (!scores->increment)
    scores->increment = 1.0;
  if (!scores->begin)
    resize_heap (scores, 0, solver->capacity);
}

#ifndef NACTIVE

// Put variables on the scores binary heap in the order in which the
// variables are activated (found in the input). Since the first activated
// variable is pushed first, activation order gives initial decision order.
// Note that, we stop bubbling up variables as soon a parent is found with
// the same score which initially are all the same.  However as soon the
// first decision variable is popped from the heap the last variable (which
// was then activated last actually) will become the first with the effect
// that until the first conflict the other decision variables after the
// first are picked in reverse activation order, which in essence matches
// the decision order of the queue.

static void
activate_scores (struct satch *solver, struct heap *scores,
		 struct unsigned_stack *activate)
{
  init_scores (solver, scores);
  const unsigned stable = solver->stable;
  LOG ("activating %zu variables on scores[%u]", SIZE (*activate), stable);
  unsigned *pos = scores->pos;
  double *score = scores->score;
  for (all_elements_on_stack (unsigned, idx, *activate))
    {
      const uint64_t activated = INC (activated[stable]);
      pos[idx] = INVALID;
      score[idx] = 1 - 1.0 / activated;
      push_heap (solver, scores, idx);
    }
  RELEASE (*activate);
  scores->size = solver->size;
}

#else

// Put variables on the scores binary heap in index order.  Since the
// variable with the largest index is pushed last, reverse index order gives
// initial decision order but only for the first decision (as discussed
// above for 'activate_scores').  Then we get reverse index order until the
// first conflict happens and scores are bumped.

static void
fill_scores (struct satch *solver, struct heap *scores)
{
  init_scores (solver, scores);
  const unsigned stable = solver->stable;
  LOG ("filling scores[%u] with %zu variables",
       stable, (size_t) (solver->size - scores->size));
  if (scores->size == solver->size)
    return;
  unsigned *pos = scores->pos;
  double *score = scores->score;
  const size_t delta = solver->size - scores->size;
  memset (pos + scores->size, 0xff, delta * sizeof *pos);
  while (scores->size < solver->size)
    {
      const uint64_t filled = INC (filled[stable]);
      const unsigned idx = scores->size++;
      score[idx] = 1 - 1.0 / filled;
      push_heap (solver, scores, idx);
    }
}

#endif

static struct heap *
get_scores (struct satch *solver)
{
  const unsigned stable = solver->stable;
  struct heap *scores = &solver->scores[stable];
#ifndef NACTIVE
  struct unsigned_stack *activate = &solver->put[stable];
  if (!EMPTY (*activate))
    activate_scores (solver, scores, activate);
#else
  if (scores->size < solver->size)
    fill_scores (solver, scores);
#endif
  assert (scores->size == solver->size);
  return scores;
}

#ifndef NVSIDS

static void
bump_variable_score (struct satch *solver, unsigned idx)
{
  INC (incremented);
  struct heap *scores = get_scores (solver);
  const double old_score = heap_score (scores, idx);
  const double new_score = old_score + scores->increment;
  LOG ("bumping score of variable %u to %g", idx, new_score);
  update_heap (solver, scores, idx, new_score);
  if (new_score > 1e150)
    rescore_scores (solver, scores);
}

static void
bump_score_increment (struct satch *solver)
{
  struct heap *scores = get_scores (solver);
  scores->increment *= scores->factor;
  LOG ("new score increment %g", scores->increment);
}

#endif

/*------------------------------------------------------------------------*/
#endif
/*------------------------------------------------------------------------*/

// The solver can keep a 'capacity' of allocated variables larger than the
// number 'size' of added variables.  This capacity increases exponentially
// and avoids costly resizing operations of data structures during API
// usage. In stand-alone solver usage the number of variables is fixed and
// thus can be pre-allocated by 'satch_reserve', which avoids any resizing.
// This strategy can of course also be followed through the API if the user
// has a reasonable bound on the number of needed variables.

// This whole section of the code can be simplified substantially if we
// could assume a fixed number of variables, which is unfortunately is not
// possible for incremental SAT solving.  We went through the effort to work
// out this resizing logic even though the solver is not incremental yet, as
// currently the API only allows one call to 'satch_solve'.

// There are no global data structures. Thus multiple solvers can exist at
// the same in the same process and clauses can be added incrementally
// without forcing the user to define a maximum variable up-front.

// In principle we could use an unsigned stack for the trail but we can also
// just pre-allocate it, since it will never contain more literals than the
// number of variables.  In 'C' this allocation will not necessarily occupy
// real memory (in terms of resident set size) even for large instances,
// since for instance Linux would just map those allocated pages to real
// pages on demand.  The pre-allocated trail makes the related code in
// 'assign' and 'boolean_constraint_propagation' more efficient.

static void
resize_trail (struct trail *trail, size_t new_capacity)
{
  assert (new_capacity);
  const size_t size = SIZE (*trail);
  const size_t bytes = new_capacity * sizeof (unsigned);
  const unsigned propagate = trail->propagate - trail->begin;
  trail->begin = realloc (trail->begin, bytes);
  if (!trail->begin)
    out_of_memory (bytes);
  trail->end = trail->begin + size;
  trail->propagate = trail->begin + propagate;
}

// Here we increase the capacity, i.e.,  the number of allocated data in
// terms of allocated variables, while 'increase_size' might just activate
// this data to be used if the number of variables increases (the 'size' of
// the solver) but stays below the allocated capacity.  In case you have not
// noted this use of 'size' and 'capacity' follows the same terminology as
// for 'std::vector' in the C++ standard template library

static void
increase_capacity (struct satch *solver, unsigned new_capacity)
{
  const unsigned old_capacity = solver->capacity;
  LOG ("increasing capacity from %u to %u", old_capacity, new_capacity);
  assert (old_capacity < new_capacity);
  assert (new_capacity <= 1u << 31);
  RESIZE_ZERO_INITIALIZED (2, solver->watches, 0);
  RESIZE_ZERO_INITIALIZED (1, solver->reasons, 0);
  RESIZE_ZERO_INITIALIZED (1, solver->levels, 0);
  RESIZE_ZERO_INITIALIZED (2, solver->values, 0);
#ifndef NSAVE
  RESIZE_ZERO_INITIALIZED (1, solver->saved, 0);
#endif
#ifndef NTARGET
  RESIZE_ZERO_INITIALIZED (1, solver->targets, 0);
#endif
#ifndef NBEST
  RESIZE_ZERO_INITIALIZED (1, solver->bests, 0);
#endif
  RESIZE_ZERO_INITIALIZED (1, solver->marks, 0);
#ifndef NACTIVE
  RESIZE_ZERO_INITIALIZED (1, solver->active, 0);
#endif
  RESIZE_ZERO_INITIALIZED (1, solver->frames, 1);
  resize_trail (&solver->trail, new_capacity);

#ifndef NQUEUE
#ifndef NQUEUE0
  if (solver->queue[0].size)
    resize_queue (&solver->queue[0], new_capacity);
#else
  assert (!solver->queue[0].links);
#endif
#ifndef NQUEUE1
  if (solver->queue[1].size)
    resize_queue (&solver->queue[1], new_capacity);
#else
  assert (!solver->queue[1].links);
#endif
#endif

#ifndef NHEAP
#ifndef NHEAP0
  if (solver->scores[0].size)
    resize_heap (&solver->scores[0], old_capacity, new_capacity);
#else
  assert (!solver->scores[0].begin);
#endif
#ifndef NHEAP1
  if (solver->scores[1].size)
    resize_heap (&solver->scores[1], old_capacity, new_capacity);
#else
  assert (!solver->scores[1].begin);
#endif
#endif

  solver->capacity = new_capacity;
}

// This function activates all variables with index 'old_size' until
// 'new_size-1'.   After calling this function there are 'new_size' active
// variables (except for already root-level assigned variables).

static void
increase_size (struct satch *solver, unsigned new_size)
{
#if !defined(NDEBUG) || defined(NACTIVE)
  const unsigned old_size = solver->size;
  assert (solver->size < new_size);
#endif
  const unsigned old_capacity = solver->capacity;
  assert (new_size <= 1u << 31);
  if (new_size > old_capacity)
    {
      unsigned new_capacity;
      if (new_size > 1u << 30)
	new_capacity = 1u << 31;	// Maximum capacity reached.
      else
	{
	  // Otherwise pick as 'new_capacity' the smallest power of two
	  // larger than 'new_size'.  This ensures a geometric increase.

	  assert (old_capacity <= 1u << 30);
	  new_capacity = 1;

	  while (new_size > new_capacity)
	    {
	      assert (new_capacity <= 1u << 30);
	      new_capacity *= 2;
	    }
	}
      increase_capacity (solver, new_capacity);
    }
  assert (new_size <= solver->capacity);
  LOG ("increase solver size form %u to %u", old_size, new_size);
  solver->size = new_size;
#ifdef NACTIVE
  const unsigned delta = new_size - old_size;
  solver->unassigned += delta;
  solver->statistics.active += delta;
#endif
}

/*------------------------------------------------------------------------*/

// Checks whether the imported clause contains a literal and its negation.
// If this is not the case this function also removes duplicated literals.

static bool
imported_clause_trivial_or_satisfied (struct satch *solver)
{
  assert (!solver->level);
  const unsigned *const end_clause = solver->clause.end;
  unsigned *const begin_clause = solver->clause.begin;
  unsigned *q = begin_clause;
  bool trivial = false;
  signed char *const marks = solver->marks;
  const signed char *const values = solver->values;
  for (const unsigned *p = begin_clause; p != end_clause; p++)
    {
      const unsigned lit = *p;
      const signed value = values[lit];
      if (value < 0)
	{
	  LOG ("skipping falsified literal %u", lit);
	  continue;
	}
      if (value > 0)
	{
	  LOG ("found satisfied literal %u", lit);
	  trivial = true;
	  break;
	}
      const unsigned idx = INDEX (lit);
      signed char prev = marks[idx];
      const signed char mark = INT_SIGN (lit);
      if (mark < 0)
	prev = -prev;
      if (prev > 0)
	{
	  LOG ("skipping duplicated literal %u", lit);
	  continue;
	}
      if (prev < 0)
	{
	  LOG ("clause contains both literal %u and its negation %u",
	       NOT (lit), lit);
	  trivial = true;
	  break;
	}
      *q++ = lit;
      marks[idx] = mark;
    }
  solver->clause.end = q;
  for (const unsigned *p = begin_clause; p != q; p++)
    marks[INDEX (*p)] = 0;
  return trivial;
}

/*------------------------------------------------------------------------*/

// The 'import logic' follows the description above:
//
// 'elit' signed external literal (as in API and DIMACS format)
// 'eidx' signed external variable index (in the range '1...INT_MAX')
// 'iidx' unsigned internal variable index (in the range '0...(INT_MAX-1)')
// 'ilit' unsigned internal literal (in the range '0...2*(INT_MAX-1)+1')

static unsigned
import_literal (struct satch *solver, int elit)
{
  assert (elit);
  assert (elit != INT_MIN);	// Otherwise '-elit' might be undefined.
  const int eidx = abs (elit);
  const unsigned iidx = eidx - 1;
  if (iidx >= solver->size)
    increase_size (solver, iidx + 1);
  unsigned ilit = LITERAL (iidx);
  if (elit < 0)
    ilit = NOT (ilit);
  LOG ("imported external literal %d as internal literal %u", elit, ilit);
  return ilit;
}

/*------------------------------------------------------------------------*/

// Estimate the number of cache lines spanning the given array.  We could
// use the numerical vales of the 'begin' and 'end' pointers of the array
// but that would make the code dependent on memory addresses which should
// be avoided.  Therefore we fall back to an estimation, which in essence
// assumes that the start address is cache-line-size aligned.

// Typical size of a cache line is 128 bytes, but even if your processor has
// less or more, this computation is anyhow just a rough estimate and by
// making it machine independent we keep the scheduling of for instance the
// focused and stable phases and thus the whole solver execution also
// machine independent (does not vary for different cache-line size).

#define log2_bytes_per_cache_line	7
#define bytes_per_cache_line		(1u << log2_bytes_per_cache_line)

static inline size_t
cache_lines (const void *begin, const void *end)
{
  assert (begin <= end);
  const size_t round = bytes_per_cache_line - 1;
  const size_t bytes = (char *) end - (char *) begin;
  const size_t res = (bytes + round) >> log2_bytes_per_cache_line;
  return res;
}

/*------------------------------------------------------------------------*/

// Propagating a literal over the clauses in which it occurs negatively,
// more precisely for which its negation is watched, is the hot-spot of
// CDCL solving.  This is further pronounced by learning many long clauses.   

static struct clause *
propagate_literal (struct satch *solver, unsigned lit)
{
  LOG ("propagating %u", lit);

  const unsigned not_lit = NOT (lit);
  struct watches *const watches = solver->watches + not_lit;
  signed char *const values = solver->values;

  // We traverse all the watches of the literal 'not_lit' and remove those
  // for which we stop watching the clause (since we found a replacement).
  // The updated watches pointers 'q' follows the traversal pointer 'p'.

  union watch *q = watches->begin;
  const union watch *p = q;

  struct clause *conflict = 0;

  const union watch *const end_watches = watches->end;

  // By counting 'tick's we approximate the number of cache lines read in
  // 'propagation' only focusing on accessing memory of watch stacks,
  // then mainly watches and clause memory.  We do not take into account
  // assigning a variable nor reading assigned values.

  // Since the size of watches differs with and without 'NVIRTUAL' defined,
  // the size of the accessed memory changes too which in turn changes when
  // switching from stable mode back to focused mode happens.  However,
  // completely avoiding this discrepancy would also require to sort reason
  // literals of binary clauses in order to avoid different traversal during
  // conflict analysis.  It also changes when compiling on a 32-bit machine.
  // Furthermore it is pretty difficult to keep the same behaviour with and
  // without blocking literals (avoiding different watch replacement).

  uint64_t ticks = 1 + cache_lines (q, end_watches);

  while (!conflict && p != end_watches)
    {
#ifndef NBLOCK
      const union watch watch = *q++ = *p++;	// Keep header by default.
      const struct header header = watch.header;
      const unsigned blocking_lit = header.blocking;
      const signed char blocking_value = values[blocking_lit];

      // There is dedicated code for propagating over binary clauses.  With
      // the blocking literal stored in the watcher-stack there is no need
      // to access the actual binary clauses here.

      if (header.binary)
	{
	  if (blocking_value < 0)
	    {
	      conflict = binary_clause (solver, not_lit, blocking_lit);
	      LOGCLS (conflict, "conflicting");
	    }
	  else if (!blocking_value)
	    {
	      assert (!blocking_value);
	      assign (solver, blocking_lit, binary_reason (not_lit));
	      ticks++;
	    }
#ifdef NVIRTUAL
	  *q++ = *p++;		// Copy clause too.
#endif
	  continue;
	}
      else
#endif
	// Handle larger non-binary clause in case blocking literals are
	// enabled or both cases (binary and non-binary clauses) if they are.
	{
	  struct clause *clause = (*q++ = *p++).clause;	// Copy clause.
	  assert (!clause->garbage);
#ifndef NBLOCK
	  if (blocking_value > 0)
	    continue;
#endif
	  unsigned *const literals = clause->literals;

	  // At this point we have to access the large clause. This is the
	  // real hot-spot of the solver.  Up-to 80% of the time can be
	  // spent here in the first pointer access without the blocking
	  // literal idea (and specialized binary clause propagation above).
	  // In the source code below with the assertions above disabled the
	  // first pointer access would be accessing the first literal
	  // 'literals[0]' of the clause.  The main purpose of the 'blocking
	  // literal' idea is to reduce the need for this costly pointer
	  // dereference as much as possible.

	  ticks++;		// We count these accesses.

	  // The two watched literals of a clause are stored as first two
	  // literals but we do not know at which position.  In order to
	  // avoid introducing a 'branch' (if-then-else) we simply use the
	  // trick to compute the XOR of the first two literals and the
	  // watched literal 'not_lit', which gives the other literal.

	  const unsigned other = literals[0] ^ literals[1] ^ not_lit;
	  const signed char other_value = values[other];

	  // Another common situation is that the other watched literal in
	  // that clause is different from the blocking literal, but is
	  // assigned true.  Then we also can stop here after updating the
	  // blocking literal for this watch to this other literal.

	  if (other_value > 0)
	    {
#ifndef NBLOCK
	      q[-2].header.blocking = other;
#endif
	      continue;
	    }

	  // Normalize the position where 'not_lit' sits to position '1'.

	  literals[0] = other;
	  literals[1] = not_lit;

	  const unsigned size = clause->size;
	  const unsigned *const end_literals = literals + size;

	  // Now search for a non-false ('true' or unassigned) replacement
	  // for the watched literal 'not_lit' starting with the third.

	  unsigned replacement = INVALID;
	  signed char replacement_value = -1;
	  const unsigned *end_search = end_literals;
	  unsigned *start_search = literals + 2, *r;
#ifndef NCACHE
	  // Use and remember the old offset were we found a replacement
	  // watch or a satisfied blocking literal and resume next search of
	  // replacement literals in this clause at that position (relative
	  // to 'literals + 2').
	  start_search += clause->search;
#endif
	  for (r = start_search; r != end_search; r++)
	    {
	      replacement = *r;
	      replacement_value = values[replacement];
	      if (replacement_value >= 0)
		break;
	    }
#ifndef NCACHE
	  if (replacement_value < 0)
	    {
	      end_search = start_search;
	      start_search = literals + 2;

	      for (r = start_search; r != end_search; r++)
		{
		  replacement = *r;
		  replacement_value = values[replacement];
		  if (replacement_value >= 0)
		    {
		      clause->search = r - start_search;
		      break;
		    }
		}
	    }
	  else
	    clause->search = r - start_search;
#endif
	  if (replacement_value > 0)	// Replacement literal true.
	    {
#ifndef NBLOCK
	      // Update blocking literal only.

	      q[-2].header.blocking = replacement;
#endif
	    }
	  else if (!replacement_value)	// Replacement literal unassigned.
	    {
	      // First log the untouched clause, then stop watching the
	      // originally watched literal by simply 

	      LOGCLS (clause, "unwatching %u in", not_lit);
	      q -= long_clause_watch_size;

	      // Swap watched literal with its replacement.

	      literals[1] = replacement;
	      *r = not_lit;

	      watch_literal (solver, replacement, other, clause);
	      ticks++;
	    }
	  else if (other_value)
	    // Clause conflicting, since all literals are false!
	    {

	      assert (other_value < 0);
	      LOGCLS (clause, "conflicting");
	      conflict = clause;
	    }
	  else
	    // All literals of the clause are  false except 'other' which is
	    // unassigned and thus is now assigned.
	    {
	      assert (!other_value);
	      assign (solver, other, clause);
	      ticks++;
	    }
	}
    }

  ADD (ticks, ticks);

  // After a conflicting clause is found we break out of the propagation but
  // then still need to copy the rest of the watches.

  while (p != end_watches)
    *q++ = *p++;
  watches->end = q;

  return conflict;
}

// While the previous function propagates the assignment of one literal, the
// process of "Boolean Constraint Propagation" (BCP) implemented in the next
// function propagates all assigned literals until a conflict is found or
// all have been propagated.  Note that propagation of a literal might
// produce new assigned literals (beside finding conflicting clauses) and
// thus the following loop can be seen as breadth-first search over the unit
// implied literals of the current assignment.

static struct clause *
boolean_constraint_propagation (struct satch *solver)
{
  struct trail *trail = &solver->trail;
  unsigned *propagate = trail->propagate;
  unsigned *p;

  assert (trail->begin <= propagate);
  assert (propagate <= trail->begin + VARIABLES);

  struct clause *conflict = 0;

  for (p = propagate; !conflict && p != trail->end; p++)
    conflict = propagate_literal (solver, *p);

  solver->trail.propagate = p;
  const unsigned propagated = p - propagate;

  ADD (propagations, propagated);
  ADD (conflicts, !!conflict);	// Add '1' if there is a conflict.

  return conflict;
}

/*------------------------------------------------------------------------*/

// Update target and best-phases after from a consistent trail.  The user
// has to make sure that the trail is consistent though.  For instance in
// conflict analysis we first have to backtrack one level.

#ifndef NTARGET

static void
save_phases (struct satch *solver, signed char *phases)
{
  const signed char *end = solver->values + VARIABLES;
  signed char *q = phases, tmp;
  for (const signed char *p = solver->values; p != end; p++, q++)
    if ((tmp = *p))
      *q = tmp;
}

static void
update_target_phases (struct satch *solver, const unsigned size_trail)
{
  const uint64_t targets = INC (targets);
  save_phases (solver, solver->targets);
  solver->target = size_trail;
  message (solver, 3, "target", targets, "targeting %u variables "
	   "%.0f%% after %" PRIu64 " conflicts", size_trail,
	   percent (size_trail, solver->statistics.active), CONFLICTS);
}

#ifndef NBEST

static void
update_best_phases (struct satch *solver, const unsigned size_trail)
{
  const uint64_t bests = INC (bests);
  save_phases (solver, solver->bests);
  solver->best = size_trail;
  message (solver, 3, "best", bests, "best trail %u variables "
	   "%.0f%% after %" PRIu64 " conflicts", size_trail,
	   percent (size_trail, solver->statistics.active), CONFLICTS);
}

#endif

static void
update_phases (struct satch *solver)
{
  assert (solver->stable);
  struct trail *trail = &solver->trail;
  const unsigned size_trail = SIZE (*trail);
  if (size_trail > solver->target)
    update_target_phases (solver, size_trail);
#ifndef NBEST
  if (size_trail > solver->best)
    update_best_phases (solver, size_trail);
#endif
}

#endif

/*------------------------------------------------------------------------*/

// Backtrack to a certain decision level.   This in essence just unassigns
// the literals assigned on higher decision level.  Resets the decision
// level and the propagation pointer.  It becomes more complicated since we
// need to push back unassigned variables back to the binary heap for
// (E)VSIDS or update the search index for the VMTF queue.  Third if clause
// learning is disabled ('NLEARN' defined), then learned clauses are only
// used for computing scores and back-jumping and during backtracking have
// to be deleted.

static void
backtrack (struct satch *solver, unsigned new_level)
{
  LOG ("backtracking to level %u", new_level);
  assert (new_level < solver->level);
  const unsigned *levels = solver->levels;
  signed char *values = solver->values;

#ifndef NQUEUE
  struct queue *queue = 0;
  const struct link *links = 0;
  unsigned search = INVALID;
  unsigned max_stamp = INVALID;
#ifndef NHEAP
  if (!solver->stable)
#endif
    {
      queue = get_queue (solver);
      links = queue->links;
      search = queue->search;
      max_stamp = search == INVALID ? 0 : links[search].stamp;
    }
#endif

#ifndef NHEAP
  struct heap *scores = 0;
  const unsigned *pos = 0;
#ifndef NQUEUE
  if (solver->stable)
#endif
    {
      scores = get_scores (solver);
      pos = scores->pos;
    }
#endif

#ifdef NLEARN
  struct clause *const *const reasons = solver->reasons;
#endif

  struct trail *trail = &solver->trail;
  while (!EMPTY (*trail))
    {
      const unsigned lit = TOP (*trail);
      const unsigned idx = INDEX (lit);
      const unsigned lit_level = levels[idx];
      if (lit_level == new_level)
	break;

      (void) POP (*trail);
      LOG ("unassign %u", lit);
      assert (solver->unassigned < solver->size);
      solver->unassigned++;

      const unsigned not_lit = NOT (lit);
      assert (values[lit] > 0);
      assert (values[not_lit] < 0);
      values[lit] = 0;
      values[not_lit] = 0;
#ifdef NLEARN
      struct clause *reason = reasons[idx];
      if (reason &&
#ifndef NBLOCK
	  !is_binary_reason (reason) &&
#endif
	  reason->redundant)
	(void) delete_clause (solver, reason);
#endif
#ifndef NQUEUE
      if (links)
	{
	  const unsigned stamp = links[idx].stamp;
	  if (stamp > max_stamp)
	    search = idx, max_stamp = stamp;
	}
#endif
#ifndef NHEAP
      if (pos && pos[idx] == INVALID)
	push_heap (solver, scores, idx);
#endif
    }
#ifndef NQUEUE
  if (queue)
    {
      LOG ("searched variable index %u", search);
      queue->search = search;
    }
#endif
  solver->trail.propagate = trail->end;
  solver->level = new_level;
}

/*------------------------------------------------------------------------*/

// We have fast and slow moving exponential averages all updated during
// conflicting clause analysis.  The slow moving averages are biased
// towards their initial value (zero) and we use a method described in the
// literature (the well known ADAM machine learning paper) to correct the
// bias by multiplying with '1/(1-beta^n)' where 'beta = 1 - alpha' and
// 'alpha' is the smoothing factor (decay) and 'n' is the number of updates
// to the exponential moving average.  The 'alpha's are defined above as
// macros since some compilers will otherwise not allow the following line.

const double slow_beta = 1.0 - slow_alpha;

// We have two sets of independent averages for stable and focused mode.
// During mode switching the 'stable' bit is flipped which makes the other
// set of averages active.  However if stable mode is disabled we only have
// one set of averages and only update and use that.  To hide this logic we
// use the following function which returns the active set of averages.

static struct averages *
averages (struct satch *solver)
{
  return solver->averages + solver->stable;
}

static void
update_slow_average (double *average, unsigned value)
{
  *average += slow_alpha * (value - *average);
}

static double
unbiased_slow_average (struct averages *a, double avg)
{
  const double div = 1 - a->slow_exp;
  return !div ? 0 : div == 1 ? avg : avg / div;
}

#ifndef NRESTART

// Only 'restarting' needs a fast moving average ('fast_glue').

const double fast_beta = 1.0 - fast_alpha;

static void
update_fast_average (double *average, unsigned value)
{
  *average += fast_alpha * (value - *average);
}

static double
unbiased_fast_average (struct averages *a, double avg)
{
  const double div = 1 - a->fast_exp;
  return !div ? 0 : div == 1 ? avg : avg / div;
}

#endif

// We assume that all fast and slow moving averages are updated at the same
// time and then just update 'beta^n' for both too (even though there is a
// fast one and a slow one).

static void
update_betas (struct satch *solver)
{
  struct averages *a = averages (solver);
#ifndef NRESTART
  if (a->fast_exp)
    a->fast_exp *= fast_beta;
#endif
  if (a->slow_exp)
    a->slow_exp *= slow_beta;
}

static void
init_one_set_of_averages (struct averages *a)
{
  a->slow_exp = 1.0;
#ifndef NRESTART
  a->fast_exp = 1.0;
#endif
}

static void
init_averages (struct satch *solver)
{
  for (int i = 0; i < 2; i++)
    init_one_set_of_averages (&solver->averages[i]);
}

/*------------------------------------------------------------------------*/

// Conflict clause minimization is implemented here.

#define SEEN 1			// Literal seen during conflict analysis.

#ifndef NMINIMIZE

#define POISONED 2		// Literal can not be minimized.
#define REMOVABLE 4		// Literal can be be minimized.

static bool
minimize_literal (struct satch *solver, unsigned lit, unsigned depth)
{
  const unsigned idx = INDEX (lit);
  signed char mark = solver->marks[idx];
  assert (mark >= 0);
  if (mark & POISONED)
    return false;		// Previously shown not to be removable.
  if (mark & REMOVABLE)
    return true;		// Previously shown to be removable.
  if (depth && (mark & SEEN))
    return true;		// Analyzed thus removable (unless start).
  if (depth > minimize_depth)
    return false;		// Avoids deep recursion (stack overflow).
  assert (solver->values[lit] < 0);
  struct clause *reason = solver->reasons[idx];
  if (!reason)
    return false;		// Decisions can not be removed.
  const unsigned not_lit = NOT (lit);
  const unsigned level = solver->levels[idx];
  if (!level)
    return true;		// Root-level units can be removed.
  if (!solver->frames[level])
    return false;		// Decision level not pulled into clause.
#ifndef NBLOCK
  if (is_binary_reason (reason))
    reason = binary_reason_to_clause (solver, not_lit, reason);
  else
#endif
    INC (ticks);
  LOGCLS (reason, "trying to remove %u at depth %u along", lit, depth);
  bool res = true;
  for (all_literals_in_clause (other, reason))
    {
      if (other == not_lit)
	continue;
      if (minimize_literal (solver, other, depth + 1))
	continue;
      LOG ("could not remove literal %u", other);
      res = false;
      break;
    }
  if (depth)
    {
      mark |= (res ? REMOVABLE : POISONED);
      solver->marks[idx] = mark;
      PUSH (solver->marked, idx);
    }
  LOG ("removing %u at depth %u %s",
       lit, depth, res ? "succeeded" : "failed");
  return res;
}

static void
minimize_deduced_clause (struct satch *solver)
{
  assert (EMPTY (solver->marked));

  const unsigned *const end = solver->clause.end;
  unsigned *q = solver->clause.begin + 1;

  for (const unsigned *p = q; p != end; p++)
    {
      const unsigned lit = *p;
      LOG ("trying to minimize literal %u", lit);
      if (minimize_literal (solver, lit, 0))
	LOG ("minimized literal %u", lit);
      else
	*q++ = lit;
    }

  const size_t minimized = end - q;
  solver->clause.end = q;

  LOG ("minimized %zu literals", minimized);
  ADD (minimized, minimized);

  for (all_elements_on_stack (unsigned, idx, solver->marked))
      solver->marks[idx] &= SEEN;

  CLEAR (solver->marked);
}

#endif

/*------------------------------------------------------------------------*/

// Mark a literal as 'seen' if it has not been seen yet during conflict
// analysis (or during reason-side-bumping).  Since the 'analyze' function
// below needs the assignment level of the literal to pull in decision
// levels and decide on which literals to put in the learned clause we use
// that level as return value or 'INVALID' as result if the literal has
// been marked before (or has been assigned on the root-level zero).

// The additional pointer arguments are available through 'solver', but we
// pass them explicitly to make sure that the compiler knows that these
// fields did not change (except for 'links' which is zero if we do not need
// to sort the analyzed literals later).

static inline unsigned
analyze_literal (struct satch *solver, const unsigned *const levels,
		 signed char *const marks, unsigned lit)
{
  const unsigned idx = INDEX (lit);
  const unsigned lit_level = levels[idx];
  if (!lit_level)
    return INVALID;
  const signed char mark = marks[idx];
  assert (!mark || mark == SEEN);
  if (mark)
    return INVALID;
  marks[idx] = SEEN;
  struct analyzed analyzed;
  analyzed.idx = idx;
#ifndef NSORT
  analyzed.stamp = INVALID;
#endif
  PUSH (solver->seen, analyzed);
  LOG ("analyzing literal %u", lit);
  return lit_level;
}

/*------------------------------------------------------------------------*/

// Bumping reason side literals was introduced in the Maple solvers in 2016.
// The idea is to also bump the literals in the reasons of those literals in
// the learned clauses.  It seems that using target phases during stable
// mode really needs this technique in order to be effective (and the same
// applied to rephasing to best-phases and probably rephasing in general).

#ifndef NREASONS

static inline void
bump_reason_side_literals (struct satch *solver,
			   struct clause *const *const reasons,
			   const unsigned *const levels,
			   signed char *const marks)
{
  struct averages *a = averages (solver);
  if (unbiased_slow_average (a, a->decision_rate) >=
      bump_reason_decision_rate_limit)
    return;

  for (all_elements_on_stack (unsigned, lit, solver->clause))
    {
      const unsigned idx = INDEX (lit);
      struct clause *reason = reasons[idx];
#ifndef NBLOCK
      if (is_binary_reason (reason))
	reason = binary_reason_to_clause (solver, NOT (lit), reason);
#endif
      if (!reason)
	continue;
      for (all_literals_in_clause (other, reason))
	if (analyze_literal (solver, levels, marks, other) != INVALID)
	  INC (reasons);
    }
}

#endif

/*------------------------------------------------------------------------*/

// Sorting the analyzed variable indices to be bumped with respect to their
// stamp makes sure that they keep the same relative order after bumping
// which empirically improves the effectiveness of the decision heuristic
// (less conflicts).  You can disable this optimization at run-time by
// configuring with './configure --no-sorting'.  By default
// 'NSORT' is undefined and thus this sorting heuristic is used.

#ifndef NSORT

// Comparison function for 'qsort' to sort variable indices by stamp time.

static int
cmp_analyzed (const void *p, const void *q)
{
  const struct analyzed *a = p, *b = q;
  unsigned s = a->stamp, t = b->stamp;
  return (s < t) ? -1 : 1;
}

static void
add_stamps (struct satch *solver)
{
  struct queue *queue = get_queue (solver);
  const struct link *const links = queue->links;
  const struct analyzed *const end = solver->seen.end;
  struct analyzed *const begin = solver->seen.begin;
  for (struct analyzed * p = begin; p != end; p++)
    p->stamp = links[p->idx].stamp;
}

static void
sort_analyzed (struct satch *solver)
{
  add_stamps (solver);
  qsort (solver->seen.begin, SIZE (solver->seen),
	 sizeof (struct analyzed), cmp_analyzed);
}

#endif

/*------------------------------------------------------------------------*/

static bool
analyze_conflict (struct satch *solver, struct clause *conflict)
{
  assert (!solver->inconsistent);

  assert (EMPTY (solver->clause));	// Clause learned.

  const unsigned conflict_level = solver->level;
  if (!conflict_level)
    {
      LOG ("learned empty clause");
      solver->inconsistent = true;
      if (solver->proof)
	add_internal_clause_to_proof (solver);
#ifndef NDEBUG
      checker_add_learned_clause (solver->checker);
#endif
      return false;
    }

  assert (EMPTY (solver->blocks));	// Decision levels analyzed.
  assert (EMPTY (solver->seen));	// Analyzed literals.

  PUSH (solver->clause, INVALID);	// Reserve room for 1st UIP.

  signed char *const marks = solver->marks;
  const unsigned *const levels = solver->levels;
  struct clause *const *const reasons = solver->reasons;
  signed char *frames = solver->frames;

  struct clause *reason = conflict;

  const unsigned *t = solver->trail.end;
  unsigned unresolved_on_current_level = 0;
  unsigned uip = INVALID;

  uint64_t ticks = 0;

  for (;;)
    {
      assert (reason);
      LOGCLS (reason, "analyzing");
#ifndef NUSED
#ifndef NBLOCK
      if (reason != &solver->binary)
#endif
	{
	  if (!reason->used)
	    reason->used = 1;
#ifndef NTIER2
	  else if (reason->glue <= tier2_glue_limit)
	    reason->used = 2;
#endif
	  ticks++;
	}
#endif
      for (all_literals_in_clause (lit, reason))
	{
	  if (lit == uip)
	    continue;
	  const unsigned lit_level =
	    analyze_literal (solver, levels, marks, lit);
	  if (lit_level == INVALID)
	    continue;
	  assert (solver->values[lit] < 0);
	  if (lit_level < conflict_level)
	    {
	      if (!frames[lit_level])
		{
		  LOG ("analyzing decision level %u", lit_level);
		  PUSH (solver->blocks, lit_level);
		  frames[lit_level] = 1;
		}
	      PUSH (solver->clause, lit);
	    }
	  else
	    unresolved_on_current_level++;
	}
      unsigned uip_idx;
      do
	{
	  assert (solver->trail.begin < t);
	  uip = *--t;
	}
      while (!marks[uip_idx = INDEX (uip)]);
      if (!--unresolved_on_current_level)
	break;
      reason = reasons[uip_idx];
#ifndef NBLOCK
      if (is_binary_reason (reason))
	reason = binary_reason_to_clause (solver, uip, reason);
#endif
    }
  assert (uip != INVALID);
  LOG ("1st unique implication point %u", uip);
  const unsigned not_uip = NOT (uip);
  ACCESS (solver->clause, 0) = not_uip;
  ADD (ticks, ticks);

  LOGTMP ("deduced");
  unsigned size = SIZE (solver->clause);
  ADD (deduced, size);
  assert (size);

#ifndef NMINIMIZE
  minimize_deduced_clause (solver);
  LOGTMP ("minimized");
  size = SIZE (solver->clause);
#endif

  const unsigned glue = SIZE (solver->blocks);
  unsigned jump_level = 0;
  for (all_elements_on_stack (unsigned, lit_level, solver->blocks))
    {
      frames[lit_level] = 0;
      if (lit_level != conflict_level && jump_level < lit_level)
	jump_level = lit_level;
    }
  CLEAR (solver->blocks);

  {
    struct averages *a = averages (solver);
#ifndef NRESTART
    update_fast_average (&a->fast_glue, glue);
#endif
    update_slow_average (&a->slow_glue, glue);
    update_slow_average (&a->conflict_level, conflict_level);
    {
      const uint64_t decisions = DECISIONS;
      const uint64_t delta_decisions = decisions - a->saved_decisions;
      a->saved_decisions = decisions;
      update_slow_average (&a->decision_rate, delta_decisions);
    }
    {
      double trail_filled = percent (SIZE (solver->trail),
				     solver->statistics.active);
      update_slow_average (&a->trail_filled, trail_filled);
    }
    update_betas (solver);

    LOG ("determined jump level %u and glue %u", jump_level, glue);
    LOG ("exponential 'conflict_level' moving average %g",
	 unbiased_slow_average (a, a->conflict_level));
#ifndef NRESTART
    LOG ("exponential 'fast_glue' moving average %g",
	 unbiased_fast_average (a, a->fast_glue));
#endif
    LOG ("exponential 'slow_glue' moving average %g",
	 unbiased_slow_average (a, a->slow_glue));
  }

#ifndef NREASONS
  bump_reason_side_literals (solver, reasons, levels, marks);
#endif

#ifndef NSORT
#ifndef NVSIDS
  if (!solver->stable)
#endif
    sort_analyzed (solver);	// Sort analyzed variables wrt time stamp.
#endif

  for (all_elements_on_stack (struct analyzed, analyzed, solver->seen))
    {
      const unsigned idx = analyzed.idx;
#ifndef NBUMP
      INC (bumped);
#if defined(NVMTF) || defined(NQUEUE)
      bump_variable_score (solver, idx);
#elif defined(NVSIDS) || defined(NHEAP)
      move_variable_to_front (solver, idx);
#else
      if (solver->stable)
	bump_variable_score (solver, idx);
      else
	move_variable_to_front (solver, idx);
#endif
#endif
      assert (marks[idx]);
      marks[idx] = 0;
    }
  CLEAR (solver->seen);

#ifndef NVSIDS
#ifndef NSWITCH
  if (solver->stable)
#endif
    bump_score_increment (solver);
#endif
  if (solver->proof)
    add_internal_clause_to_proof (solver);

#ifndef NDEBUG
  for (all_elements_on_stack (unsigned, lit, solver->clause))
      checker_add_literal (solver->checker, export_literal (lit));
  checker_add_learned_clause (solver->checker);
#endif

#ifndef NTARGET
  assert (solver->level);
  backtrack (solver, solver->level - 1);
  if (solver->stable)
    update_phases (solver);
  if (jump_level < solver->level)
#endif
    backtrack (solver, jump_level);

  if (size == 1)		// Learned a unit clause.
    {
      assert (!jump_level);
      solver->iterate = true;
      assign (solver, not_uip, 0);
    }
#ifndef NVIRTUAL
  else if (size == 2)
    {
      const unsigned other = ACCESS (solver->clause, 1);
      LOGBIN (true, not_uip, other, "learned");
#ifndef NLEARN
      new_binary (solver, true);
#endif
      ADD (learned, 2);
      struct clause *reason = binary_reason (other);
      assign (solver, not_uip, reason);
    }
#endif
  else
    {
      assert (size > 1);	// Learned and at least binary clause.
      assert (jump_level > 0);

      // First literal at jump-level becomes other watch.  Such a literal
      // has to exist and thus the 'break' below has to be hit.  We further
      // rely on backtracking not to reset the level of unassigned literals.

      for (unsigned *p = solver->clause.begin + 1, *q = p;; q++)
	{
	  assert (q != solver->clause.end);
	  const unsigned lit = *q, level = levels[INDEX (lit)];
	  assert (level <= jump_level);
	  if (level == jump_level)
	    {
	      *q = *p;
	      *p = lit;
	      break;
	    }
	}

      struct clause *learned = new_redundant_clause (solver, glue);
#ifndef NUSED
#ifndef NTIER2
      if (glue <= tier2_glue_limit)
	learned->used = 2;
      else
#endif
	learned->used = 1;
#endif
      LOGCLS (learned, "learned");
      ADD (learned, size);
#ifndef NLEARN
      watch_clause (solver, learned);
#endif
      assign (solver, not_uip, learned);
    }

  CLEAR (solver->clause);

  return true;
}

/*------------------------------------------------------------------------*/

#ifndef NQUEUE

static unsigned
max_stamped_unassigned_variable_on_decision_queue (struct satch *solver)
{
  struct queue *queue = get_queue (solver);
  const struct link *const links = queue->links;
  const signed char *const values = solver->values;

  unsigned idx = queue->search;

  for (;;)
    {
      assert (idx != INVALID);
      const unsigned lit = LITERAL (idx);
      const signed char value = values[lit];
      if (!value)
	break;
      idx = links[idx].prev;
    }
  queue->search = idx;		// Cache search position.

  LOG ("maximum stamped unassigned variable %u with stamp %u",
       idx, links[idx].stamp);

  return idx;
}

#endif

#ifndef NHEAP

static unsigned
max_score_unassigned_variable_on_binary_heap (struct satch *solver)
{
  const signed char *const values = solver->values;
  struct heap *scores = get_scores (solver);

  unsigned idx;

  for (;;)
    {
      idx = max_heap (scores);
      const unsigned lit = LITERAL (idx);
      const signed char value = values[lit];
      if (!value)
	break;
      pop_heap (solver, scores);
    }

  LOG ("maximum score unassigned variable %u with score %g",
       idx, scores->score[idx]);

  return idx;
}

#endif

/*------------------------------------------------------------------------*/

// Flush unit clauses from trail after root-level propagation.  Otherwise
// the statistics of the saved trail become incorrect.

static void
flush_units (struct satch *solver)
{
  assert (!solver->level);
  assert (solver->trail.propagate == solver->trail.end);
  LOG ("flushing %zu root-level units on trail", SIZE (solver->trail));
  solver->trail.propagate = solver->trail.end = solver->trail.begin;
}

/*------------------------------------------------------------------------*/

// Decision variable heuristic uses exponential 'VSIDS' in stable mode and
// 'VMTF' in focused mode unless one of these heuristics is disabled.

static unsigned
decide_variable (struct satch *solver)
{
  unsigned idx;

#if defined(NHEAP)
  idx = max_stamped_unassigned_variable_on_decision_queue (solver);
#elif defined(NQUEUE)
  idx = max_score_unassigned_variable_on_binary_heap (solver);
#else
  if (solver->stable)
    idx = max_score_unassigned_variable_on_binary_heap (solver);
  else
    idx = max_stamped_unassigned_variable_on_decision_queue (solver);
#endif
  LOG ("decision variable %u", idx);

  return idx;
}

// The decision phase is the value assigned to the decision variable. In the
// default configuration we use 'phase saving', i.e., the previous assigned
// variable to that variable and fall back to the default phase 'true' for
// never assigned variables (unless 'NTRUE' is defined, where the default
// original phase value becomes 'false').  The default value is always
// picked if phase saving is disabled ('NSAVE' is defined).

static int
original_phase (void)
{
#ifndef NTRUE
  return 1;			// Default is 'true'.
#else
  return -1;			// Otherwise 'false' (if 'NTRUE').
#endif
}

static int
decide_phase (struct satch *solver, unsigned idx)
{
  signed char value = 0;
#ifndef NTARGET
  if (solver->stable)
    value = solver->targets[idx];
#endif
#ifndef NSAVE
  if (!value)
    value = solver->saved[idx];
#endif
  if (!value)
    value = original_phase ();
  LOG ("decision phase %d", (int) value);
  (void) idx;
  return value;
}

// Pick a decision variable and phase to which it is assigned as decision
// literal, increase decision level and assign the decision literal.

static void
decide (struct satch *solver)
{
  INC (decisions);

  assert (solver->unassigned);
  assert (!solver->inconsistent);
  assert (solver->level < solver->size);

  solver->level++;

  const unsigned idx = decide_variable (solver);
  const int value = decide_phase (solver, idx);

  const unsigned lit = LITERAL (idx);
  const unsigned decision = (value < 0 ? NOT (lit) : lit);
  LOG ("decision literal %u", decision);

  assign (solver, decision, 0);
}

/*------------------------------------------------------------------------*/

// Report verbose message lines listing the following statistics. We use the
// same trick as for signal handlers in 'main.c' and for profiles above of
// listing all different reported statistics as 'REPORT' item in 'REPORTS'.
// Then we redefine 'REPORT' to instantiate 'REPORTS' accordingly.

// *INDENT-OFF*

#define REPORTS \
REPORT(seconds, "%.2f") \
REPORT(MB, "%.0f") \
REPORT(level, "%.0f") \
REPORT_IF_REDUCE(reductions, "%" PRIu64) \
REPORT_IF_RESTART(restarts, "%" PRIu64) \
REPORT(rate, "%.0f") \
REPORT(conflicts, "%" PRIu64) \
REPORT_IF_LEARN(redundant, "%" PRIu64) \
REPORT(trail, "%.0f%%") \
REPORT(glue, "%.0f") \
REPORT(irredundant, "%" PRIu64) \
REPORT(variables, "%u") \
REPORT(remaining, "%.0f%%")

// Need to exclude 'restart' and 'reduce' reports if disabled.

#define DO_NO_REPORT(A,B) /**/
#ifdef NLEARN
#define REPORT_IF_LEARN DO_NO_REPORT
#else
#define REPORT_IF_LEARN REPORT
#endif
#ifdef NRESTART
#define REPORT_IF_RESTART DO_NO_REPORT
#else
#define REPORT_IF_RESTART REPORT
#endif
#ifdef NREDUCE
#define REPORT_IF_REDUCE DO_NO_REPORT
#else
#define REPORT_IF_REDUCE REPORT
#endif

#define MAX_HEADER      3	// Number of header lines.
#define MAX_LINE        256	// Maximum expected line length.
#define MAX_REPORTS     16	// Maximum number of reported values.

// *INDENT-ON*

static void
report (struct satch *solver, int type)
{
  if (!solver->options.verbose)
    return;

  INC (reported);

  // If you want to print a certain statistic you need to add a line to the
  // 'REPORTS' macro above but also define a matching local constant here.

  struct averages *a = averages (solver);
  const double seconds = process_time ();
  const double MB = current_resident_set_size () / (double) (1 << 20);
  const double level = unbiased_slow_average (a, a->conflict_level);
#ifndef NREDUCE
  const uint64_t reductions = solver->statistics.reductions;
#endif
#ifndef NRESTART
  const uint64_t restarts = solver->statistics.restarts;
#endif
  const double rate = unbiased_slow_average (a, a->decision_rate);
  const uint64_t conflicts = CONFLICTS;
#ifndef NLEARN
  const uint64_t redundant = solver->statistics.redundant;
#endif
  const double trail = unbiased_slow_average (a, a->trail_filled);
  const double glue = unbiased_slow_average (a, a->slow_glue);
  const uint64_t irredundant = solver->statistics.irredundant;
  const unsigned variables = solver->statistics.active;
  double remaining = percent (variables, solver->size);

  // Prepare

  int num_reported = 0;		// Number of reported values.

  int column[MAX_REPORTS];	// Save start of columns to format headers.
  char line[MAX_LINE];		// Actual line of values printed.
  int end_line = 0;		// End of the value line.

  line[end_line++] = 'c';

  // The value line has the following two characters less space than the
  // header lines which makes some room for the first header to stick out to
  // the left (this is also necessary for the 'seconds' header).

  line[end_line++] = ' ';
  line[end_line++] = type;

  // Print values to 'line' remembering starting positions and widths.

// *INDENT-OFF*

#define REPORT(NAME,FMT) \
  { \
    assert (end_line < MAX_LINE); \
    line[end_line++] = ' '; \
    column[num_reported++] = end_line; \
    char buffer[32]; \
    sprintf (buffer, FMT, NAME); \
    for (const char * p = buffer; *p; p++) \
      assert (end_line < MAX_LINE), \
      line[end_line++] = *p; \
  }
  REPORTS

#undef REPORT

// *INDENT-ON*

  // Initially and after 16 rows without printing a header we print one.
  // This gives 20 rows with 3 header lines (and one empty line) which
  // perfectly matches typical (classical small) terminal height.

  if ((solver->statistics.reported % 16) == 1)
    {
      char header[MAX_HEADER][MAX_LINE];
      int end_header[MAX_HEADER];

      for (int i = 0; i < MAX_HEADER; i++)
	{
	  header[i][0] = 'c';
	  end_header[i] = 1;
	}

      int reported = 0;

      // This is the really trick part to get a nicely adjusted header to
      // the columns of values which vary in size.  Goal is to keep the
      // column names in the middle above the values split in different
      // header rows so that they do not overlap.

// *INDENT-OFF*

#define REPORT(NAME, FMT) \
      { \
        const int row = reported % MAX_HEADER; \
        assert (end_header[row] < MAX_LINE); \
        header[row][end_header[row]++] = ' '; \
        assert (reported < num_reported); \
        const int start = column[reported++]; \
        const int end = \
          (reported == num_reported ? end_line : column[reported]); \
        const int value_width = end - start - 1; \
        const int name_width = strlen (#NAME); \
        int target; \
        if (name_width > value_width) \
          target = start - (name_width - value_width + 1)/2; \
        else \
          target = start + (value_width - name_width + 1)/2; \
        assert (target <= MAX_LINE); \
        while (end_header[row] < target) \
          { \
            assert (end_header[row] < MAX_LINE); \
            header[row][end_header[row]++] = ' '; \
          } \
        for (const char * p = #NAME; *p; p++) \
          { \
            assert (end_header[row] < MAX_LINE); \
            header[row][end_header[row]++] = *p; \
          } \
      }
      REPORTS
#undef REPORT

// *INDENT-ON*

      fputs ("c\n", stdout);

      for (int i = 0; i < MAX_HEADER; i++)
	{
	  for (int j = 0; j < end_header[i]; j++)
	    fputc (header[i][j], stdout);
	  fputc ('\n', stdout);
	}
      fputs ("c\n", stdout);
    }

  for (int i = 0; i < end_line; i++)
    fputc (line[i], stdout);
  fputc ('\n', stdout);

  fflush (stdout);
}

// Report statistics after a unit clause has been learned and propagated.

static void
iterate (struct satch *solver)
{
  report (solver, 'i');
  solver->iterate = false;
}

/*------------------------------------------------------------------------*/

// Functions used for scaling conflict intervals.

#if !defined(NREDUCE) || !defined(NRESTART)

static double
logn (uint64_t n)
{
  return log10 (n + 10);
}

#endif

#ifndef NSWITCH

static double
nlognlognlogn (uint64_t n)
{
  double tmp = log10 (n + 10);
  return n * tmp * tmp * tmp;
}

#endif

#ifndef NREDUCE

static double
ndivlogn (uint64_t n)
{
  return n / logn (n);
}

#endif

#if !defined(NREDUCE) || !defined(NSWITCH)

static double
scale_interval (uint64_t base, double (*scale) (uint64_t), uint64_t count)
{
  return base * (1 + scale (count));
}

#endif

/*------------------------------------------------------------------------*/

// Restarts are in principle triggered by restart intervals (measured in the
// number of conflicts passed).   However in focused mode we use exponential
// moving averages of the glucose level (glue) of learned clauses to
// determine whether we are in a phase where those levels go down or
// increase.  If the glue goes down we do not restart but if it goes up,
// that is the fast moving average is above a certain margin over the slower
// moving average, the we restart.

#ifndef NRESTART

static bool
restarting (struct satch *solver)
{
  assert (solver->unassigned);
  assert (!solver->inconsistent);

  if (!solver->level)
    return false;
  if (solver->limits.restart > CONFLICTS)
    return false;

#ifndef NSTABLE

  // Use only (large) conflict intervals in stable mode to trigger restarts.
  // However during computing the next restart limit below we use a
  // reluctant doubling of the base restart interval (also called Luby).

  if (solver->stable)
    return true;

#endif

  struct averages *a = averages (solver);

  const double fast = unbiased_fast_average (a, a->fast_glue);
  const double slow = unbiased_slow_average (a, a->slow_glue);
  const double limit = restart_margin * slow;

  return limit <= fast;
}

static void
restart (struct satch *solver)
{
  const uint64_t restarts = INC (restarts);
  message (solver, 4, "restart", restarts,
	   "restarting after %" PRIu64 " conflicts (limit %" PRIu64 ")",
	   CONFLICTS, solver->limits.restart);
  if (solver->options.verbose > 2)
    report (solver, 'r');

#ifndef NTARGET
  if (solver->stable)
    update_phases (solver);
#endif
  backtrack (solver, 0);

  uint64_t interval;
#ifndef NSTABLE
  if (solver->stable)
    {
      // This is the approach of Donald Knuth to compute the 'reluctant
      // doubling' sequence. In other solvers it is called 'Luby' sequence.
      // We further use a much longer base interval than in focused mode.

      struct reluctant *r = &solver->reluctant;
      uint64_t u = r->u, v = r->v;

      // The base interval is multiplied with the reluctant doubling
      // sequence number (1,2,1,1,2,4,1,1,2,4,8,1,1,2,1,1,2,4,1,1,...).

      interval = v * stable_restart_interval;

      if ((u & -u) == v)
	u++, v = 1;
      else
	assert (UINT64_MAX / 2 >= v), v *= 2;
      r->u = u, r->v = v;
    }
  else
#endif
    {
      assert (restart_interval >= 1);
      interval = (restart_interval - 1) + logn (restarts);
    }

  solver->limits.restart = CONFLICTS + interval;

  message (solver, 4, "restart", restarts,
	   "new %s restart limit %" PRIu64 " after %" PRIu64 " conflicts",
	   solver->stable ? "stable" : "focused",
	   solver->limits.restart, interval);
}

#endif

/*------------------------------------------------------------------------*/

#ifndef NREPHASE

static bool
rephasing (struct satch *solver)
{
  if (!solver->stable)
    return false;
  return solver->limits.rephase <= CONFLICTS;
}

static char
original_phases (struct satch *solver)
{
  const signed char value = original_phase ();
  memset (solver->saved, value, VARIABLES);
  return 'O';
}

#ifndef NINVERTED

static char
inverted_phases (struct satch *solver)
{
  const signed char value = -original_phase ();
  memset (solver->saved, value, VARIABLES);
  return 'I';
}

#endif

#ifndef NBEST

static char
best_phases (struct satch *solver)
{
  const signed char *const bests = solver->bests;
  const signed char *const end = bests + VARIABLES;
  signed char *const saved = solver->saved;
  signed char *q = saved, tmp;
  for (const signed char *p = bests; p != end; p++, q++)
    if ((tmp = *p))
      *q = tmp;
  solver->best = 0;
  return 'B';
}

#endif

static void
rephase (struct satch *solver)
{
  char (*functions[4]) (struct satch *);
  unsigned size_functions = 0;

#ifndef NINVERTED
  functions[size_functions++] = inverted_phases;
#ifndef NBEST
  functions[size_functions++] = best_phases;
#endif
#endif
  functions[size_functions++] = original_phases;
#ifndef NBEST
  functions[size_functions++] = best_phases;
#endif
  assert (size_functions <= sizeof functions / sizeof *functions);

  const uint64_t rephased = INC (rephased);
  const char type = functions[rephased % size_functions] (solver);

  const uint64_t interval = rephased * rephase_interval;
  solver->limits.rephase = CONFLICTS + interval;

  message (solver, 4, "rephase", rephased,
	   "new rephase limit %" PRIu64 " conflicts after %" PRIu64,
	   solver->limits.rephase, interval);
#ifndef NTARGET
  if (solver->stable)
    {
      LOG ("reset target size");
      memcpy (solver->targets, solver->saved, VARIABLES);
      solver->target = 0;
    }
#endif
  report (solver, type);
}

#endif

/*------------------------------------------------------------------------*/

// Reducing the clause data base by removing useless redundant clauses is
// important to keep the memory usage of the solver low, but also to
// speed-up propagation.  The reduction interval in terms of conflicts is
// increased arithmetically by 'reduce_interval'.  We combine reductions
// with clause data base simplifications which remove root-level satisfied
// clauses.  Removing falsified literals is not implemented yet.

#ifndef NREDUCE

static bool
reducing (struct satch *solver)
{
  return solver->limits.reduce.conflicts <= CONFLICTS;
}

// Protect reason clauses from garbage collection. The same function can
// be used afterwards to make reason clauses unprotected again.  It is
// better to lazily protect clauses during reductions instead of eagerly
// setting the 'protect' bit during assignments to avoid dereferencing
// pointers to binary clause reasons (if 'NBLOCK' is defined).

static void
set_protect_flag_of_reasons (struct satch *solver, bool protect)
{
  struct clause *const *const reasons = solver->reasons;
  for (all_elements_on_stack (unsigned, lit, solver->trail))
    {
      const unsigned idx = INDEX (lit);
      struct clause *reason = reasons[idx];
      if (!reason)
	continue;
#ifndef NBLOCK
      if (is_binary_reason (reason))
	continue;
#endif
      LOGCLS (reason, "%sprotecting", protect ? "" : "un");
      assert (reason->protected != protect);
      reason->protected = protect;
    }
}

static bool
clause_root_level_satisfied (struct satch *solver, struct clause *c)
{
  const signed char *const values = solver->values;
  const unsigned *const levels = solver->levels;
  for (all_literals_in_clause (lit, c))
    if (values[lit] > 0 && !levels[INDEX (lit)])
      return true;
  return false;
}

// Irredundant clauses are not reduced but root-level satisfied clauses
// can be collected during reduction too.  This is only necessary if there
// are new root-level fixed variables since the last reduction though.

static void
mark_satisfied_irredundant_clauses_as_garbage (struct satch *solver)
{
  for (all_irredundant_clauses (c))
    {
      assert (!c->redundant);
      assert (!c->garbage);
      if (c->protected)
	continue;
      if (!clause_root_level_satisfied (solver, c))
	continue;
      LOGCLS (c, "root-level satisfied thus marked garbage");
      assert (!c->garbage);
      c->garbage = true;
    }
}

// Redundant clauses with large enough glucose level (glue) which have not
// been used since the last reduction are deletion candidates. If there
// are new root-level fixed variables since the last reduction we also
// mark clauses as garbage which are root-level satisfied.

static void
gather_reduce_candidates (struct satch *solver, bool new_fixed_variables,
			  struct clauses *candidates)
{
  for (all_redundant_clauses (c))
    {
      assert (c->redundant);
      assert (!c->garbage);
      if (c->protected)
	continue;
      if (new_fixed_variables && clause_root_level_satisfied (solver, c))
	{
	  LOGCLS (c, "root-level satisfied thus marked garbage");
	  c->garbage = true;
	  continue;
	}
#ifndef NVIRTUAL
      assert (c->size > 2);
#else
      // As we can not protect binary reason clauses we just ignore them as.
      assert (c->size > 1);
      if (c->size == 2)
	continue;
#endif
#ifndef NTIER1
      if (c->glue <= tier1_glue_limit)
	continue;
#endif
#ifndef NUSED
      if (c->used)
	{
	  c->used--;		// Works for both 'used:1' and 'used:2'.
#ifndef NTIER2
	  if (c->glue <= tier2_glue_limit)
#endif
	    continue;
	}
#endif
      PUSH (*candidates, c);
    }

  if (solver->options.verbose < 2)
    return;

  const size_t size_candidates = SIZE (*candidates);
  const size_t redundant = SIZE (solver->redundant);
  message (solver, 2, "reduce", solver->statistics.reductions,
	   "gathered %zu reduce candidate clauses %.0f%%",
	   size_candidates, percent (size_candidates, redundant));
}

// Before actually deleting the garbage clauses we have to flush of course
// watches from the watcher lists pointing to such garbage clauses.

static void
flush_garbage_watches (struct satch *solver)
{
  struct watches *all_watches = solver->watches;
#ifndef NVIRTUAL
  signed char *const values = solver->values;
  const unsigned *const levels = solver->levels;
#endif
  for (all_literals (lit))
    {
#ifndef NVIRTUAL
      signed char lit_value = values[lit];
      if (lit_value && levels[INDEX (lit)])
	lit_value = 0;
#endif
      struct watches *const lit_watches = all_watches + lit;
      union watch *const end = lit_watches->end;
      union watch *q = lit_watches->begin;
      const union watch *p = q;
      while (p != end)
	{
#ifndef NBLOCK
	  const union watch watch = *p++;
#ifndef NVIRTUAL
	  const struct header header = watch.header;
	  if (header.binary)
	    {
	      const unsigned blocking = header.blocking;

	      signed char blocking_value = values[blocking];
	      if (blocking_value && levels[INDEX (blocking)])
		blocking_value = 0;

	      // We want to eagerly remove root-level satisfied binary
	      // clauses as well, but since those sit in watch lists only
	      // (if 'NVIRTUAL' and 'NBLOCK' are undefined) we have to check
	      // whether the literal or the other blocking literal are
	      // root-level assigned.  In both cases (since we assume
	      // propagation went to completion on the root-level) we know
	      // that the binary clause has to be satisfied.

	      if (lit_value || blocking_value)
		{
		  assert (lit_value > 0 || blocking_value > 0);
		  delete_binary (solver, header.redundant, lit, blocking);
		  continue;	// Drop header by not copying it.
		}
	      *q++ = watch;	// Keep header and skip non-existing clause.
	      continue;
	    }
#endif
	  *q++ = watch;		// Keep blocking literal header.
#endif
	  const struct clause *const clause = (*q++ = *p++).clause;
	  if (clause->garbage)
	    q -= long_clause_watch_size;	// Stop watching clause.
	}
      lit_watches->end = q;
    }
}

// After removing garbage watches we can finally delete garbage clauses.

static void
delete_garbage_clauses (struct satch *solver, struct clauses *clauses,
			size_t *bytes_ptr, size_t *count_ptr)
{
  size_t bytes = 0;
  size_t count = 0;

  struct clause *const *const end = clauses->end;
  struct clause **q = clauses->begin;

  for (struct clause ** p = q; p != end; p++)
    {
      struct clause *const c = *p;
      if (c->garbage)
	{
	  assert (!c->protected);
	  bytes += delete_clause (solver, c);
	  count++;
	}
      else
	*q++ = c;
    }
  clauses->end = q;

  *bytes_ptr += bytes;
  *count_ptr += count;
}

/*------------------------------------------------------------------------*/

// This the actual comparison functions for 'qsort' to order reduce
// candidates.  Clauses are more useful if they have a smaller glue or
// smaller size with the same glue.  The result is negative if the first
// argument is more useful than the second.  The result is positive, if the
// second argument is more useful.  Since 'qsort is not stable we make
// comparison deterministic by using clause ids as tie-breaker.

static int
cmp_reduce (const void *p, const void *q)
{
  const struct clause *const c = *(const struct clause * const *) p;
  const struct clause *const d = *(const struct clause * const *) q;
#ifndef NGLUE
  if (c->glue < d->glue)
    return -1;
  if (c->glue > d->glue)
    return 1;
#endif
  if (c->size < d->size)
    return -1;
  if (c->size > d->size)
    return 1;
  if (c->id < d->id)
    return 1;
  assert (c->id > d->id);
  return -1;
}

static void
sort_reduce_candidates (struct clauses *candidates)
{
  struct clause **begin = candidates->begin;
  qsort (begin, SIZE (*candidates), sizeof *begin, cmp_reduce);
}

/*------------------------------------------------------------------------*/

// From the remaining candidates we reduce 'reduce_fraction' of clauses.

static void
mark_garbage_candidates (struct satch *solver, struct clauses *candidates)
{
  const size_t size = SIZE (*candidates);
  assert (0.0 <= reduce_fraction);
  const size_t reduce = reduce_fraction * size;

  message (solver, 4, "reduce", solver->statistics.reductions,
	   "target is to reduce %zu out of %zu clauses %.0f%%",
	   reduce, size, percent (reduce, size));

  const double keep_fraction = 1.0 - reduce_fraction;
  const size_t keep = keep_fraction * size;

  size_t reduced = 0;

  while (SIZE (*candidates) > keep)
    {
      struct clause *c = POP (*candidates);
      LOGCLS (c, "reducing thus marked garbage");
      assert (!c->protected);
      assert (!c->garbage);
      c->garbage = true;
      reduced++;
    }

  message (solver, 3, "reduce", solver->statistics.reductions,
	   "reducing %zu out of %zu clauses %.0f%%",
	   reduced, size, percent (reduced, size));
}

/*------------------------------------------------------------------------*/

// Reduce less useful redundant clauses frequently.

static void
reduce (struct satch *solver)
{
  START (reduce);

  const uint64_t reductions = INC (reductions);

#ifndef NVIRTUAL
  assert (solver->statistics.redundant >= SIZE (solver->redundant));
  assert (solver->statistics.irredundant >= SIZE (solver->irredundant));
#else
  assert (solver->statistics.redundant == SIZE (solver->redundant));
  assert (solver->statistics.irredundant == SIZE (solver->irredundant));
#endif

  // First protect reasons from garbage collection and mark all newly
  // satisfied clauses as garbage.  This is only necessary if there are
  // newly fixed (root-level unit) variables since the last reduction, but
  // then also requires to go over the irredundant clauses.

  set_protect_flag_of_reasons (solver, true);

  const bool new_fixed_variables =
    solver->limits.reduce.fixed < solver->statistics.fixed;
  if (new_fixed_variables)
    mark_satisfied_irredundant_clauses_as_garbage (solver);

  // At the core of reduction is to first gather potential redundant reduce
  // candidate clauses (omitting those that are definitely kept).  Then
  // these candidates are sorted with respect to metric which is supposed to
  // reflect potential usefulness. From the less useful clauses a large
  // fraction ('reduce_fraction') is then marked as garbage to be collected.

  {
    struct clauses candidates;
    INIT (candidates);

    gather_reduce_candidates (solver, new_fixed_variables, &candidates);
    sort_reduce_candidates (&candidates);
    mark_garbage_candidates (solver, &candidates);

    RELEASE (candidates);
  }

  // Before we can delete the garbage clauses we first have to remove
  // references to those clauses marked as garbage from the watch lists.

  flush_garbage_watches (solver);

  {
    size_t bytes = 0, count = 0;
    if (new_fixed_variables)
      delete_garbage_clauses (solver, &solver->irredundant, &bytes, &count);
    delete_garbage_clauses (solver, &solver->redundant, &bytes, &count);

    // No we can mark reasons of literals on the trail as unprotected.

    set_protect_flag_of_reasons (solver, false);

    // We then compute and report the next conflict limit for reduction.

    solver->limits.reduce.fixed = solver->statistics.fixed;
    const uint64_t interval =
      scale_interval (reduce_interval, ndivlogn, reductions);
    solver->limits.reduce.conflicts = CONFLICTS + interval;
    message (solver, 4, "reduce", reductions,
	     "next reduce limit at %" PRIu64 " after %" PRIu64 " conflicts",
	     solver->limits.reduce.conflicts, interval);

    // Finally we report on how many clauses we collected.

    message (solver, 2, "reduce", reductions,
	     "collected %zu clauses (%zu bytes, %.0f MB)",
	     count, bytes, bytes / (double) (1u << 20));
  }

  report (solver, '-');
  STOP (reduce);
}

#endif

/*------------------------------------------------------------------------*/

// Switch between focused mode with aggressive restarting and stable mode
// with almost no restarting.  At the same time switch between two different
// decision variable schemes (by default VMTF vs (E)VSIDS).  During stable
// mode we also enable rephasing and target phases.  The two modes have
// there own averages ('glue', 'rate', 'level' and 'trail').

// Start and end of a mode is indicated by a '{' and '}' pair for focused
// mode (the initial mode) and '[' and ']' for stable mode.

#ifndef NSWITCH

static void
start_mode (struct satch *solver)
{
  if (solver->stable)
    {
      START (stable);
      report (solver, '[');
      LOG ("start stable mode");
    }
  else
    {
      START (focused);
      report (solver, '{');
      LOG ("start focused mode");
    }
}

static void
stop_mode (struct satch *solver)
{
  if (solver->stable)
    {
      STOP (stable);
      LOG ("stop stable mode");
      report (solver, ']');
    }
  else
    {
      STOP (focused);
      LOG ("stop focused mode");
      report (solver, '}');
    }
}

static bool
switching (struct satch *solver)
{
  struct limits *limits = &solver->limits;
  if (limits->mode.conflicts)
    return limits->mode.conflicts <= CONFLICTS;
  else
    return limits->mode.ticks.limit <= TICKS;
}

#ifndef NHEAP

static void
push_trail_to_heap (struct satch *solver)
{
  LOG ("pushing back trail to heap in reverse order");
  struct heap *scores = get_scores (solver);
  const unsigned *const pos = scores->pos;
  const unsigned *const begin = solver->trail.begin;
  const unsigned *end = solver->trail.end;
  while (end > begin)
    {
      const unsigned lit = *--end;
      const unsigned idx = INDEX (lit);
      if (pos[idx] == INVALID)
	push_heap (solver, scores, idx);
    }
}

#endif

#ifndef NQUEUE

static void
reset_queue_search (struct satch *solver)
{
  LOG ("reset queue search");
  struct queue *queue = get_queue (solver);
  queue->search = queue->last;
}

#endif

static void
mode_ticks_limit_hit (struct satch *solver, uint64_t switched)
{
  message (solver, 2, "switch", switched,
	   "%s mode limit of %" PRIu64 " ticks hit at %" PRIu64 " ticks",
	   solver->stable ? "focused" : "stable",
	   solver->limits.mode.ticks.limit, TICKS);
}

static void
set_new_mode_limit (struct satch *solver, uint64_t switched)
{
  struct limits *limits = &solver->limits;
  const uint64_t interval = limits->mode.ticks.interval;
  const uint64_t scaled =
    scale_interval (interval, nlognlognlogn, switched / 2);
  solver->limits.mode.ticks.limit = TICKS + scaled;
  message (solver, 3, "switch", switched,
	   "new %s mode limit of %" PRIu64 " ticks after %" PRIu64 " ticks",
	   solver->stable ? "focused" : "stable",
	   limits->mode.ticks.limit, scaled);
}

static void
switch_to_focused_mode (struct satch *solver, uint64_t switched)
{
  assert (solver->stable);
  mode_ticks_limit_hit (solver, switched);

#ifndef NHEAP1
  push_trail_to_heap (solver);
#endif
#ifndef NQUEUE1
  reset_queue_search (solver);
#endif
  solver->stable = false;
  assert (switched >= 2);
  assert (!(switched & 1));
}

static void
switch_to_stable_mode (struct satch *solver, uint64_t switched)
{
  assert (!solver->stable);

  struct limits *limits = &solver->limits;

  if (limits->mode.conflicts)
    {
      message (solver, 2, "switch", switched,
	       "focused mode limit of %" PRIu64 " conflicts hit at %"
	       PRIu64 " conflicts and %" PRIu64 " ticks",
	       limits->mode.conflicts, CONFLICTS, TICKS);

      limits->mode.ticks.interval = TICKS;
      limits->mode.conflicts = 0;
    }
  else
    mode_ticks_limit_hit (solver, switched);

#ifndef NHEAP0
  push_trail_to_heap (solver);
#endif
#ifndef NQUEUE0
  reset_queue_search (solver);
#endif
  solver->stable = true;
  assert ((switched & 1));

#ifndef NRESTART
  solver->reluctant.u = solver->reluctant.v = 1;
  solver->limits.restart = CONFLICTS + stable_restart_interval;
#endif

#ifndef NTARGET
  LOG ("reset target size");
  solver->target = 0;
#endif
}

static void
switch_mode (struct satch *solver)
{
  const uint64_t switched = INC (switched);
  stop_mode (solver);
  if (solver->stable)
    switch_to_focused_mode (solver, switched);
  else
    switch_to_stable_mode (solver, switched);
  struct averages *a = averages (solver);
  a->saved_decisions = DECISIONS;
  set_new_mode_limit (solver, switched);
  start_mode (solver);
}

#endif

/*------------------------------------------------------------------------*/

static void
init_limits (struct satch *solver)
{
#ifndef NREDUCE
  solver->limits.reduce.conflicts = reduce_interval;
#endif
#ifndef NREPHASE
  solver->limits.rephase = rephase_interval;
#endif
#ifndef NRESTART
  solver->limits.restart = restart_interval;
#endif
#ifndef NSWITCH
  solver->limits.mode.conflicts = initial_mode_conflicts_interval;
#endif
#ifdef NSTABLE
  assert (!solver->stable);
#endif
#ifdef NFOCUSED
  assert (solver->stable);
#endif
#if defined(NRESTART) && defined(NREDUCE) && defined(NREPHASE)
  // Avoid 'unused solver' warning with '-p'.
  (void) solver;
#endif
}

/*------------------------------------------------------------------------*/

// This is the main CDCL solving loop.

static int
solve (struct satch *solver, int delta_limit)
{
  START (solve);
  report (solver, '*');

  int res = solver->inconsistent ? 20 : 0;
  struct clause *conflict;

  uint64_t conflict_limit =
    delta_limit < 0 ? UINT64_MAX : CONFLICTS + delta_limit;

#ifndef NSWITCH
  start_mode (solver);
#endif
  while (!res)
    if ((conflict = boolean_constraint_propagation (solver)))
      {
	if (!analyze_conflict (solver, conflict))
	  res = 20;
      }
    else
      {
	if (solver->iterate)
	  iterate (solver);

	if (!solver->unassigned)
	  res = 10;
	else
	  {
	    if (CONFLICTS >= conflict_limit)
	      break;
#ifndef NRESTART
	    if (restarting (solver))
	      restart (solver);
	    else
#endif
#ifndef NSWITCH
	    if (switching (solver))
	      switch_mode (solver);
	    else
#endif
#ifndef NREDUCE
	    if (reducing (solver))
	      reduce (solver);
	    else
#endif
#ifndef NREPHASE
	    if (rephasing (solver))
	      rephase (solver);
	    else
#endif
	    if (!solver->level)
	      flush_units (solver);

	    decide (solver);
	  }
      }
#ifndef NSWITCH
  stop_mode (solver);
#endif

  report (solver, !res ? '?' : res == 10 ? '1' : '0');
  STOP (solve);

  return res;
}

/*------------------------------------------------------------------------*/

#ifndef NDEBUG

// This witness checker goes over the saved original clauses and checks that
// each of them is satisfied.  If not a fatal error message is triggered
// after printing the original clause which is unsatisfied.

static void
check_witness (struct satch *solver)
{
  const int *const begin_original = solver->original.begin;
  const int *const end_original = solver->original.end;
  size_t clauses = 0;
  for (const int *p = begin_original, *c = p; c != end_original; c = p)
    {
      clauses++;
      bool satisfied = false;
      int lit;
      while (assert (p != end_original), (lit = *p++))
	if (satch_val (solver, lit) == lit)
	  satisfied = true;
      if (satisfied)
	continue;
      fprintf (stderr,
	       "libsatch: fatal error: clause[%zd] unsatisfied:\n", clauses);
      for (const int *q = c; q != p; q++)
	printf (" %d", *q);
      fputc ('\n', stderr);
      fflush (stderr);
      abort ();
    }
  LOG ("checked witness successfully");
}

#endif

/*------------------------------------------------------------------------*/

// The API functions below have several requirements (contracts) and those
// need to be enforced even in optimized code, particularly in order to help
// library users to detect, test and debug invalid API usage.

static void
invalid_usage (const char *message, const char *function)
{
  fprintf (stderr,
	   "libsatch: invalid API usage in '%s': %s\n", function, message);
  fflush (stderr);
  abort ();
}

// Macros to enforce valid API usage.

#define REQUIRE(CONDITION,MESSAGE) \
do { \
  if (!(CONDITION)) \
    invalid_usage (MESSAGE, __func__); \
} while (0)

#define REQUIRE_NON_ZERO_SOLVER() \
  REQUIRE (solver, "zero solver argument")

#define REQUIRE_VALID_LITERAL(ELIT) \
do { \
  REQUIRE ((ELIT) != INT_MIN, "'INT_MIN' literal argument"); \
  REQUIRE (sizeof (void*) > 4 || abs (ELIT) <= (1<<30), \
           "maximum of '2^30' variables exceeded on 32-bit system"); \
} while (0)

#define REQUIRE_NON_ZERO_VALID_LITERAL(ELIT) \
do { \
  REQUIRE ((ELIT), "zero literal argument"); \
  REQUIRE ((ELIT) != INT_MIN, "'INT_MIN' literal argument"); \
} while (0)

/*========================================================================*/
//    Below are the non-static functions accessible through the API.      //
/*========================================================================*/

struct satch *
satch_init (void)
{
  struct satch *solver = calloc (1, sizeof (struct satch));
  if (!solver)
    fatal_error ("could not allocate solver");
#ifdef NFOCUSED
  solver->stable = 1;
#endif
#ifndef NDEBUG
  solver->checker = checker_init ();
#endif
#ifndef NBLOCK
  init_binary (solver);
#endif
#ifndef NVSIDS
#ifndef NFOCUSED
  solver->scores[0].factor = focused_score_increment_factor;
#endif
#ifndef NSTABLE
  solver->scores[1].factor = stable_score_increment_factor;
#endif
#endif
  init_averages (solver);
  init_limits (solver);
  init_profiles (solver);
  return solver;
}

void
satch_release (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
#ifdef NLEARN
  if (solver->level)
    backtrack (solver, 0);	// To delete reason clauses.
#endif
  free (solver->levels);
  free (solver->values);
#ifndef NSAVE
  free (solver->saved);
#endif
#ifndef NTARGET
  free (solver->targets);
#endif
#ifndef NBEST
  free (solver->bests);
#endif
  free (solver->marks);
#ifndef NACTIVE
  free (solver->active);
#endif
  free (solver->frames);
  free (solver->reasons);
  free (solver->trail.begin);

#ifndef NQUEUE
#ifndef NQUEUE0
  release_queue (&solver->queue[0]);
#else
  assert (!solver->queue[0].links);
#endif
#ifndef NQUEUE1
  release_queue (&solver->queue[1]);
#else
  assert (!solver->queue[1].links);
#endif
#endif

#ifndef NHEAP
#ifndef NHEAP0
  release_heap (&solver->scores[0]);
#else
  assert (!solver->scores[0].begin);
#endif
#ifndef NHEAP1
  release_heap (&solver->scores[1]);
#else
  assert (!solver->scores[1].begin);
#endif
#endif

#ifndef NACTIVE
#ifndef NFOCUSED
  RELEASE (solver->put[0]);
#else
  assert (EMPTY (solver->put[0]));
#endif
#ifndef NSTABLE
  RELEASE (solver->put[1]);
#else
  assert (EMPTY (solver->put[1]));
#endif
#endif

  solver->proof = 0;
  for (all_literals (lit))
    {
      struct watches *watches = solver->watches + lit;
#if !defined(NDEBUG) && !defined(NVIRTUAL)
      const union watch *const end = watches->end;
      for (const union watch * p = watches->begin; p != end; p++)
	if (p->header.binary)
	  delete_header (solver, lit, p->header);
	else
	  p++;
#endif
      RELEASE (*watches);
    }
  free (solver->watches);

#ifndef NMINIMIZE
  RELEASE (solver->marked);
#endif
  RELEASE (solver->seen);
  RELEASE (solver->clause);
  RELEASE (solver->blocks);

  for (all_pointers_on_stack (struct clause, c, solver->irredundant))
      (void) delete_clause (solver, c);
  RELEASE (solver->irredundant);
#ifndef NLEARN
  for (all_pointers_on_stack (struct clause, c, solver->redundant))
      (void) delete_clause (solver, c);
  RELEASE (solver->redundant);
#endif
  assert (!solver->statistics.irredundant);
  assert (!solver->statistics.redundant);
#ifndef NBLOCK
  release_binary (solver);
#endif

  RELEASE (solver->added);
#ifndef NDEBUG
  RELEASE (solver->original);

#ifndef NLEARN
  checker_enable_leak_checking (solver->checker);
#endif
  checker_release (solver->checker);
#endif

  free (solver);
}

/*------------------------------------------------------------------------*/

// Add a literal to an internal temporary clause or if the literal argument
// is zero then add a new irredundant / original clause to the solver which
// consists of all the previously literals added to the temporary clause.

void
satch_add (struct satch *solver, int elit)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_VALID_LITERAL (elit);
  REQUIRE (!solver->status, "incremental usage not implemented yet");
#ifndef NDEBUG
  PUSH (solver->original, elit);
#endif

  // If an empty clause has been added or derived we do not need to add
  // anything and just return for the rest of time this solver is used.

  if (solver->inconsistent)
    return;

  if (elit)
    {
      // Add the literal to the internal temporary 'clause' after importing
      // it, i.e., adjusting the 'size' (number of active variables) if its
      // variable has never been seen before.  Also turn the external signed
      // DIMACS 'int' literal into and internal 'unsigned' literal.

      const unsigned ilit = import_literal (solver, elit);
      PUSH (solver->clause, ilit);
      PUSH (solver->added, elit);
#ifndef NDEBUG
      checker_add_literal (solver->checker, elit);
#endif
    }
  else
    {
#ifndef NDEBUG
      checker_add_original_clause (solver->checker);
#endif
      bool remove_original_clause;

      // First check whether the imported clause is already (root-level)
      // satisfied or trivial (contains both a literal and its negation).
      // During this check falsified and duplicated literals are removed.

      if (!imported_clause_trivial_or_satisfied (solver))
	{
#ifndef NACTIVE
	  // Activate variables in the order they appear in the input CNF.
	  // This gives an implicit order of the variables in the decision
	  // queue as well as in the binary heap keeping variables in the
	  // same clauses close to each other which seems beneficial.

	  activate_literals (solver);
#endif

	  // We need special treatment for empty and unary clauses since all
	  // internally allocated clauses have at least two literals.  

	  const size_t size = SIZE (solver->clause);

	  if (!size)
	    {
	      LOG ("empty thus inconsistent imported clause");
	      solver->inconsistent = true;
	    }
	  else if (size == 1)
	    {
	      // It is a common technique to represent unit clauses by just
	      // assigning its literal on the root-level.  This makes sure
	      // that all allocated clauses are at least binary, but for
	      // instance requires that 'analyze' treats root-level literals
	      // in a special way, 'reduce' and thus 'assign' ignore
	      // clauses forcing root-level assigned literals and finally
	      // (and maybe really the most severe consequence), makes proof
	      // tracing semantics rather complex (particularly regarding the
	      // situation of deleting unit clauses in RUP / DRAT proofs).

	      const unsigned unit = ACCESS (solver->clause, 0);
	      const signed char value = solver->values[unit];
	      if (value > 0)
		{
		  LOG ("skipping redundant unit clause %u", unit);
		}
	      else if (value < 0)
		{
		  LOG ("found inconsistent unit clause %u", unit);
		  solver->inconsistent = true;
		}
	      else
		{
		  LOG ("found unit clause %u", unit);
		  assign (solver, unit, 0);
		}
	    }
#ifndef NVIRTUAL
	  else if (size == 2)
	    {
	      new_binary (solver, false);
#ifndef NDEBUG
	      const unsigned lit = ACCESS (solver->clause, 0);
	      const unsigned other = ACCESS (solver->clause, 1);
	      LOGBIN (false, lit, other, "imported");
#endif
	    }
#endif
	  else
	    {
	      struct clause *clause = new_irredundant_clause (solver);
	      LOGCLS (clause, "imported");
	      watch_clause (solver, clause);
	    }

	  const size_t added = SIZE (solver->added);
	  assert (size <= added);

	  if (size < added)
	    {
	      if (solver->proof)
		add_internal_clause_to_proof (solver);
#ifndef NDEBUG
	      for (all_elements_on_stack (unsigned, lit, solver->clause))
		  checker_add_literal (solver->checker, export_literal (lit));
	      checker_add_learned_clause (solver->checker);
#endif
	      remove_original_clause = true;
	    }
	  else
	    remove_original_clause = false;
	}
      else
	remove_original_clause = true;

      CLEAR (solver->clause);
      if (remove_original_clause)
	{
	  if (solver->proof)
	    {
	      start_deletion_proof_line (solver);
	      for (all_elements_on_stack (int, lit, solver->added))
		  add_external_literal_to_proof_line (solver, lit);
	      end_proof_line (solver);
	    }
#ifndef NDEBUG
	  for (all_elements_on_stack (int, lit, solver->added))
	      checker_add_literal (solver->checker, lit);
	  checker_delete_clause (solver->checker);
#endif
	}
      CLEAR (solver->added);
    }
}

/*------------------------------------------------------------------------*/

// Reserve at least 'max_var' variables that is the size of the solver. If
// the users knows this number then pre-allocating everything to that size
// avoids resizing the solver data.

void
satch_reserve (struct satch *solver, int max_var)
{
  REQUIRE_NON_ZERO_SOLVER ();
  assert (0 <= max_var);
  const size_t requested_capacity = max_var;
  if (requested_capacity > solver->capacity)
    increase_capacity (solver, requested_capacity);
}

int
satch_maximum_variable (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  assert (solver->size <= (unsigned) INT_MAX);
  return solver->size;
}

/*------------------------------------------------------------------------*/

// The IPASIR interface returns '-elit' if 'elit' is assigned 'false' and
// 'elit' if it is assigned to 'true'.  Otherwise it returns zero.  We do
// not want to use 'import_literal' here, since this forces to adapt the
// size (and capacity) of the solver to this literal even though it did not
// occur in a clause yet.  So we have to do that importing manually.

int
satch_val (struct satch *solver, int elit)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_NON_ZERO_VALID_LITERAL (elit);
  REQUIRE (solver->status == 10,
	   (solver->status == 20 ?
	    "expected status to be '10' and not '20'" :
	    !solver->status ?
	    "expected status to be '10' and not '0'" :
	    "expected status to be '10'"));
  int eidx = abs (elit);
  assert (eidx > 0);
  assert (eidx != INT_MIN);
  const unsigned iidx = eidx - 1;
  if (iidx >= solver->size)
    return 0;
  const unsigned ilit = LITERAL (iidx);
  signed char tmp = solver->values[ilit];
  if (!tmp)
    return 0;
  int res = (tmp > 0) ? elit : -elit;
  if (elit < 0)
    res = -res;
  assert (res == elit || res == -elit);
  return res;
}

int
satch_solve (struct satch *solver, int conflict_limit)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE (EMPTY (solver->clause),
	   "incomplete clause (zero literal missing)");
  REQUIRE (!solver->status, "no incremental solving yet");
  if (solver->options.verbose)
    section (solver, "solving");
  int res = solve (solver, conflict_limit);
  LOG ("internal solving procedure returns '%d'", res);
  solver->status = res;
#ifndef NDEBUG
  if (res == 10)
    check_witness (solver);
#endif
  return res;
}

/*------------------------------------------------------------------------*/

void
satch_set_verbose_level (struct satch *solver, int new_verbose_level)
{
  REQUIRE_NON_ZERO_SOLVER ();
  if (new_verbose_level < 0)
    new_verbose_level = 0;
#ifndef NDEBUG
  if (new_verbose_level > 1)
    checker_verbose (solver->checker);
#endif
  solver->options.verbose = new_verbose_level;
}

void
satch_enable_logging_messages (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
#ifndef NDEBUG
  checker_logging (solver->checker);
  checker_verbose (solver->checker);
  solver->options.logging = true;
#else
  (void) solver;
#endif
  solver->options.verbose = INT_MAX;
}

void
satch_ascii_proof (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  solver->options.ascii = true;
}

void
satch_trace_proof (struct satch *solver, FILE * proof)
{
  REQUIRE_NON_ZERO_SOLVER ();
  solver->proof = proof;
}

/*------------------------------------------------------------------------*/

double
satch_process_time (void)
{
  return process_time ();
}

void
satch_start_profiling_parsing (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  START (parse);
}

double
satch_stop_profiling_parsing (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  return STOP (parse);
}

void
satch_section (struct satch *solver, const char *name)
{
  REQUIRE_NON_ZERO_SOLVER ();
  section (solver, name);
}

void
satch_statistics (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  const double stop = print_profiles (solver);
  print_statistics (solver, stop);
  print_resource_usage (solver, stop);
}
