/*------------------------------------------------------------------------*/

// This is the library code of the SAT solver Satch with API in 'satch.h'.

// The full code of the library is contained in this file except for the
// header files 'satch.h', 'colors.h', 'stack.h' and 'features.h', and the
// three functions 'satch_compile', 'satch_identifier', and 'satch_version',
// which provide build information and are implemented in 'config.c', which
// in turn is automatically generated by 'mkconfig.sh'.  If you do not need
// those, nor the internal proof checking code in 'catch.[ch]', then you can
// either compile or just link against this file 'satch.c'.

// In order to disable proof checking and debugging (and avoid a link-time
// dependency on 'catch.o') compile with 'NDEBUG' defined.  Not defining
// 'NDEBUG' enables of course also assertion checking in general, also
// witness checking and includes logging code.  The latter still needs to be
// enabled at run-time through 'satch_enable_logging_messages' though.

// So again, if you do not want to use our build set-up, i.e., neither
// './configure' nor 'mkconfig.sh' but just want to link against this
// file instead of linking against the library and do not need proof
// checking in 'catch.c' (because you are not working on the 'satch' library
// itself) then just define 'NDEBUG' by for instance using '-DNDEBUG' as
// compiler option to compile this file and then link to it.

// We do not support assertion checking without internal proof checking (and
// witness checking).  These additional checks increase memory usage by a
// factor of two to four and solving times by up to a factor of five (due to
// simpler and thus slower checker data structures) but are worth to keep
// enabled in testing the library anyhow.  We are not aware of a scenario
// where production use of the solver would require to change this.

/*------------------------------------------------------------------------*/

#include "satch.h"		// API of the solver.

/*------------------------------------------------------------------------*/

#include <assert.h>
#include <math.h>
#include <inttypes.h>
#include <limits.h>
#include <stdarg.h>
#include <stdbool.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

/*------------------------------------------------------------------------*/

// System specific include files for 'getrusage', 'stat', and 'access'.

#include <sys/resource.h>
#include <sys/time.h>
#include <sys/types.h>
#include <unistd.h>

/*------------------------------------------------------------------------*/

// Rather complex and painful to implement checking of the compatibility of
// disabled features as well as disabling certain features based on other
// disabled features (e.g., if bumping is disabled with 'NBUMP' then VSIDS
// scores are disabled with 'NVSIDS' too).  Including this file also
// provides a consistent feature setting (of 'N...' macros).

// If you want to see which of these macros are actually defined use
// './configure -d' which in turn defines '-DIAGNOSE' and forces printing
// those definitions and in particularly check out 'features/README.md'.

#include "features.h"

/*------------------------------------------------------------------------*/

// Hard coded options for simplicity.

#define slow_alpha              1e-5	// Exponential moving average rate.

#ifndef NSWITCH
#define initial_focused_mode_conflicts 1e3
#define initial_focused_mode_ticks     1e8
#endif

#ifndef NELIMINATION

#ifndef NINPROCESSING
#define elimination_interval	500	// Base elimination interval.
#endif

#ifndef NELIMINATIONLIMITS
#ifndef NINPROCESSING
#define elimination_ticks_fraction 0.2	// Ticks fraction in elimination.
#endif
#define elimination_occurrence_limit 1e3
#define elimination_clause_size_limit 100
#define elimination_rounds 2
#endif

#endif

#ifndef NSUBSUMPTION

#ifndef NINPROCESSING
#define subsumption_ticks_fraction 0.1	// Ticks fraction in subsumption.
#endif

#ifndef NSUBSUMPTIONLIMITS
#define subsumption_occurrence_limit 1e3
#define subsumption_clause_size_limit 1e3
#define subsumption_rounds 2
#ifndef NSTRENGTHENING
#define strengthening_occurrence_limit 1e3
#endif
#endif

#endif

#ifndef NSTABLE
#define stable_restart_interval 1024	// Basic stable restart interval.
#endif

#ifndef NMINIMIZE
#define minimize_depth          1e4	// Recursive minimization depth.
#endif

#ifndef NREDUCE
#define reduce_fraction         0.75	// Fraction of reduced clauses.
#ifndef NTIER1
#define tier1_glue_limit        2	// Kept clause glue limit (tier 1).
#ifndef NTIER2
#define tier2_glue_limit        6	// Delayed reduction glue (tier 2).
#endif
#endif
#define reduce_interval         300	// Reduce conflicts interval.
#endif

#ifndef NREPHASE
#define rephase_interval	1e3	// Rephase conflict interval.
#endif

#ifndef NRESTART
#define fast_alpha              3e-2	// Exponential moving average rate.
#define restart_interval        1	// Basic (focused) restart interval.
#define restart_margin          1.1	// Margin for fast_glue > slow_glue.
#endif

#ifndef NBUMPREASONS
#define bump_reason_decision_rate_limit		10
#endif

// Increase factors (inverse of decay) for exponential VSIDS.

#ifndef NVSIDS

#ifndef NFOCUSED
#define focused_score_increment_factor	1.15
#endif

#ifndef NSTABLE
#define stable_score_increment_factor	1.05
#endif

#define MAX_SCORE		1e150	// Maximum score before rescore.

#endif

/*------------------------------------------------------------------------*/

// Local include files beside 'satch.h' and 'features.h'.

// As explained at the top of this file, there is a dependency on 'catch.h'
// at compile-time and thus 'catch.o' at link-time but only if 'NDEBUG' is
// undefined and thus assertion, proof and witness checking are enabled.
// Thus for production use you really want to define 'NDEBUG'.

#ifndef NDEBUG
#include "catch.h"		// Online proof checker for testing.
#endif

#ifndef NRADIXSORT
#include "rsort.h"		// Generic radix sort implementation.
#endif

#include "stack.h"		// Generic stack implementation.
#include "colors.h"		// Shared code for terminal colors.

/*------------------------------------------------------------------------*/

// The basic clause data structure.  Note however that binary clauses are
// kept in watch lists by default if blocking literals are used (or
// equivalently 'NBLOCK' is kept undefined).

struct clause
{
#if defined(LOGGING) || defined(NRADIXSORT)

  // From 'solver->statistics.added' needed for stable sorting if radix
  // sorting is disabled ('NRADIXSORT' defined) and of course for logging.

  uint64_t id;
#endif

  // First we have boolean flags with few bits.  This way the compiler has
  // the opportunity to merge them all into a single (32-bit) word.

  bool garbage:1;		// Collect at next garbage collection.
  bool protected:1;		// Do not collect current reason clauses.
  bool redundant:1;		// Redundant / learned (not irredundant).
#ifndef NSUBSUMPTION
  bool subsumed:1;		// Already used in subsumption.
#endif
#ifndef NUSED
#ifndef NTIER2
  unsigned used:2;		// Used since last clause reduction.
#else
  unsigned used:1;		// Used since last clause reduction.
#endif
#endif

#ifdef NWATCHES
 unsigned sum;			// Sum of non-false literals.
 unsigned count;		// Number of non-false literals.
#endif

#ifndef NGLUE
  unsigned glue;		// Glucose level (LBD).
#endif

#ifndef NCACHE
  unsigned search;		// Cached replacement search position.
#endif

  unsigned size;		// Size of clause (number of literals).

#ifndef NVARIADIC

  // This default version 'embeds' the literals directly into the clause.
  // Then the literals follow the clause header directly in memory.  This
  // makes the size of the actual memory block of a clause 'variadic'.

  unsigned literals[2];
#else

  // This non-variadic version stores the literals separately which requires
  // another rather expensive pointer dereference accessing the literals.

  unsigned *literals;
#endif
};

/*------------------------------------------------------------------------*/

// Stack of clause pointers.

struct clauses
{
  struct clause **begin, **end, **allocated;
};

/*------------------------------------------------------------------------*/

// Watches are made of a watch header and a clause unless blocking literals
// are disabled ('NBLOCK' defined).  If blocking literals are enabled
// ('NBLOCK' undefined) the blocking literal and thus the header is
// enough to watch a binary clause and the clause pointer can be omitted.

// Actually, binary clauses can become completely 'virtual' and do not have
// to be stored at all outside of watch lists.  Thus in the default compact
// compilation mode ('NVIRTUAL' undefined) we split watches into the two
// parts 'binary' and 'clause' and then use a 'union' type for 'watch' in
// order to be able to mix short watches for binary clauses (without clause
// pointer) with long watches for larger clauses on the same watcher stack.

// This union type allows to push them independently, even though we always
// need to push a header, but can optionally omit the clause.  Code to
// traverse watcher stacks becomes slightly more complicated though.

// In order to avoid switching between 'union' and 'struct' with and without
// virtual binary clauses (w/o 'NVIRTUAL' undefined) we always simply use
// this 'union' type. The actual memory operations performed do not change
// anyhow.  As drawback one can consider that, without blocking literals,
// i.e., 'NBLOCK' defined and thus also 'NVIRTUAL', watches are declared as
// unions with a single member 'clause', which clutters code slightly
// (requires to use 'watch.clause').

#ifndef NBLOCK

// The header part of a watch if blocking literals are used.

struct header
{
  bool binary;			// Binary clause.
  bool redundant;		// Relevant for statistics and logging.
  unsigned blocking;		// Blocking literal of the clause.
};

#define long_clause_watch_size 2	// Two watches per long clause.

#else

#define long_clause_watch_size 1	// One without blocking literals.

#endif

// The actual watch data structure (it is a 'union' - see discussion above).

// For Java programmers not familiar with the 'union' concept in C (or
// equivalently to variant records in Pascal) is the following explanation.

// All members of a 'union' type overlap in memory and it depends on how you
// access the 'union' (in our case as '.header' or '.clause') what data is
// read (particularly if the fields have different length in bytes).  This
// is completely unsafe though in general (breaks strong typing) and for
// instance in Pascal could be used to implement type casts.  The user has
// to make sure that the right data is accessed and this requires of course
// some additional context.

// In our case, without blocking literals ('NBLOCK' defined), the 'union'
// just hides a clause pointer.  With blocking literals (keeping 'NBLOCK'
// undefined) there are always one to two watches considered together on
// watcher stacks.  The 'binary' field of the first one determines whether
// the second one really exists (or is the start of another single or pair
// of watches).  If 'binary' is false the second watch is a clause pointer.

union watch
{
#ifndef NBLOCK
  struct header header;
#endif
  struct clause *clause;
};

// Stack of watches.

struct watches
{
  union watch *begin, *end, *allocated;
};

/*------------------------------------------------------------------------*/

// Conflict and other limits for restarts, reductions etc.

// We use the following idiom to define an internal macro option 'NLIMITS'
// (i.e., which is not in 'features.h') in case the 'limits' structure
// becomes empty and it does not need to be declared in the solver.  There
// we can then only test 'NLIMITS'.  Note that, an empty 'struct' would
// trigger an error during pedantic compilation ('./configure -p').

#ifdef NLIMITS
#undef NLIMITS			// This is actually an option thus undefine it first.
#endif

#ifdef NELIMINATION
#ifdef NREDUCE
#ifdef NREPHASE
#ifdef NRESTART
#ifdef NSUBSUMPTION
#ifdef NSWITCH
#define NLIMITS
#endif
#endif
#endif
#endif
#endif
#endif

#ifndef NLIMITS

struct limits
{
#ifndef NELIMINATION
  struct
  {
    uint64_t conflicts;		// Conflict-limit on elimination.
    uint64_t fixed;		// Root-level fixed at elimination.
    uint64_t marked;		// Marked as elimination candidates.
#ifndef NELIMINATIONLIMITS
    uint64_t ticks;		// Ticks limit for elimination.
    uint64_t search;		// Saved search ticks at last elimination.
#endif
  } eliminate;
#endif
#ifndef NREDUCE
  struct
  {
    uint64_t conflicts;		// Conflict-limit on reducing.
    uint64_t fixed;		// Root-level fixed at reduction.
  } reduce;
#endif
#ifndef NREPHASE
  uint64_t rephase;		// Conflict-limit on rephasing.
#endif
#ifndef NRESTART
  uint64_t restart;		// Conflict-limit on restarting.
#endif
#ifndef NSWITCH
  struct
  {
    uint64_t conflicts;		// Conflict-limit if non zero.
    struct
    {
      uint64_t limit;		// Ticks-limit on mode switching.
      uint64_t interval;	// Ticks-mode base-interval (computed).
    } ticks;
  } mode;
#endif
#ifndef NSUBSUMPTION
  struct
  {
    uint64_t marked;		// Marked as subsume candidates.
#ifndef NSUBSUMPTIONLIMITS
    uint64_t ticks;		// Ticks limit for subsumption.
    uint64_t search;		// Saved search ticks at last elimination.
#endif
  } subsume;
#endif
};

#endif

/*------------------------------------------------------------------------*/

#if defined(NVIRTUAL) || defined(NELIMINATION)
#define NBINARIES
#endif

/*------------------------------------------------------------------------*/

// These are counters used for 'reluctant doubling' which is the way how
// Donald Knuth implements the computation of the 'Luby' sequence to control
// restart intervals. We only control restarts through reluctant doubling in
// stable mode though.

// Again we use this idiom explained above to define an internal macro
// option 'NRELUCTANT' which is defined if (through disabling other
// features) there is no need for reluctant doubling code.

#if defined(NRESTART) || defined(NSTABLE)
#define NRELUCTANT
#endif

#ifndef NRELUCTANT

struct reluctant
{
  uint64_t u, v;
};

#endif

/*------------------------------------------------------------------------*/

// Relying on compile-time configuration, we have very few run-time options.

struct options
{
  bool ascii;			// Use ASCII proof format.
#ifdef LOGGING
  bool logging;			// Print logging messages.
#endif
  unsigned verbose;		// Verbose level for messages 0..4.
};

/*------------------------------------------------------------------------*/

// Runtime statistics.

struct statistics
{
#ifndef NLAZYACTIVATION
  uint64_t activated[2];	// Activated variables (added queue/scores).
#endif
  uint64_t added;		// Number of added clauses.
#ifndef NBEST
  uint64_t bests;		// Number of saved best trails.
#endif
#ifndef NBUMP
  uint64_t bumped;		// Bumped literals.
#endif
  uint64_t collected;		// Garbage collected bytes.
  uint64_t conflicts;		// Total number of conflicts.
  uint64_t deleted;		// Number of deleted clauses.
  uint64_t decisions;		// Total number of decisions.
  uint64_t deduced;		// Deduced literals (of 1st UIP clause).
#ifndef NELIMINATION
  uint64_t eliminated;		// Number of eliminated variables.
  uint64_t elimination_ticks;	// Number of elimination ticks.
  uint64_t eliminations;	// Number of elimination phases.
#endif
#ifdef NLAZYACTIVATION
  uint64_t filled[2];		// Filled variables (added queue/scores).
#endif
  uint64_t fixed;		// Root level assigned variables (units).
#ifndef NVSIDS
  uint64_t incremented;		// Bumped by incrementing score.
#endif
  uint64_t irredundant;		// Current number of irredundant clauses.
  uint64_t learned;		// Learned literals (after minimization).
#ifndef NELIMINATION
  uint64_t marked_eliminate;	// Marked eliminate candidate variables.
#endif
#ifndef NSUBSUMPTION
  uint64_t marked_subsume;	// Marked subsume candidate variables.
#endif
#ifndef NMINIMIZE
  uint64_t minimized;		// Minimized literals.
#endif
#ifndef NVMTF
  uint64_t moved;		// Bumped by moving to front.
#endif
  uint64_t propagations;	// Propagated literals.
#ifndef NBUMPREASONS
  uint64_t reasons;		// Additionally bumped reason side literals.
#endif
#ifndef NELIMINATION
  uint64_t resolutions;		// Number of resolutions.
#endif
#ifndef NREDUCE
  uint64_t reduced;		// Number of reduced clauses.
  uint64_t reductions;		// Number of reductions (not clauses).
#endif
  uint64_t redundant;		// Current number of redundant clauses.
  uint64_t remaining;		// Remaining active variables.
#ifndef NREPHASE
  uint64_t rephased;		// How often saved phases have been reset.
#endif
  uint64_t reported;		// Number of calls to 'report'.
#ifndef NVSIDS
  uint64_t rescored;		// Rescored EVSIDS scores.
#endif
#ifndef NVMTF
  uint64_t restamped;		// Restamped VMTF timestamps.
#endif
#ifndef NRESTART
  uint64_t restarts;		// Number of restarts.
#endif
#ifndef NREUSE
  uint64_t reused;		// Number of reused trails.
#endif
  uint64_t sections;		// Number of calls to 'section'.
#ifndef NSHRINK
  uint64_t shrunken;		// Shrunken literals.
#endif
  uint64_t solved;		// Number of calls to 'satch_solve'.
#ifndef NSUBSUMPTION
  uint64_t strengthened;	// Strengthened clauses.
  uint64_t subsumed;		// Subsumed clauses.
  uint64_t subsumption_ticks;	// Number of subsumption ticks.
  uint64_t subsumptions;	// Full backward subsumptions.
#endif
#ifndef NSWITCH
  uint64_t switched;		// Number of focused/stable mode switches.
#endif
#ifndef NTARGET
  uint64_t targets;		// Number of saved target trails.
#endif
  uint64_t ticks;		// Propagation ticks.
  uint64_t variables;		// Activated variables.
};

/*------------------------------------------------------------------------*/

#ifndef NQUEUE

// Links for doubly-linked variable decision queue.

struct link
{
  unsigned prev;		// Previous variable index.
  unsigned next;		// Next variable index
  unsigned stamp;		// Enqueue time stamp.
};

/*------------------------------------------------------------------------*/

// Variable move-to-front doubly-linked list decision queue.

struct queue
{
  struct link *links;		// Variable links in decision queue.
  unsigned size;		// Size of queue (when last used).
  unsigned first;		// First enqueued variable index.
  unsigned last;		// Last enqueued variable index.
  unsigned search;		// Cache search in 'decide'.
  unsigned stamp;		// Enqueue time stamp.
};

#endif

/*------------------------------------------------------------------------*/

#ifndef NHEAP

// Priority queue with (E)VSIDS scores implemented as binary heap.

struct heap
{
  unsigned *begin, *end;	// Pre-allocated stack of variables.
  unsigned *pos;		// Pre-allocated variable to position map.
  double *score;		// The actual score of the variable.
  unsigned size;		// Size of heap (when last used).
  double increment;		// Exponentially increasing score increment.
  double factor;		// Increased by this factor.
};

#endif

/*------------------------------------------------------------------------*/

// Analyzed variables (enables sorting with respect to stamps).

struct analyzed
{
  unsigned idx;
#ifndef NSORTANALYZED
  unsigned stamp;		// Needed for sorting bumped variables only.
#endif
};

/*------------------------------------------------------------------------*/

// Stack of analyzed indices with stamps.

struct analyzed_stack
{
  struct analyzed *begin, *end, *allocated;
};

/*------------------------------------------------------------------------*/

// Pre-allocated stack of literals with 'propagate' to perform breadth-first
// search over assigned literals on the trail during propagation.

struct trail
{
  unsigned *begin, *end;	// As in 'stack' (can use stack macros).
  unsigned *propagate;		// Position of next literal to propagate.
};

/*------------------------------------------------------------------------*/

// Exponential moving averages (for 'exp' see below).

struct averages
{
  double conflict_level;	// Slow moving average of conflict level.
  double slow_glue;		// Slow moving average of glue.
  double slow_exp;		// Cached 'slow_beta^n'.
  double trail_filled;		// Slow moving relative trail size average.
  double decision_rate;		// Slow decisions per conflict rate.
  uint64_t saved_decisions;
#ifndef NRESTART
  double fast_glue;		// Fast moving average of glue.
  double fast_exp;		// Cached 'fast_beta^n'.
#endif
};

/*------------------------------------------------------------------------*/

// We use an idiom of defining at compile-time a list of code parameters
// multiple times (here 'PROFILES', but also see 'REPORTS' below and
// 'SIGNALS' in 'main.c').  The idea is that the parameter list contains the
// variations of some common code, that is compile-time parameters of that
// code.  Here for example the common code will be in the 'PROFILE' macro
// (singular) which is then instantiated with its single parameter (we use
// 'NAME') if we just write 'PROFILES' (plural).  This way  we can use that
// parameter in 'PROFILE' at compile time as symbol as well as string (with
// '#NAME'), or even generate new symbols (see 'SIGNALS' in 'main.c').

// *INDENT-OFF*

#define PROFILES \
PROFILE_IF_FOCUSED (focused)     /* Time spent in focused mode. */ \
PROFILE_IF_ELIMINATION (eliminate) /* Time spent in elimination. */ \
PROFILE (parse)                  /* Time spent parsing. */ \
PROFILE_IF_REDUCE (reduce)       /* Time spent reduce. */ \
PROFILE (solve)                  /* Time spent solving. */ \
PROFILE_IF_STABLE (stable)       /* Time spent in stable mode. */ \
PROFILE_IF_SUBSUMPTION (subsume) /* Time spent in full subsumption. */ \
PROFILE (total)			 /* Total time spent. */

#define DO_NOT_PROFILE(ARG) /**/

#ifndef NFOCUSED
#define PROFILE_IF_FOCUSED PROFILE
#else
#define PROFILE_IF_FOCUSED DO_NOT_PROFILE
#endif

#ifndef NREDUCE
#define PROFILE_IF_REDUCE PROFILE
#else
#define PROFILE_IF_REDUCE DO_NOT_PROFILE
#endif

#ifndef NSTABLE
#define PROFILE_IF_STABLE PROFILE
#else
#define PROFILE_IF_STABLE DO_NOT_PROFILE
#endif

#ifndef NSUBSUMPTION
#define PROFILE_IF_SUBSUMPTION PROFILE
#else
#define PROFILE_IF_SUBSUMPTION DO_NOT_PROFILE
#endif

#ifndef NELIMINATION
#define PROFILE_IF_ELIMINATION PROFILE
#else
#define PROFILE_IF_ELIMINATION DO_NOT_PROFILE
#endif

// *INDENT-ON*

struct profile
{
  double start, time;		// Start time, and total time.
  const char *name;		// Used in 'print_profiles'.
};				// Initialized in 'init_profiles'.

#define MAX_PROFILES            16

struct profiles
{
#define PROFILE(NAME) \
  struct profile NAME;		// Declare all the profiles.
  PROFILES
#undef PROFILE
  struct profile *begin[MAX_PROFILES];	// Pre-allocated!
  struct profile **end;
};

// Variable flags.

struct flags
{
  bool active:1;		// Active so neither fixed nor eliminated.
#ifndef NELIMINATION
  bool eliminate:1;		// Removed since last 'eliminate'.
  bool eliminated:1;		// Variable eliminated in 'eliminate'.
#endif
  bool fixed:1;			// Root-level assigned variable (unit).
#ifndef NSUBSUMPTION
  unsigned subsume:2;		// Newly added after last 'subsume'.
#endif
};

/*------------------------------------------------------------------------*/

// The full solver state is captured in this structure.

struct satch
{
  int status;			// UNKNOWN, SATISFIABLE, UNSATISFIABLE.
  bool inconsistent;		// Empty clause found or derived.
  bool iterate;			// Report learned unit clause.
  bool stable;			// Stable mode (fewer restarts).
  bool dense;			// Dense mode (connected - not watched).
  unsigned level;		// Current decision level.
  unsigned size;		// Number of variables.
  size_t capacity;		// Allocated variables.
  unsigned unassigned;		// Number of unassigned variables.
  unsigned *levels;		// Decision levels of variables.
  signed char *values;		// Current assignment of literals.
  struct flags *flags;		// Variable flags.
#ifndef NSAVE
  signed char *saved;		// Saved assignments of variables.
#endif
#ifndef NTARGET
  signed char *targets;		// Target phases.
  unsigned target;		// Maximum trail size.
#endif
#ifndef NBEST
  signed char *bests;		// Best phases.
  unsigned best;		// Best trail size.
#endif
  signed char *marks;		// Mark flags of variables.
#ifndef NLAZYACTIVATION
  struct unsigned_stack put[2];	// To be put on decision queue / heap.
#endif
#ifndef NMINIMIZE
  struct unsigned_stack poisoned;	// Variables marked as poisoned.
  struct unsigned_stack removable;	// Variables marked as removable.
#endif
#ifndef NSHRINK
  struct unsigned_stack shrunken;	// Shrunken variables.
  unsigned *position;		// Variable position on trail.
#endif
  signed char *frames;		// Level pulled in learned clauses.
#ifndef NQUEUE
  struct queue queue[2];	// Variable decision queue (stable=1).
#endif
#ifndef NHEAP
  struct heap scores[2];	// Variable decision heap (stable=1).
#endif
  struct clause **reasons;	// Reason clauses of a variable.
#ifndef NBLOCK
  struct clause binary[2];	// Temporary binary clauses.
#endif
#ifndef NBINARIES
  struct unsigned_stack binaries;	// Saved redundant binary clauses.
#endif
#ifndef NELIMINATION
  struct unsigned_stack extend;	// Solution reconstruction.
  struct unsigned_stack resolvents;	// Temporary resolvents.
#endif
  struct watches *watches;	// Watches of a literal.
  struct trail trail;		// Assigned literals.
  struct analyzed_stack analyzed;	// Analyzed literals.
  struct unsigned_stack clause;	// Temporary clause.
  struct unsigned_stack blocks;	// Analyzed decision levels.
  struct clauses irredundant;	// Current irredundant clauses.
  struct clauses redundant;	// Current redundant clauses.
#ifndef NLIMITS
  struct limits limits;		// Limits on restart, reduce, etc.
#endif
#ifndef NRELUCTANT
  struct reluctant reluctant;	// Doubling for stable restart (Luby).
#endif
  struct options options;	// Few runtime options.
  struct averages averages[2];	// Exponential moving averages (stable=1).
  struct statistics statistics;	// Statistic counters.
  struct profiles profiles;	// Built in run-time profiling.
#ifndef NDEBUG
  struct int_stack original;	// Copy of all original clauses.
  struct checker *checker;	// Internal proof checker.
#endif
  struct int_stack added;	// Added external clause.
  FILE *proof;			// Tracing to this file if non-zero.
#ifdef LOGGING
  char format[4][128];		// String buffer for logging.
  unsigned next_format;		// Next buffer for logging.
#endif
};

// The main point of this extensive configurability is to be able to strip
// down (disable) parts of the solver state if a feature which does not need
// that part is disabled. For instance if reluctant doubling is not needed
// ('--no-stable' or '--no-restart'), then we do not want to initialize it
// during mode switching.   If we do not even have a 'reluctant' member in
// this case, the compiler will catch accidental usage.

// This way we can reduce the code really needed for a feature and as just
// described remove accidental run-time overhead related to code for a
// disabled feature.

// This approach is almost straight-forward except for the various variants
// of using VSIDS or VMTF in focused and stable mode (or if one of the
// latter is disabled), which requires two averages in the default
// configuration and maybe two queues or two heaps (or a queue in stable
// mode for '--no-focused --no-vsids').  Therefore we do have some fields
// duplicated (the arrays '...[2]' above) but we make sure that we really
// only use one if the configuration needs a particular instance.

/*------------------------------------------------------------------------*/

// We use 'unsigned (int)' as type for internal literals and variable
// indices.  Our internal variable indices start at zero and literals are
// variable indices multiplied by two. The lowest bit of a literal denotes
// its sign.  The following function maps variable indices to literals.

static unsigned
LITERAL (unsigned idx)
{
  assert (idx < (1u << 31));	// Check for overflow.
  return idx << 1;
}

// Vice-versa this function maps literals to their variable index.

static unsigned
INDEX (unsigned lit)
{
  return lit >> 1;
}

// The least significant bit of a literal is its sign.

static unsigned
SIGN_BIT (unsigned lit)
{
  return lit & 1;
}

// Values of type 'signed char' are ternary and this function translate an
// (unsigned) literal bit into a (binary) 'true' or 'false' ('1' or '-1').

static int
INT_SIGN (unsigned lit)
{
  return SIGN_BIT (lit) ? -1 : 1;
}

// Negating a literal amounts to flipping its least significant bit.

static unsigned
NOT (unsigned lit)
{
  return lit ^ 1;
}

// Note that the API uses signed integers for literals.  These signed
// external DIMACS variable indices are in the range '1..INT_MAX' and are
// mapped to internal variable indices '0..(INT_MAX-1)'.

// The mapping between internal and external literals is as follows.

// +----------------------------------------+----------------------------+
// | External signed DIMACS literals        | Internal unsigned literals |
// +----------------------------------------+----------------------------+
// |     1                                  |    0                       |
// |    -1                                  |    1                       |
// |     2                                  |    2                       |
// |    -2                                  |    3                       |
// |    ...                                 |   ...                      |
// |  INT_MAX =   (1u<<31)-1  =  2147483647 | (1u<<32)-4 = 4294967292    |
// | -INT_MAX = -((1u<<31)-1) = -2147483647 | (1u<<32)-3 = 4294967293    |
// +----------------------------------------+----------------------------+

// We use the following two invalid values as sentinel to terminate a
// clause externally or as invalid literal or invalid variable internally.

// +----------------------------------------+----------------------------+
// |     0                                  | INVALID    = (1u<<32)-1    |
// |                                        |            = 4294967295    |
// |                                        |            = UINT_MAX      |
// +----------------------------------------+----------------------------+

// For completeness, note that, there is one unused value in each case.

// +----------------------------------------+----------------------------+
// | INT_MIN = -(1u<<31)      = -2147483648 | (1u<<32)-2 = 4294967294    |
// +----------------------------------------+----------------------------+

// Here we assume that 'sizeof (unsigned) == sizeof (int)', signed integers
// are encoded in two-complement and thus 'INT_MAX == (1u<<31)-1'.

// It would be possible to also use 'int' for literals internally, but then
// iterator code would become much more complicated.  Access to positively
// and negatively indexed arrays, i.e., watches and values, would be strange
// and requires complex reallocation code too (for incremental usage).

// Thus we allow up to 'INT_MAX' variables and use the all-bits-one number
// 'INVALID' to denote invalid literals and variable indices '(1u<<32)-1'.

// By default (as long 'NBLOCK' is not defined) we use 'bit-stuffing' to
// distinguish binary clause reasons (the other literal) from real large
// clause reasons (pointer to the clause).  This technique requires that
// we use the least significant bit of a pointer as flag to distinguish this
// case and accordingly reduces the number of variables on a 32-bit system.
// We use another bit for storing the information whether such reason clause
// is redundant.  Thus on a 32-bit system the maximum number of variables is
// '2^29' (which will not be reachable on such a system anyhow) but on
// 64-bit systems we can have 'INT_MAX' variables.

#define INVALID UINT_MAX

/*------------------------------------------------------------------------*/

// Increase and decrease statistic counters with over/under-flow checking.

// For those readers not familiar with this style of C macros, note that
// that this 'do { ... } while (0)' idiom makes sure that the macro almost
// acts like a procedure (function without any return value), allows local
// variables (not here but see the macros in 'stack.h'), and still can be
// used with a semicolon after it in an 'if-then-else' statement such as
//
//   if (c->redundant) DEC (redundant); else DEC (irredundant);
//
// which would become a syntax error if we only use a block of curly
// parenthesis.  We can also 'return' early with a 'break' statement
// (instead of 'return').  An alternative consists of statement expressions,
// which however are a GCC extension and (pedantic) compilation fails for
// '-W -Wall -Werror -pedantic' on these extensions (as for the otherwise
// pretty handy 'typeof', which, accordingly, we also do not use).

#define DEC(NAME) \
do { \
  assert (solver->statistics.NAME > 0); \
  solver->statistics.NAME--; \
} while (0)

// For this macro we want to produce a 'return' value which requires a more
// sophisticated use of the 'comma' operator. Again 'statement expressions'
// would be an alternative but we do not want to use those.  This technique
// breaks down if you need more sophisticated control flow, i.e., loops.
// See 'COVER' for another use of 'comma' as well as how we define the
// anticipated loop condition in the 'all_...' iterator macros below.

#define INC(NAME) \
  ( \
    assert (solver->statistics.NAME < UINT64_MAX), \
    ++solver->statistics.NAME \
  )

#define ADD(NAME,DELTA) \
do { \
  assert (UINT64_MAX - (DELTA) >= solver->statistics.NAME); \
  solver->statistics.NAME += (DELTA); \
} while (0)

/*------------------------------------------------------------------------*/

// The number of variables and literals.

#define VARIABLES (solver->size)
#define LITERALS (2u*VARIABLES)

// We also often need the number of conflicts, decisions and ticks.

#define CONFLICTS (solver->statistics.conflicts)
#define DECISIONS (solver->statistics.decisions)
#define TICKS (solver->statistics.ticks)

/*------------------------------------------------------------------------*/

// Iterators for global solver data.  They can be used in a similar way as
// range-based for-loops in C++-11.  For instance the idiom
//
//   for (all_variables (idx))
//     ...
//
// goes over all variable indices 'idx'.

// The features of C'99 we use here are local declarations in for-loops and
// the comma-operator to assign the range variable 'idx' as side effect of a
// 'true' expression.  Similar code in 'stack.h' allows to iterate over
// generic stacks.

#define all_variables(IDX) \
  unsigned IDX = 0, END_VARIABLES = VARIABLES; IDX < END_VARIABLES; IDX++

#define all_literals(LIT) \
  unsigned LIT = 0, END_LITERALS = LITERALS; LIT < END_LITERALS; LIT++

#define all_elements_in_array(TYPE,LIT,SIZE,LITS) \
  TYPE LIT, * P_ ## LIT = (LITS), \
            * const END_ ## LIT = P_ ## LIT + (SIZE); \
  (P_ ## LIT != END_ ## LIT) && (LIT = *P_ ## LIT, true); ++P_ ## LIT

#define all_literals_in_clause(LIT,C) \
   all_elements_in_array (unsigned, LIT, (C)->size, (C)->literals)

#define all_irredundant_clauses(C) \
  all_pointers_on_stack (struct clause, C, solver->irredundant)

#define all_redundant_clauses(C) \
  all_pointers_on_stack (struct clause, C, solver->redundant)

#define all_redundant_clauses_in_reverse(C) \
  all_pointers_on_stack_in_reverse (struct clause, C, solver->redundant)

/*------------------------------------------------------------------------*/

// The 'COVER' macro is used for testing and debugging, more precisely for
// the case where full assertion checking (and proof checking) is not
// feasible, but you still want to figure out whether a certain situation
// can happen.  Those conditions 'COND' are thus 'coverage goals', i.e.,
// conditions you want to hit, or situations where you are almost 100% sure
// that they can never happen, but you want to make sure that it does not
// happen maybe accidentally during a full run on a competition set.  Trying
// to cover a certain condition during fuzzing with full optimization and no
// other (assertion) checking switched on is another common use case.

// Now to the macro itself.  This is in essence follows the same principle
// when you implement 'assert' yourself.  The main point is that it should
// be an expression of type 'void' such that you can use it as part of a
// 'comma' list.  For other examples see 'TOP' and 'POP' in 'stack.h'.

#define COVER(COND) \
( \
    (COND) \
  ? \
    ( \
      fflush (stdout), \
      fprintf (stderr, "%s:%ld: %s: Coverage goal `%s' reached.\n", \
        __FILE__, (long) __LINE__, __func__, #COND), \
      abort (), \
      (void) 0 \
    ) \
  : \
    (void) 0 \
)

/*------------------------------------------------------------------------*/

// Export internal unsigned literals as external signed literals.

static unsigned
export_literal (unsigned ilit)
{
  const unsigned iidx = INDEX (ilit);
  assert (iidx < (unsigned) INT_MAX - 1);
  const int eidx = iidx + 1;
  const int elit = SIGN_BIT (ilit) ? -eidx : eidx;
  return elit;
}

/*------------------------------------------------------------------------*/

// These declarations provide nice warning messages if these functions are
// used with format strings which do not match the type of an argument,
// which otherwise is very hard to get right (particularly for logging).

static void fatal_error (const char *fmt, ...)
  __attribute__((format (printf, 1, 2)));

// As with 'NLIMITS' above we want to have a central place where we filter
// out cases where message code is not included and then define 'NMESSAGE.

#ifdef NBUMP
#ifdef NELIMINATION
#ifdef NSWITCH
#ifdef NREDUCE
#ifdef NREPHASE
#ifdef NRESTART
#ifdef NTARGET
#define NMESSAGE
#endif
#endif
#endif
#endif
#endif
#endif
#endif

#ifndef NMESSAGE

static void message (struct satch *,
		     unsigned level, const char *name, uint64_t count,
		     const char *fmt, ...)
  __attribute__((format (printf, 5, 6)));

#endif

#ifdef LOGGING

static void logging_message (struct satch *, const char *fmt, ...)
  __attribute__((format (printf, 2, 3)));

#ifndef NVIRTUAL

static void logging_binary (struct satch *solver,
			    bool redundant, unsigned lit, unsigned other,
			    const char *fmt, ...)
  __attribute__((format (printf, 5, 6)));

#endif

#ifndef NBLOCK

static void logging_tagged (struct satch *solver, unsigned lit,
			    struct clause *, const char *fmt, ...)
  __attribute__((format (printf, 4, 5)));

#endif

static void logging_clause (struct satch *, struct clause *,
			    const char *fmt, ...)
  __attribute__((format (printf, 3, 4)));

static void logging_temporary (struct satch *, const char *fmt, ...)
  __attribute__((format (printf, 2, 3)));

#endif

/*------------------------------------------------------------------------*/

// This section contains error, verbose and logging messages.

// Fatal error message printed to '<stderr>' followed by an 'abort' call.

static void
fatal_error (const char *fmt, ...)
{
  COLORS (2);
  va_list ap;
  fprintf (stderr, "%slibsatch: %sfatal error: %s", BOLD, RED, NORMAL);
  va_start (ap, fmt);
  vfprintf (stderr, fmt, ap);
  va_end (ap);
  fputc ('\n', stderr);
  fflush (stderr);
  abort ();
}

// Running out-of-memory is a common fatal error message.

static void
out_of_memory (size_t bytes)
{
  fatal_error ("out-of-memory allocating %zu bytes", bytes);
}

#ifndef NMESSAGE

// Print a verbose message with the given verbose level.

static void
message (struct satch *solver,
	 unsigned level, const char *name, uint64_t count,
	 const char *fmt, ...)
{
  if (solver->options.verbose < level)
    return;
  fputs ("c ", stdout);
  printf ("[%s-%" PRIu64 "] ", name, count);
  va_list ap;
  va_start (ap, fmt);
  vprintf (fmt, ap);
  va_end (ap);
  fputc ('\n', stdout);
  fflush (stdout);
}

#endif

// Print nicely formatted 'c ---- [ <name> ] ----- ... ' section start line.

static void
internal_section (struct satch *solver, const char *name)
{
  assert (solver);
  if (solver->statistics.sections)
    fputs ("c\n", stdout);
  INC (sections);
  COLORS (1);
  fputs ("c ", stdout);
  COLOR (BLUE);
  fputs ("---- [ ", stdout);
  COLOR (BOLD);
  fputs (name, stdout);
  COLOR (NORMAL);
  COLOR (BLUE);
  fputs (" ] ", stdout);
  for (size_t i = strlen (name); i < 66; i++)
    putc ('-', stdout);
  COLOR (NORMAL);
  fputs ("\nc\n", stdout);
  fflush (stdout);
}

#if (!defined(NBLOCK) && (defined(LOGGING) || !defined(NUSED))) \
||  (!defined(NVIRTUAL) && (!defined(NDEBUG) || !defined(NSUBSUMPTION)))

static bool
is_temporary_binary (struct satch *solver, struct clause *c)
{
  return c == solver->binary || c == solver->binary + 1;
}

#endif

#ifdef LOGGING

// Logging functions are only compiled in debugging mode and then still need
// to be enabled at run-time (with '-l' or 'satch_enable_logging_messages').

static void
logging_prefix (struct satch *solver)
{
  COLORS (1);
  COLOR (MAGENTA);
  assert (solver->options.logging);
  printf ("c LOG %u ", solver->level);
}

#define logging_format(fmt) \
do { \
  va_list ap; \
  va_start (ap, fmt); \
  vprintf (fmt, ap); \
  va_end (ap); \
} while (0)

static void
logging_suffix (void)
{
  COLORS (1);
  COLOR (NORMAL);
  fputc ('\n', stdout);
  fflush (stdout);
}

// This is the function for default log messages from the 'LOG' macro.
// It prints the SAT-competition comment-line prefix 'c', the string 'LOG',
// then the decision level and finally the actual logging message, all
// separated by spaces.

static void
logging_message (struct satch *solver, const char *fmt, ...)
{
  logging_prefix (solver);
  logging_format (fmt);
  logging_suffix ();
}

static size_t
format_literal (struct satch *solver, char *res, unsigned ilit)
{
  const int tmp = solver->values[ilit];
  const int elit = export_literal (ilit);

  if (!tmp)
    return sprintf (res, "%u(%d)", ilit, elit);

  const unsigned iidx = INDEX (ilit);
  const unsigned level = solver->levels[iidx];
  return sprintf (res, "%u(%d)@%u=%d", ilit, elit, level, tmp);
}

static char *
next_format (struct satch *solver)
{
  char *res = solver->format[solver->next_format++];

  if (solver->next_format == sizeof solver->format / sizeof solver->format[0])
    solver->next_format = 0;

  return res;
}

static const char *
logging_literal (struct satch *solver, unsigned lit)
{
  char *res = next_format (solver);
  (void) format_literal (solver, res, lit);
  return res;
}

static const char *
logging_variable (struct satch *solver, unsigned idx)
{
  char *res = next_format (solver);
  char *tmp = res + sprintf (res, "variable %u literal ", idx);
  const unsigned lit = LITERAL (idx);
  (void) format_literal (solver, tmp, lit);
  return res;
}

#define LOGLIT(LIT) logging_literal (solver, (LIT))
#define LOGVAR(IDX) logging_variable (solver, (IDX))

#ifndef NVIRTUAL

// For virtual binary clauses we need special logging functions too.

static void
logging_binary (struct satch *solver,
		bool redundant, unsigned lit, unsigned other,
		const char *fmt, ...)
{
  logging_prefix (solver);
  logging_format (fmt);
  if (redundant)
    printf (" redundant");
  else
    printf (" irredundant");
  printf (" binary clause %s %s", LOGLIT (lit), LOGLIT (other));
  logging_suffix ();
}

#endif

// After printing in essence the same message as the basic logging function
// above this clause logging function conveniently prints the type of the
// clause given as argument, its glue (if redundant), its size and literals.

static void
logging_clause (struct satch *solver, struct clause *c, const char *fmt, ...)
{
  logging_prefix (solver);
  logging_format (fmt);
#ifndef NBLOCK
  // With blocking literals enabled we use the temporary binary clause for
  // binary reasons and binary conflicts.  This clause needs special
  // treatment here since its identifier is invalid (always zero).
  if (is_temporary_binary (solver, c))
    printf (" temporary binary clause");
  else
#endif
    {
      if (c->redundant)
	{
	  printf (" redundant");
#ifndef NGLUE
	  printf (" glue %u", c->glue);
#endif
	}
      else
	printf (" irredundant");
      printf (" size %u clause[%" PRIu64 "]", c->size, c->id);
    }
  for (all_literals_in_clause (lit, c))
    printf (" %s", LOGLIT (lit));
  logging_suffix ();
}

// The temporary clause 'solver->clause' is logged here.

static void
logging_temporary (struct satch *solver, const char *fmt, ...)
{
  logging_prefix (solver);
  logging_format (fmt);
  printf (" size %zu temporary clause", SIZE_STACK (solver->clause));
  for (all_elements_on_stack (unsigned, lit, solver->clause))
      printf (" %s", LOGLIT (lit));
  logging_suffix ();
}

#define LOG(...) \
do { \
  if (solver->options.logging) \
    logging_message (solver, __VA_ARGS__); \
} while (0)

#ifndef NVIRTUAL

// Log binary clauses (give the two literals first).

#define LOGBIN(...) \
do { \
  if (solver->options.logging) \
    logging_binary (solver, __VA_ARGS__); \
} while (0)

#endif

#ifndef NBLOCK

#define LOGTAGGED(...) \
do { \
  if (solver->options.logging) \
    logging_tagged (solver, __VA_ARGS__); \
} while (0)

#endif

// Log large clauses (first argument is the clause).

#define LOGCLS(...) \
do { \
  if (solver->options.logging) \
    logging_clause (solver, __VA_ARGS__); \
} while (0)

// Log the temporary clause in the solver.

#define LOGTMP(...) \
do { \
  if (solver->options.logging) \
    logging_temporary (solver, __VA_ARGS__); \
} while (0)

#else

// Make sure not to include logging code if 'LOGGING' is undefined.

#define LOG(...) do { (void) solver; } while(0)
#define LOGBIN(...) do { (void) solver; } while(0)
#define LOGTAGGED(...) do { (void) solver; } while(0)
#define LOGCLS(...) do { (void) solver; } while(0)
#define LOGTMP(...) do { (void) solver; } while(0)

#endif

/*------------------------------------------------------------------------*/

// This is a section of rather Unix specific code which might require some
// porting effort if building on other operating systems.  On the other hand
// it is only used for diagnostic purposes and in principle can be removed.

// Process time since starting the process.

static double
process_time (void)
{
  struct rusage u;
  double res;
  if (getrusage (RUSAGE_SELF, &u))
    return 0;
  res = u.ru_utime.tv_sec + 1e-6 * u.ru_utime.tv_usec;
  res += u.ru_stime.tv_sec + 1e-6 * u.ru_stime.tv_usec;
  return res;
}

// The maximum amount of memory used by this process as seen by the system.

static uint64_t
maximum_resident_set_size (void)
{
  struct rusage u;
  if (getrusage (RUSAGE_SELF, &u))
    return 0;
  return ((uint64_t) u.ru_maxrss) << 10;
}

// Current memory used by this process as seen by the system.  This is
// very Linux specific and will not work even on other Unix systems.

uint64_t
current_resident_set_size (void)
{
  char path[48];
  sprintf (path, "/proc/%" PRIu64 "/statm", (uint64_t) getpid ());
  FILE *file = fopen (path, "r");
  if (!file)
    return 0;
  uint64_t dummy, rss;
  int scanned = fscanf (file, "%" PRIu64 " %" PRIu64 "", &dummy, &rss);
  fclose (file);
  return scanned == 2 ? rss * sysconf (_SC_PAGESIZE) : 0;
}

/*------------------------------------------------------------------------*/

// Computing the percentage or 'relative' average between two numbers is
// very common and always needs to be guarded against division by zero.
// Therefore we factor out this check into two simple functions which also
// makes the caller code (usually) more readable.

static double
percent (double a, double b)
{
  return b ? 100.0 * a / b : 0;
}

static double
relative (double a, double b)
{
  return b ? a / b : 0;
}

/*------------------------------------------------------------------------*/

// Macros and functions to 'START' and 'STOP' profiling a function.

// References to profiles are pushed on the profile stack in order to
// include time spent in a function in case that function is interrupted
// ('START' issued but interrupted without the corresponding 'STOP').

// Having this profiling information printed in optimized code running on a
// full set of benchmarks is very important to find performance regressions.

#define START(NAME) \
  start_profiling (solver, &solver->profiles.NAME)

#define STOP(NAME) \
  stop_profiling (solver, &solver->profiles.NAME, process_time ())

static void
init_profiles (struct satch *solver)
{
  struct profiles *profiles = &solver->profiles;
  profiles->end = profiles->begin;
#define PROFILE(NAME) \
  profiles->NAME.name = #NAME;
  PROFILES
#undef PROFILE
}

static void
start_profiling (struct satch *solver, struct profile *profile)
{
  struct profiles *profiles = &solver->profiles;
  const double start = process_time ();
  profile->start = start;
  assert (profiles->end < profiles->begin + MAX_PROFILES);
  *profiles->end++ = profile;
}

// Starting and stopping a profile has to follow a block structure, i.e.,
// the corresponding 'STOP' has be to called in reverse order of 'START'.

// For instance 'START (A); START (B); ...; STOP (A); STOP (B);' is correct
// but interleaving not ('START (A); START (B); ...; STOP (A); STOP (B);').

// In order to simplify testing and debugging violations of this rule we
// explicitly ask the caller to specify the stopped profile, even though in
// principle it could be derived from the top of the profile stack.

static double
stop_profiling (struct satch *solver, struct profile *profile, double stop)
{
  struct profiles *profiles = &solver->profiles;
  assert (TOP (*profiles) == profile);
  const double time = stop - profile->start;
  profile->time += time;
  (void) POP (*profiles);
  return time;
}

// If interrupted, flush all pending unfinished profiles with the current
// process time.  In order to avoid calling 'getrusage' too often in this
// (often critical and time-constrained) situation we have the current time
// as argument to 'stop_profiling'.

static double
flush_profiles (struct satch *solver)
{
  struct profiles *profiles = &solver->profiles;
  const double stop = process_time ();
  while (!EMPTY_STACK (*profiles))
    stop_profiling (solver, TOP (*profiles), stop);
  profiles->total.time = profiles->parse.time + profiles->solve.time;
  return stop;
}

// Printing the profile information first sorts them according to time.

// We use our own bubble-sort since, first, the number of profiles is small
// and more importantly we do not want to allocate heap memory (usually
// required by implementations of 'qsort') because this function should only
// work with already existing memory.

// Consider for instance the case where it was called from an interrupt
// handler catching a segmentation-fault due to out-of-memory.  Then calling
// an external sorting function might trigger another segmentation-fault and
// we will not see the profiling information.  This is bad because for an
// out-of-memory run the profiling information might be particularly useful.

static double
print_profiles (struct satch *solver)
{
  // First flush all timing information (stop all pending profiles).

  const double stop = flush_profiles (solver);

  internal_section (solver, "profiling");	// As early as possible.

  // Then add all profiles to the (pre-allocated) profiles stack skipping
  // those without any time spent in it (unless verbose level is larger 1).

  struct profiles *profiles = &solver->profiles;
  const bool verbose = solver->options.verbose > 1;
  assert (EMPTY_STACK (*profiles));

// *INDENT-OFF*

#define PROFILE(NAME) \
do { \
    struct profile * profile = &profiles->NAME; \
    if (profile == &profiles->total) \
      break; \
    if (!verbose && !profile->time) \
      break; \
    assert (profiles->end < profiles->begin + MAX_PROFILES); \
    *profiles->end++ =  &profiles->NAME; \
} while (0);

  PROFILES
#undef PROFILE

// *INDENT-ON*

  // Sort profiles with respect to time used and name as tie breaker.

  const size_t size = SIZE_STACK (*profiles);
  for (size_t i = 0; i < size; i++)
    {
      struct profile *p = profiles->begin[i];
      for (size_t j = i + 1; j < size; j++)
	{
	  struct profile *q = profiles->begin[j];
	  if (p->time < q->time ||
	      (p->time == q->time && strcmp (p->name, q->name) > 0))
	    {
	      profiles->begin[i] = q;
	      profiles->begin[j] = p;
	      p = q;
	    }
	}
    }

  // Finally print the profile information in sorted order.

  const double total = profiles->total.time;
  for (size_t i = 0; i < size; i++)
    {
      struct profile *p = profiles->begin[i];
      printf ("c %14.2f  %6.2f %%  %s\n",
	      p->time, percent (p->time, total), p->name);

    }
  fputs ("c =============================================\n", stdout);
  printf ("c %14.2f  %6.2f %%  total\n", total, 100.0);

  return stop;
}

/*------------------------------------------------------------------------*/

static void
print_statistics (struct satch *solver, double seconds)
{
  internal_section (solver, "statistics");
  struct statistics s = solver->statistics;
  const bool verbose = solver->options.verbose > 1;

  // Factored out parts of the formatting string.

#define F1 "c %-24s"		// Prefix plus left justified name.
#define L2 "17"			// First number column (absolute values).
#define L3 "17"			// Second number column (absolute values).
#define P3 "14"			// Second number column (relative / percent).

  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 "s clauses\n", "added:", s.added, "");
#ifndef NBEST
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "bests:",
	  s.bests, relative (s.conflicts, s.bests));
#endif
#ifndef NBUMP
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f literals\n", "bumped:",
	    s.bumped, relative (s.bumped, s.conflicts));
#endif
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f MB\n", "collected:",
	  s.collected, s.collected / (double) (1u << 20));
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f per second\n", "conflicts:",
	  s.conflicts, relative (s.conflicts, seconds));
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f per conflict\n", "decisions:",
	  s.decisions, relative (s.decisions, s.conflicts));
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f literals\n", "deduced:",
	    s.deduced, relative (s.deduced, s.conflicts));
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  added\n", "deleted:",
	    s.deleted, percent (s.deleted, s.added));
#ifndef NELIMINATION
  printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  variables\n", "eliminated:",
	  s.eliminated, percent (s.eliminated, s.variables));
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "eliminations:",
	    s.eliminations, relative (s.conflicts, s.eliminations));
#endif
  printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  variables\n", "fixed:",
	  s.fixed, percent (s.fixed, s.variables));
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f literals\n", "learned:",
	  s.learned, relative (s.learned, s.conflicts));
#ifndef NVSIDS
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  bumped\n", "incremented:",
	    s.incremented, percent (s.incremented, s.bumped));
#endif
#ifndef NMINIMIZE
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  deduced\n", "minimized:",
	    s.minimized, percent (s.minimized, s.deduced));
#endif
#ifndef NVMTF
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  bumped\n", "moved:",
	    s.moved, percent (s.moved, s.bumped));
#endif
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f per second\n", "propagations:",
	  s.propagations, relative (s.propagations, seconds));
#ifndef NBUMPREASONS
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  bumped\n", "reasons:",
	    s.reasons, percent (s.reasons, s.bumped));
#endif
#ifndef NREDUCE
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f per reduction\n", "reduced:",
	  s.reduced, relative (s.reduced, s.reductions));
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "reductions:",
	    s.reductions, relative (s.conflicts, s.reductions));
#endif
#ifndef NREPHASE
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "rephased:",
	  s.rephased, relative (s.conflicts, s.rephased));
#endif
#ifndef NVSIDS
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "rescored:",
	  s.rescored, relative (s.conflicts, s.rescored));
#endif
#ifndef NVMTF
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "restamped:",
	  s.restamped, relative (s.conflicts, s.restamped));
#endif
#ifndef NELIMINATION
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f per variable\n", "resolutions:",
	  s.resolutions, relative (s.resolutions, s.variables));
#endif
#ifndef NRESTART
  printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "restarts:",
	  s.restarts, relative (s.conflicts, s.restarts));
#endif
#ifndef NREUSE
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  restarts\n", "reused:",
	    s.reused, percent (s.reused, s.restarts));
#endif
#ifndef NSHRINK
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  deduced\n", "shrunken:",
	    s.shrunken, percent (s.shrunken, s.deduced));
#endif
#ifndef NSUBSUMPTION
  printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  added\n", "strengthened:",
	  s.strengthened, percent (s.strengthened, s.added));
  printf (F1 " %" L2 PRIu64 " %" P3 ".0f %%  added\n", "subsumed:",
	  s.subsumed, percent (s.subsumed, s.added));
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "subsumptions:",
	    s.subsumptions, relative (s.conflicts, s.subsumptions));
#endif
#ifndef NSWITCH
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "switched:",
	    s.switched, relative (s.conflicts, s.switched));
#endif
#ifndef NTARGET
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f interval\n", "targets:",
	    s.targets, relative (s.conflicts, s.targets));
#endif
  if (verbose)
    printf (F1 " %" L2 PRIu64 " %" L3 ".2f per propagation\n", "ticks:",
	    s.ticks, relative (s.ticks, s.propagations));
}

static void
print_resource_usage (struct satch *solver, double seconds)
{
  internal_section (solver, "resources");
  const uint64_t memory = maximum_resident_set_size ();
  printf ("c %-24s %17" PRIu64 " bytes %11.2f MB\n",
	  "memory:", memory, memory / (double) (1 << 20));
  printf ("c %-24s %17s %17.2f seconds\n", "time:", "", seconds);
}

/*------------------------------------------------------------------------*/

// Print DRAT (actually DRUP) proof lines to the given proof file.

// These lines are either clause additions or clause deletions and either a
// binary or ASCII format is used.  The binary format distinguishes
// additions from deletions by a leading 'a' respectively 'd' (ASCII)
// character, while the ASCII format just adds a 'd ' prefix (note the space
// after 'd') for clause deletion.

// After that the literals are printed.  The binary format uses a dynamic
// word length for numbers while the ASCII format looks like the DIMACS
// format. The end of a proof line is indicated by zero (then number zero
// '0' in the ASCII format and the zero byte in the binary format).

static void
start_addition_proof_line (struct satch *solver)
{
  assert (solver->proof);
  if (!solver->options.ascii)
    fputc ('a', solver->proof);
}

static void
start_deletion_proof_line (struct satch *solver)
{
  assert (solver->proof);
  fputc ('d', solver->proof);
  if (solver->options.ascii)
    fputc (' ', solver->proof);
}

static void
add_external_literal_to_proof_line (struct satch *solver, int elit)
{
  assert (solver->proof);
  if (solver->options.ascii)
    fprintf (solver->proof, "%d ", elit);
  else
    {
      // This is almost like our internal literal encoding except that it is
      // shifted by two, since zero is used as sentinel of a proof line.

      assert (2u * INT_MAX + 1 == UINT_MAX);	// Overflow for 'INT_MAX'.

      const unsigned plit = 2u * abs (elit) + (elit < 0);

      // Now this proof literal 'plit' is written 7-bit wise to the file.

      // The 8th most significant bit of the actual written byte denotes
      // whether further non-zero bits, so at least one more byte, follow.

      unsigned rest = plit;

      while (rest & ~0x7f)
	{
	  const unsigned char byte = (rest & 0x7f) | 0x80;
	  fputc (byte, solver->proof);
	  rest >>= 7;
	}

      fputc ((unsigned char) rest, solver->proof);
    }
}

static void
add_internal_literal_to_proof_line (struct satch *solver, unsigned ilit)
{
  const int elit = export_literal (ilit);
  add_external_literal_to_proof_line (solver, elit);
}

static void
end_proof_line (struct satch *solver)
{
  assert (solver->proof);
  if (solver->options.ascii)
    fputs ("0\n", solver->proof);
  else
    fputc (0, solver->proof);
  fflush (solver->proof);
}

/*------------------------------------------------------------------------*/

// The following functions combine both proof tracing and checking with the
// internal checker the addition and deletion of a given clause.  For
// addition proof and checker make sure that the clause is implied (through
// unit propagation) and for deletion it is first checked that the clause
// has been added before or was added as original clause and has not been
// deleted yet (followed by actually deleting it in the proof and checker).

// Trace and check addition of the clause given as array.

static void
trace_and_check_addition (struct satch *solver,
			  size_t size, unsigned *literals, unsigned except)
{
  if (solver->proof)
    {
      start_addition_proof_line (solver);
      for (all_elements_in_array (unsigned, lit, size, literals))
	if (lit != except)
	    add_internal_literal_to_proof_line (solver, lit);
      end_proof_line (solver);
    }
#ifndef NDEBUG
  for (all_elements_in_array (unsigned, lit, size, literals))
    if (lit != except)
        checker_add_literal (solver->checker, export_literal (lit));
  checker_add_learned_clause (solver->checker);
#endif
}

// Trace and check deletion of the clause given as array.

static void
trace_and_check_deletion (struct satch *solver,
			  size_t size, unsigned *literals)
{
  if (solver->proof)
    {
      start_deletion_proof_line (solver);
      for (all_elements_in_array (unsigned, lit, size, literals))
	  add_internal_literal_to_proof_line (solver, lit);
      end_proof_line (solver);
    }
#if !defined(NDEBUG) && !defined(NLEARN)
  for (all_elements_in_array (unsigned, lit, size, literals))
      checker_add_literal (solver->checker, export_literal (lit));
  checker_delete_clause (solver->checker);
#endif
}

static void
trace_and_check_empty_addition (struct satch *solver)
{
  trace_and_check_addition (solver, 0, 0, INVALID);
}

static void
trace_and_check_unit_addition (struct satch *solver, unsigned unit)
{
  trace_and_check_addition (solver, 1, &unit, INVALID);
}

// Trace and check the temporary clause as being added.

static void
trace_and_check_temporary_addition (struct satch *solver)
{
  const size_t size = SIZE_STACK (solver->clause);
  trace_and_check_addition (solver, size, solver->clause.begin, INVALID);
}

#if !defined(NVIRTUAL) && \
    (!defined(NREDUCE) || !defined(NDEBUG) || !defined(NELIMINATION))

static void
trace_and_check_binary_deletion (struct satch *solver,
				 unsigned lit, unsigned other)
{
  unsigned literals[2] = { lit, other };
  trace_and_check_deletion (solver, 2, literals);
}

#endif

#ifndef NSTRENGTHENING

static void
trace_and_check_clause_addition (struct satch *solver,
				 struct clause *c, unsigned remove)
{
  trace_and_check_addition (solver, c->size, c->literals, remove);
}

#endif

static void
trace_and_check_clause_deletion (struct satch *solver, struct clause *c)
{
  trace_and_check_deletion (solver, c->size, c->literals);
}

/*------------------------------------------------------------------------*/

// Allocate the actual clause data memory and depending on whether we embed
// the literals directly into the clause using a variadic array member just
// allocate one chunk of memory or otherwise the literals separately.

#ifndef NVARIADIC

static size_t
bytes_clause (size_t size)
{
  assert (size > 1);
  return sizeof (struct clause) + (size - 2) * sizeof (unsigned);
}

// This default variadic variant just allocates one chunk of memory.

static struct clause *
allocate_clause (size_t size)
{
  const size_t bytes = bytes_clause (size);
  struct clause *res = malloc (bytes);
  if (!res)
    out_of_memory (bytes);
  return res;
}

static size_t
deallocate_clause (struct clause *c)
{
  const size_t bytes = bytes_clause (c->size);
  free (c);
  return bytes;
}

#else

// The non-variadic variant has to allocate two memory blocks.

static struct clause *
allocate_clause (size_t size)
{
  const size_t header_bytes = sizeof (struct clause);
  struct clause *res = malloc (header_bytes);
  if (!res)
    out_of_memory (header_bytes);
  const size_t literals_bytes = size * sizeof (unsigned);
  res->literals = malloc (literals_bytes);
  if (!res->literals)
    out_of_memory (literals_bytes);
  return res;
}

static size_t
deallocate_clause (struct clause *c)
{
  const size_t header_bytes = sizeof (struct clause);
  const size_t literals_bytes = c->size * sizeof (unsigned);
  free (c->literals);
  free (c);
  return header_bytes + literals_bytes;
}

#endif

/*------------------------------------------------------------------------*/

// Adding and deleting clauses.

// We start with the shared clause allocation function 'add_clause'.

static struct clause *
#ifndef NGLUE
add_clause (struct satch *solver, bool redundant, unsigned glue)
#else
add_clause (struct satch *solver, bool redundant)
#endif
{
#if defined(LOGGING) || defined(NRADIXSORT)
  const uint64_t added =
#endif
    INC (added);
  const size_t size = SIZE_STACK (solver->clause);
#ifdef NVIRTUAL
  assert (size > 1);		// Units and empty clauses are implicit.
#else
  assert (size > 2);		// No binary clauses allocated at all!
#endif
  struct clause *res = allocate_clause (size);
#if defined(LOGGING) || defined(NRADIXSORT)
  res->id = added;
#endif
  res->garbage = false;
  res->protected = false;
  res->redundant = redundant;
#ifndef NUSED
  res->used = 0;
#endif
#ifndef NSUBSUMPTION
  res->subsumed = false;
#endif
#ifdef NWATCHES
  res->sum = 0;
  res->count = 0;
#endif
#ifndef NGLUE
  res->glue = glue;
#endif
#ifndef NCACHE
  res->search = 0;
#endif
  res->size = size;
  memcpy (res->literals, solver->clause.begin, size * sizeof (unsigned));
  return res;
}

static struct clause *
new_irredundant_clause (struct satch *solver)
{
#ifndef NGLUE
  struct clause *res = add_clause (solver, false, 0);
#else
  struct clause *res = add_clause (solver, false);
#endif
  PUSH (solver->irredundant, res);
  INC (irredundant);
  return res;
}

static struct clause *
#ifndef NGLUE
new_redundant_clause (struct satch *solver, unsigned glue)
#else
new_redundant_clause (struct satch *solver)
#endif
{
#ifndef NGLUE
  struct clause *res = add_clause (solver, true, glue);
#else
  struct clause *res = add_clause (solver, true);
#endif
#ifndef NLEARN
  PUSH (solver->redundant, res);
#endif
  INC (redundant);
  return res;
}

// Deleting clauses beside deallocation implicitly also triggers adding a
// deletion line to the proof (if tracing is enabled) and in debugging
// compilation mode also deletes the clause from the internal proof checker.

// This is in contrast to adding clauses to the proof and the checker which
// has to be done explicitly by the caller of the 'new_...' functions above.

static size_t
delete_clause (struct satch *solver, struct clause *c)
{
  INC (deleted);
  LOGCLS (c, "delete");
  if (!c->garbage)
    {
      trace_and_check_clause_deletion (solver, c);
      if (c->redundant)
	DEC (redundant);
      else
	DEC (irredundant);
    }
  return deallocate_clause (c);
}

/*------------------------------------------------------------------------*/

// Watch a literal 'lit' in a clause with blocking literal 'other'.

#ifndef NBLOCK

static void
watch_literal (struct satch *solver, bool redundant,
	       unsigned lit, unsigned blocking, struct clause *c)
{
  assert (!solver->dense);
  struct watches *watches = solver->watches + lit;
  union watch watch;
  watch.header.binary = (c->size == 2);
  watch.header.redundant = redundant;
  watch.header.blocking = blocking;
  LOGCLS (c, "watching %s blocking %s in", LOGLIT (lit), LOGLIT (blocking));
  PUSH (*watches, watch);
  watch.clause = c;
  PUSH (*watches, watch);
}

#elif !defined(NWATCHES)

static void
watch_literal (struct satch *solver, unsigned lit, struct clause *c)
{
  assert (!solver->dense);
  struct watches *watches = solver->watches + lit;
  union watch watch;
  LOGCLS (c, "watching %s in", LOGLIT (lit));
  watch.clause = c;
  PUSH (*watches, watch);
}

#endif

#if !defined(NREDUCE) || !defined(NELIMINATION)

#ifndef NBLOCK

static void
unwatch_literal (struct satch *solver, unsigned lit, struct clause *c)
{
  assert (!solver->dense);
  struct watches *watches = solver->watches + lit;
  const union watch *const end = watches->end;
  union watch *q = watches->begin;
  for (;;)
    {
      assert (q != end);
#if !defined(NVIRTUAL) || defined(LOGGING)
      const union watch watch = *q++;
      const struct header header = watch.header;
#endif
#ifndef NVIRTUAL
      if (header.binary)
	continue;
#endif
      const struct clause *d = q++->clause;
      if (c == d)
	{
	  LOGCLS (c, "unwatching %s blocking %s in",
		  LOGLIT (lit), LOGLIT (header.blocking));
	  break;
	}
    }
  while (q != end)
    q[-2] = *q, q++;
  watches->end -= 2;
}

#elif !defined(NWATCHES)

static void
unwatch_literal (struct satch *solver, unsigned lit, struct clause *c)
{
  assert (!solver->dense);
  struct watches *watches = solver->watches + lit;
  const union watch *const end = watches->end;
  union watch *q = watches->begin;
  for (;;)
    {
      assert (q != end);
      const struct clause *d = q++->clause;
      if (c == d)
	{
	  LOGCLS (c, "unwatching %s in", LOGLIT (lit));
	  break;
	}
    }
  while (q != end)
    q[-1] = *q, q++;
  watches->end--;
}

#endif

#endif

#ifndef NWATCHES

// Watch first two literals in the clause.

static void
watch_clause (struct satch *solver, struct clause *c)
{
  assert (!solver->dense);
  assert (c->size > 1);
  const unsigned lit = c->literals[0];
  const unsigned other = c->literals[1];
#ifndef NBLOCK
  const bool redundant = c->redundant;
  watch_literal (solver, redundant, lit, other, c);
  watch_literal (solver, redundant, other, lit, c);
#else
  watch_literal (solver, lit, c);
  watch_literal (solver, other, c);
#endif
}

#endif

/*------------------------------------------------------------------------*/

#ifndef NBLOCK

// With blocking literals we do not have to store clauses as reasons. At the
// same time (since this is used for compact watch data structures anyhow)
// we also use the temporary binary clause for conflicting binary clauses.

static void
init_binary (struct satch *solver)
{
  for (unsigned i = 0; i < 2; i++)
    {
      struct clause *binary = solver->binary + i;
      binary->size = 2;
#ifdef NVARIADIC
      const size_t bytes = 2 * sizeof (unsigned);
      if (!(binary->literals = malloc (bytes)))
	out_of_memory (bytes);
#endif
    }
}

static void
release_binary (struct satch *solver)
{
#ifdef NVARIADIC
  for (unsigned i = 0; i < 2; i++)
    free (solver->binary[i].literals);
#else
  (void) solver;		// Prevent unused 'solver' warning.
#endif
}

// Copy 'lit' and 'other' to one of the two temporary binary clauses in the
// solver.  This is used for generating a binary clause conflict (if
// 'NBLOCK' is undefined) and through 'untag_clause' to unify the conflict
// analysis code with and without 'NBLOCK'.

static struct clause *
binary_clause (struct satch *solver, unsigned pos,
	       bool redundant, unsigned lit, unsigned other)
{
  assert (pos == 0 || pos == 1);
  struct clause *res = solver->binary + pos;
  assert (!res->garbage);
  assert (res->size == 2);
  res->redundant = redundant;
  res->literals[0] = lit;
  res->literals[1] = other;
  return res;
}

/*------------------------------------------------------------------------*/

// We want to only have one global 'reason' array in which we store both
// binary clause reasons (which consists of just the other literal) as well
// as pointers to large clause.  We distinguish those by 'stuffing' a bit
// into the clause pointer.  In case the least-significant bit is set then
// the rest of the 'reason' pointer forms the other literal.  Otherwise it
// is the actual pointer to a large clause.

// Note that the least two significant bits of a pointer are zero on all
// systems we have seen and this is a common idiom anyhow (for instance in
// AIG and BDD packages). For logging we thus can also use the second least
// significant bit for storing whether the binary (reason) is redundant.

// Some technical details follow on why this scheme works perfectly well on
// 64-bit machines.  On such machines pointer size is twice the size of
// 'unsigned' literals and the 32-bit variable-index easily fits into the
// upper 62 bits of a reason pointer.  On 32-bit machines this might break
// for literals larger equal to 2^30 which is however prevented by raising
// an API contract violation, when trying to import a variable of size
// larger than 2^29.  Thus on 32-bit machines we 'only' have 2^29 variables.
// Trying to reach this limit on a 32-bit machine would probably lead to
// a memory overflow much earlier anyhow.

static bool
is_tagged_clause (const struct clause *const c)
{
  uintptr_t word = (uintptr_t) c;
  return !!(word & 3);
}

static struct clause *
tag_binary_clause (bool redundant, uintptr_t other)
{
  const uintptr_t tmp = (other << 2) | 1 | (redundant << 1);
  struct clause *res = (struct clause *) tmp;
  assert (is_tagged_clause (res));
  return res;
}

static unsigned
tagged_clause_to_literal (const struct clause *c)
{
  assert (is_tagged_clause (c));
  const uintptr_t tmp = (uintptr_t) c;
  const unsigned res = tmp >> 2;
  return res;
}

static unsigned
tagged_clause_to_redundant (const struct clause *c)
{
  assert (is_tagged_clause (c));
  const uintptr_t tmp = (uintptr_t) c;
  const bool res = !!(tmp & 2);
  return res;
}

#if defined(LOGGING)

static void
logging_tagged (struct satch *solver, unsigned lit,
		struct clause *c, const char *fmt, ...)
{
  const unsigned other = tagged_clause_to_literal (c);
  const bool redundant = tagged_clause_to_redundant (c);
  logging_prefix (solver);
  logging_format (fmt);
  if (redundant)
    printf (" redundant");
  else
    printf (" irredundant");
  printf (" binary clause %s %s", LOGLIT (lit), LOGLIT (other));
  logging_suffix ();
}

#endif

static struct clause *
untag_clause (struct satch *solver,
	      unsigned pos, unsigned lit, const struct clause *c)
{
  assert (is_tagged_clause (c));
  const unsigned other = tagged_clause_to_literal (c);
  const bool redundant = tagged_clause_to_redundant (c);
  return binary_clause (solver, pos, redundant, lit, other);
}

#endif

/*------------------------------------------------------------------------*/

// The following macro increases the array given as argument which either
// comes as variable indexed array ('FACTOR=1') or literal indexed array
// ('FACTOR=2'). This reallocation would be more complex to code for signed
// 'int' literals and is one of the reasons we use 'unsigned' literals.

// The last argument is for 'frames' which should be of size 'size + 1'
// since they are accessed through the solver level, which can reach 'size'
// even though probably not in the situation where 'frames' is accessed.
// Nevertheless we accommodate for this potential off-by-one allocation by
// adding 'ADJUST' to the size.

#define RESIZE_UNINITIALIZED(P) \
do { \
  const size_t new_bytes = (size_t) new_capacity * sizeof *(P); \
  (P) = realloc ((P), new_bytes); \
  if (!(P)) \
    out_of_memory (new_bytes); \
} while (0)

#define RESIZE_ZERO_INITIALIZED(FACTOR,P,ADJUST) \
do { \
  const size_t size = sizeof *(P); \
  const size_t old_bytes = \
    old_capacity ? FACTOR * (size_t) (old_capacity + ADJUST) * size : 0; \
  const size_t new_bytes = FACTOR * (size_t) (new_capacity + ADJUST) * size; \
  void * chunk = calloc (new_bytes, 1); \
  if (!chunk) \
    out_of_memory (new_bytes); \
  if (old_bytes) \
    memcpy (chunk, (P), old_bytes); \
  free ((P)); \
  (P) = chunk; \
} while (0)

/*------------------------------------------------------------------------*/
#ifndef NHEAP
/*------------------------------------------------------------------------*/

// Functions to implement a binary heap with embedded scores and, in
// particular, a score update function used for the priority queue for
// decision variables, i.e., the EVSIDS scheme.

// As with queues this heap might have two instances in the solver but in
// default compilation only one for stable mode is actually used and
// initialized lazily on-demand, i.e., by comparing the solver size with the
// zero initialized 'size'.

#if 0

static void
check_heap (struct heap *heap)
{
#ifndef NDEBUG
  const unsigned size = SIZE_STACK (*heap);
  const unsigned *const begin = heap->begin;
  const unsigned *const pos = heap->pos;
  const double *const score = heap->score;
  for (unsigned i = 0; i < size; i++)
    {
      const unsigned idx = begin[i];
      const unsigned idx_pos = pos[idx];
      assert (idx_pos == i);
      unsigned child_pos = 2 * idx_pos + 1;
      unsigned parent_pos = (child_pos - 1) / 2;
      assert (parent_pos == idx_pos);
      if (child_pos < size)
	{
	  unsigned child = begin[child_pos];
	  assert (score[idx] >= score[child]);
	  if (++child_pos < size)
	    {
	      parent_pos = (child_pos - 1) / 2;
	      assert (parent_pos == idx_pos);
	      child = begin[child_pos];
	      assert (score[idx] >= score[child]);
	    }
	}
    }
#else
  (void) heap;			// Prevent unsigned 'heap' warning.
#endif
}

#else
#define check_heap(...) do { } while (0)
#endif

static void
bubble_up (struct satch *solver, struct heap *heap, unsigned idx)
{
  unsigned *stack = heap->begin;
  unsigned *pos = heap->pos;
  unsigned idx_pos = pos[idx];
  const double *const score = heap->score;
  const double idx_score = score[idx];
  while (idx_pos)
    {
      const unsigned parent_pos = (idx_pos - 1) / 2;
      const unsigned parent = stack[parent_pos];
      const double parent_score = score[parent];
      if (parent_score >= idx_score)
	break;

      LOG ("swap heap[%u] = %u (%g) with heap[%u] = %u (%g)",
	   idx_pos, idx, idx_score, parent_pos, parent, parent_score);

      stack[idx_pos] = parent;
      pos[parent] = idx_pos;
      idx_pos = parent_pos;
    }
  stack[idx_pos] = idx;
  pos[idx] = idx_pos;
  LOG ("settled to heap[%u] = %u (%g)", idx_pos, idx, idx_score);
  check_heap (heap);
}

static void
bubble_down (struct satch *solver, struct heap *heap, unsigned idx)
{
  const double *score = heap->score;
  unsigned *begin = heap->begin;
  unsigned *pos = heap->pos;

  const unsigned size = SIZE_STACK (*heap);

  const double idx_score = score[idx];
  unsigned idx_pos = pos[idx];

  for (;;)
    {
      unsigned child_pos = 2 * idx_pos + 1;
      if (child_pos >= size)
	break;

      unsigned child = begin[child_pos];
      double child_score = score[child];

      const unsigned sibling_pos = child_pos + 1;
      if (sibling_pos < size)
	{
	  const unsigned sibling = begin[sibling_pos];
	  const double sibling_score = score[sibling];
	  if (sibling_score > child_score)
	    {
	      child = sibling;
	      child_pos = sibling_pos;
	      child_score = sibling_score;
	    }
	}

      if (child_score <= idx_score)
	break;

      assert (idx_pos < child_pos);
      LOG ("swap heap[%u] = %u (%g) with heap[%u] = %u (%g)",
	   idx_pos, idx, idx_score, child_pos, child, child_score);

      begin[idx_pos] = child;
      pos[child] = idx_pos;
      idx_pos = child_pos;
    }
  begin[idx_pos] = idx;
  pos[idx] = idx_pos;
  LOG ("settled to heap[%u] = %u (%g)", idx_pos, idx, idx_score);
  check_heap (heap);
}

static void
push_heap (struct satch *solver, struct heap *heap, unsigned idx)
{
  const unsigned size = SIZE_STACK (*heap);
  assert (size < solver->size);
  unsigned *pos = heap->pos;
  assert (pos[idx] == INVALID);
  pos[idx] = size;
  *heap->end++ = idx;
  LOG ("push heap[%u] = %u (%g)", size, idx, heap->score[idx]);
  bubble_up (solver, heap, idx);
}

static unsigned
max_heap (struct heap *heap)
{
  return ACCESS (*heap, 0);
}

static unsigned
pop_heap (struct satch *solver, struct heap *heap)
{
  check_heap (heap);
  const unsigned res = max_heap (heap);
  LOG ("pop heap[0] = %u (%g)", res, heap->score[res]);
  unsigned *pos = heap->pos;
  assert (!pos[res]);
  pos[res] = INVALID;
  const unsigned last = POP (*heap);
  if (last == res)
    return res;
  pos[last] = 0;
  heap->begin[0] = last;
  bubble_down (solver, heap, last);
  return res;
}

#ifndef NVSIDS

static void
update_heap (struct satch *solver, struct heap *heap,
	     unsigned idx, double new_score)
{
  check_heap (heap);
  double *score = heap->score;
  const double old_score = score[idx];
  if (old_score < new_score)
    {
      score[idx] = new_score;
      if (heap->pos[idx] != INVALID)
	bubble_up (solver, heap, idx);
    }
  else if (old_score > new_score)
    {
      if (heap->pos[idx] != INVALID)
	bubble_down (solver, heap, idx);
    }
}

static double
heap_score (struct heap *heap, unsigned idx)
{
  return heap->score[idx];
}

static void
rescore_scores (struct satch *solver, struct heap *scores)
{
  const uint64_t rescored = INC (rescored);
  const unsigned size = solver->size;
  double *score = scores->score;
  assert (size);
  double max_score = score[0];
  for (unsigned idx = 1; idx < size; idx++)
    {
      const double tmp_score = score[idx];
      if (tmp_score > max_score)
	max_score = tmp_score;
    }
  assert (max_score);
  message (solver, 2, "rescore", rescored,
	   "rescoring heap with maximum score %g", max_score);
  for (unsigned idx = 0; idx < size; idx++)
    score[idx] /= max_score;
  scores->increment /= max_score;
  message (solver, 3, "rescore", rescored,
	   "new score increment %g", scores->increment);
}

#endif

/*------------------------------------------------------------------------*/

static void
resize_heap (struct heap *heap, size_t old_capacity, size_t new_capacity)
{
  const size_t size = SIZE_STACK (*heap);
  RESIZE_UNINITIALIZED (heap->begin);
  heap->end = heap->begin + size;
  RESIZE_UNINITIALIZED (heap->pos);
  RESIZE_ZERO_INITIALIZED (1, heap->score, 0);
}

static void
release_heap (struct heap *heap)
{
  free (heap->begin);
  free (heap->pos);
  free (heap->score);
  memset (heap, 0, sizeof *heap);
}

static void
init_scores (struct satch *solver, struct heap *scores)
{
  if (!scores->increment)
    scores->increment = 1.0;
  if (!scores->begin)
    resize_heap (scores, 0, solver->capacity);
}

#ifndef NLAZYACTIVATION

// Put variables on the scores binary heap in the order in which the
// variables are activated (found in the input). Since the first activated
// variable is pushed first, activation order gives initial decision order.

// In contrast to MiniSAT and descendants we initialize last activated
// variables with the largest score '1-1/activated', which in essence
// matches the decision order of the queue.

// In MiniSAT almost the same would happen except for the first decision.
// The first decision in MiniSAT is the first variable pushed on the heap.
// After it is taken out (when searching for the next decision), the last
// variable of the heap is swapped with it and thus the last activated
// variable is taken as next decision.  This continues until the first
// conflict is hit, but in principle MiniSAT code loosely matches our
// initialization of scores and how we initialize decision queue.

static void
activate_scores (struct satch *solver, struct heap *scores,
		 struct unsigned_stack *activate)
{
  init_scores (solver, scores);
  const unsigned stable = solver->stable;
  LOG ("activating %zu variables on scores[%u]", SIZE_STACK (*activate),
       stable);
  unsigned *pos = scores->pos;
  double *score = scores->score;
  for (all_elements_on_stack (unsigned, idx, *activate))
    {
      const uint64_t activated = INC (activated[stable]);
      pos[idx] = INVALID;
      score[idx] = 1 - 1.0 / activated;
      push_heap (solver, scores, idx);
    }
  RELEASE_STACK (*activate);
  scores->size = solver->size;
}

#else

// Put variables on the scores binary heap in index order. Without the
// initial score assignment '1-1/filled' below this would match what MiniSAT
// and descendants would do.  See discussion above too.

static void
fill_scores (struct satch *solver, struct heap *scores)
{
  init_scores (solver, scores);
  const unsigned stable = solver->stable;
  LOG ("filling scores[%u] with %zu variables",
       stable, (size_t) (solver->size - scores->size));
  if (scores->size == solver->size)
    return;
  unsigned *pos = scores->pos;
  double *score = scores->score;
  const size_t delta = solver->size - scores->size;
  memset (pos + scores->size, 0xff, delta * sizeof *pos);
  while (scores->size < solver->size)
    {
      const uint64_t filled = INC (filled[stable]);
      const unsigned idx = scores->size++;
      score[idx] = 1 - 1.0 / filled;
      push_heap (solver, scores, idx);
    }
}

#endif

static struct heap *
get_scores (struct satch *solver)
{
  const unsigned stable = solver->stable;
  struct heap *scores = &solver->scores[stable];
#ifndef NLAZYACTIVATION
  struct unsigned_stack *activate = &solver->put[stable];
  if (!EMPTY_STACK (*activate))
    activate_scores (solver, scores, activate);
#else
  if (scores->size < solver->size)
    fill_scores (solver, scores);
#endif
  assert (scores->size == solver->size);
  return scores;
}

#ifndef NVSIDS

static void
bump_variable_score (struct satch *solver, unsigned idx)
{
  INC (incremented);
  struct heap *scores = get_scores (solver);
  const double old_score = heap_score (scores, idx);
  const double new_score = old_score + scores->increment;
  LOG ("bumping score of %s to %g", LOGVAR (idx), new_score);
  update_heap (solver, scores, idx, new_score);
  if (new_score > MAX_SCORE)
    rescore_scores (solver, scores);
}

static void
bump_score_increment (struct satch *solver)
{
  struct heap *scores = get_scores (solver);
  scores->increment *= scores->factor;
  LOG ("new score increment %g", scores->increment);
}

#endif

/*------------------------------------------------------------------------*/
#endif
/*------------------------------------------------------------------------*/

#ifndef NELIMINATION

// Variables which occur in an irredundant clause which is deleted are
// marked as candidates for variable eliminations.

// For instance if a unit clause is learned during search and an irredundant
// clauses becomes satisfied and then during reduction is removed, the other
// variables in such a clause should be retried to be eliminated in the next
// variable elimination round since they now occur less often.

// We also use the 'marked_eliminate' counter to wait in 'eliminating' until
// we really have a chance to eliminate a new variable.

// We have to put this code early since clause deletion calls it.

static void
mark_eliminate_literal (struct satch *solver, unsigned lit)
{
  const unsigned idx = INDEX (lit);
  struct flags *f = solver->flags + idx;
  if (!f->active)
    return;
  if (f->eliminate)
    return;
  LOG ("marking %s as elimination candidate", LOGVAR (idx));
  f->eliminate = true;
  INC (marked_eliminate);
}

static void
mark_eliminate_clause (struct satch *solver, struct clause *c)
{
  for (all_literals_in_clause (lit, c))
    mark_eliminate_literal (solver, lit);
}

#endif

#if !defined(NSUBSUMPTION) && (!defined(NREDUCE) || !defined(NELIMINATION))

// For subsumption a similar approach is used, except that variables are
// considered subsumption candidates if an irredundant clause is added.

static void
mark_subsume_variable (struct satch *solver, unsigned idx)
{
  struct flags *f = solver->flags + idx;
  if (!f->active)
    return;
  if (f->subsume & 1)
    return;
  LOG ("marking %s as subsume candidate", LOGVAR (idx));
  f->subsume |= 1;
  INC (marked_subsume);
}


static void
mark_subsume_literal (struct satch *solver, unsigned lit)
{
  const unsigned idx = INDEX (lit);
  mark_subsume_variable (solver, idx);
}

#endif

/*------------------------------------------------------------------------*/

#ifndef NVIRTUAL

// This section handles virtual binary clauses which only reside in watch
// lists but are not actually allocated. This feature (disabled without
// defining 'NVIRTUAL') can save up to a factor of four in memory usage.

static inline void
watch_binary (struct satch *solver,
	      bool redundant, unsigned lit, unsigned blocking)
{
  union watch watch;
  watch.header.binary = true;
  watch.header.redundant = redundant;
  watch.header.blocking = blocking;
  PUSH (solver->watches[lit], watch);
  LOGBIN (redundant, lit, blocking,
	  "watching %s blocking %s in", LOGLIT (lit), LOGLIT (blocking));
}

static void
add_new_binary_and_watch_it (struct satch *solver, bool redundant)
{
  assert (SIZE_STACK (solver->clause) == 2);
  const unsigned lit = ACCESS (solver->clause, 0);
  const unsigned other = ACCESS (solver->clause, 1);
  watch_binary (solver, redundant, lit, other);
  watch_binary (solver, redundant, other, lit);
  if (redundant)
    INC (redundant);
  else
    INC (irredundant);
}

#if !defined(NREDUCE) || !defined(NDEBUG) || !defined(NELIMINATION)

// In contrast to large clauses deleting virtual binary clauses does not
// deallocate any memory but statistics have to be adapted.  We also need to
// trigger adding deletion lines to proofs and the checker if enabled.  See
// the corresponding discussion before 'delete_clause' above too.  Last but
// not least we have to update counts of literals and 'eliminate' flags.

static void
really_delete_binary (struct satch *solver,
		      bool redundant, unsigned lit, unsigned other)
{
  LOGBIN (redundant, lit, other, "delete");
  trace_and_check_binary_deletion (solver, lit, other);
#ifndef NELIMINATION
  if (!redundant)
    {
      mark_eliminate_literal (solver, lit);
      mark_eliminate_literal (solver, other);
    }
#endif
  if (redundant)
    DEC (redundant);
  else
    DEC (irredundant);
}

static void
delete_binary (struct satch *solver,
	       bool redundant, unsigned lit, unsigned other)
{
  // We watch 'lit' in the watch list of 'other' and vice versa. Thus when
  // we delete these virtual binary clauses (residing only in watch lists)
  // we do not know which of the two cases we encounter first but both
  // occurrences should trigger 'delete_binary'.  Thus we delete the virtual
  // binary clause only once when 'lit' is smaller than 'other'.

  if (lit < other)
    really_delete_binary (solver, redundant, lit, other);
}

#endif

#ifndef NDEBUG

// Short-hand only used in 'internal_release' in debugging mode.

static void
delete_header (struct satch *solver, unsigned lit, struct header header)
{
  const bool redundant = header.redundant;
  const unsigned blocking = header.blocking;
  delete_binary (solver, redundant, lit, blocking);
}

#endif

#endif // of '#ifndef NVIRTUAL'

/*------------------------------------------------------------------------*/

static void
mark_garbage (struct satch *solver, struct clause *c, const char *msg)
{
#ifndef NVIRTUAL
  assert (!is_tagged_clause (c));
  assert (!is_temporary_binary (solver, c));
#endif
  assert (!c->garbage);
  LOGCLS (c, "%s thus marked garbage", msg);
  c->garbage = true;
  trace_and_check_deletion (solver, c->size, c->literals);
  if (c->redundant)
    DEC (redundant);
  else
    DEC (irredundant);
#ifndef NELIMINATION
  if (!c->redundant)
    {
      mark_eliminate_clause (solver, c);
    }
#endif
#ifndef LOGGING
  (void) msg;			// Prevent unused 'msg' warning.
#endif
}

/*------------------------------------------------------------------------*/

#if !defined(NELIMINATION) || defined(NWATCHES)

// Connect literal in irredundant clause.

static void
connect_literal (struct satch *solver, unsigned lit, struct clause *c)
{
#ifndef NWATCHES
  assert (solver->dense);
#endif
#ifdef LOGGING
#ifndef NVIRTUAL
  if (is_tagged_clause (c))
    LOGTAGGED (lit, c, "connecting %s to", LOGLIT (lit));
  else
#endif
    LOGCLS (c, "connecting %s to", LOGLIT (lit));
#endif
#if !defined(NDEBUG) && !defined(NVIRTUAL)
  if (!is_tagged_clause (c))
    assert (!c->garbage);
#endif
  const union watch watch = {.clause = c };
  PUSH (solver->watches[lit], watch);
}

static void
connect_clause (struct satch *solver, struct clause *c)
{
  for (all_literals_in_clause (lit, c))
    connect_literal (solver, lit, c);
}

/*------------------------------------------------------------------------*/

#if (!defined(NSUBSUMPTION) && !defined(NVIRTUAL)) || \
    (!defined(NELIMINATION) && !defined(NVIRTUAL)) || \
    !defined(NSTRENGTHENING) || \
    ((!defined(NREDUCE) || !defined(NELIMINATION)) && defined(NWATCHES))

static void
disconnect_literal (struct satch *solver, unsigned lit, struct clause *c)
{
#ifndef NWATCHES
  assert (solver->dense);
#endif
#ifdef LOGGING
#ifndef NVIRTUAL
  if (is_tagged_clause (c))
    LOGTAGGED (lit, c, "disconnecting %s from", LOGLIT (lit));
  else
#endif
    LOGCLS (c, "disconnecting %s from", LOGLIT (lit));
#endif
  struct watches *watches = solver->watches + lit;
  const union watch *const end = watches->end;
  union watch *q = watches->begin;
  while (assert (q != end), q->clause != c)
    q++;
  while (++q != end)
    q[-1] = *q;
  watches->end--;
  if (EMPTY_STACK (*watches))
    RELEASE_STACK (*watches);
}

#endif

#endif

/*------------------------------------------------------------------------*/

#ifdef NWATCHES

static void
count_clause (struct satch *solver, struct clause *c)
{
  unsigned sum = 0, count = 0;

  const signed char * const values = solver->values;

  for (all_literals_in_clause (lit, c))
    {
	signed char tmp = values[lit];
	if (tmp < 0)
	  continue;
	count++;
	sum += lit;
    }

  c->sum = sum;
  c->count = count;
  LOGCLS (c, "count set to %u in", count);
}

#endif

/*------------------------------------------------------------------------*/

static void
assign (struct satch *solver, unsigned lit, struct clause *reason)
{
#ifdef LOGGING
#ifndef NBLOCK
  if (is_tagged_clause (reason))
    LOGTAGGED (lit, reason, "assign %s reason", LOGLIT (lit));
  else
#endif
  if (reason)
    LOGCLS (reason, "assign %s reason", LOGLIT (lit));
  else if (!solver->level)
    LOG ("assign %s through unit clause %s", LOGLIT (lit), LOGLIT (lit));
  else
    LOG ("assign %s decision", LOGLIT (lit));
#endif

  // Garbage clauses can not be reasons.

#ifndef NDEBUG
#ifndef NBLOCK
  if (!is_tagged_clause (reason))
#endif
    if (reason)
      assert (!reason->garbage);
#endif

  const unsigned idx = INDEX (lit);

  if (!solver->level)
    {
      solver->statistics.fixed++;	// Root-level fixed literal (unit).

      assert (solver->statistics.remaining);
      solver->statistics.remaining--;	// One less active variable.

      struct flags *f = solver->flags + idx;
      assert (f->active);
      f->active = false;
      assert (!f->fixed);
      f->fixed = true;

      if (reason)
	{
	  trace_and_check_unit_addition (solver, lit);
#ifndef NBLOCK
	  if (!is_tagged_clause (reason))
#endif
	    mark_garbage (solver, reason, "root-level forcing");
	  reason = 0;
	}
    }

  const unsigned not_lit = NOT (lit);
  assert (!solver->values[lit]);
  assert (!solver->values[not_lit]);

  // Set value of 'lit' and 'not-lit' independently in order to turn the
  // code for accessing the value of a literal into a simple array look-up
  // as well. This makes it simpler and branch-less too.

  solver->values[lit] = 1;
  solver->values[not_lit] = -1;

#ifndef NSAVE

  // Saved value is used as decision phase if 'idx' is picked as decision.

  solver->saved[idx] = INT_SIGN (lit);
#endif

  solver->reasons[idx] = reason;	// Remember reason clause.
  solver->levels[idx] = solver->level;	// Remember decision level.

#ifndef NSHRINK
  solver->position[idx] = SIZE_STACK (solver->trail);
#endif

  // Add literal to the partial assignment in the pre-allocated 'trail'.

  assert (solver->trail.end < solver->trail.begin + VARIABLES);
  *solver->trail.end++ = lit;

  // Used for fast termination check on 'satisfiable' instances.

  assert (solver->unassigned);
  solver->unassigned--;
}

/*------------------------------------------------------------------------*/

// Activating variables means adding them to the solver.

// It is also helpful to activate variables in the order they appear in the
// input by putting them on each of the two 'put' stacks, which allows to
// delay initialization of the decision queue / heap and only when the queue
// or the heap is queried through 'get_queue' resp. 'get_scores' it is
// filled in the order in which the variables occur in the formula.

static void
activate_literals (struct satch *solver)
{
  struct flags *flags = solver->flags;
  for (all_elements_on_stack (unsigned, lit, solver->clause))
    {
      const unsigned idx = INDEX (lit);
      struct flags *f = flags + idx;
      if (f->active)
	continue;
      f->active = true;
#ifndef NSUBSUMPTION
      f->subsume = 1;
      INC (marked_subsume);
#endif
#ifndef NELIMINATION
      f->eliminate = true;
      INC (marked_eliminate);
#endif
      LOG ("activated %s", LOGVAR (idx));
#ifndef NLAZYACTIVATION
#ifndef NFOCUSED
      PUSH (solver->put[0], idx);
#endif
#ifndef NSTABLE
      PUSH (solver->put[1], idx);
#endif
#endif
      solver->statistics.remaining++;
      solver->statistics.variables++;
      solver->unassigned++;
    }
}

/*------------------------------------------------------------------------*/
#ifndef NQUEUE
/*------------------------------------------------------------------------*/

// Functions to implement a doubly-linked variable decision queue.

#ifndef NBUMP

// We use 32-bit enqueue time stamps which overflow rather frequently after
// roughly 4 billion enqueue operations.  In this case we just go over all
// variable links in order of the decision queue and assign fresh stamps.

// Even for many variables (the maximum variable index is '(1u<<31) - 2') we
// still need a billion enqueue operations before this triggers and thus the
// accumulated complexity for this operation can be ignored.

static void
restamp_queue (struct satch *solver, struct queue *queue)
{
  const uint64_t restamped = INC (restamped);
  message (solver, 2, "restamp", restamped,
	   "restamping indices in decision queue");
  struct link *links = queue->links, *link;
  unsigned stamp = 0;
  for (unsigned idx = queue->first; idx != INVALID; idx = link->next)
    {
      link = links + idx;
      assert (stamp < UINT_MAX);
      link->stamp = ++stamp;
    }
  queue->search = queue->last;
  queue->stamp = stamp;
}

#endif

// Simple doubly linked list enqueue operation at the end of the queue with
// time stamping, where the time is the 'enqueue time'.  The 'search' index
// of the queue is also updated if this variable is unassigned.

static void
enqueue (struct satch *solver, struct queue *queue, unsigned idx)
{
  LOG ("enqueue %u", idx);
  struct link *const links = queue->links;
  struct link *const link = links + idx;
  const unsigned last = queue->last;
  if (last == INVALID)
    {
      assert (queue->first == INVALID);
      queue->first = idx;
    }
  else
    {
      struct link *const prev = links + last;
      assert (prev->next == INVALID);
      prev->next = idx;
    }
  link->prev = last;
  queue->last = idx;
  link->next = INVALID;

  // Now comes the 'stamping' trick from our SAT'2015 paper which makes sure
  // that time stamps respect queue order and can thus be used to compare in
  // constant time whether an element is to the left or right of the cached
  // search index, which during searching for unassigned decision variables
  // is set to the last decision variable index first and then updated in
  // case a variable right to the cached search index becomes unassigned
  // during backtracking.  This technique makes sure that right to the
  // search index all variables are assigned in the decision queue.  See
  // also the code involving stamps in 'backtrack' and in 'decide'.

  link->stamp = ++queue->stamp;
#ifdef NBUMP
  assert (link->stamp);
#else
  if (link->stamp)		// Check for overflow.
#endif
    {
      LOG ("enqueued %s stamped %u", LOGVAR (idx), link->stamp);
      const unsigned lit = LITERAL (idx);
      if (!solver->values[lit])
	queue->search = idx;
    }
#ifndef NBUMP
  else
    restamp_queue (solver, queue);
#endif
}

#ifndef NVMTF

// Simple doubly linked list dequeue operation (no stamping involved).

static void
dequeue (struct satch *solver, struct queue *queue, unsigned idx)
{
  LOG ("dequeue %u", idx);
  struct link *const links = queue->links;
  struct link *const link = links + idx;
  const unsigned prev_idx = link->prev;
  const unsigned next_idx = link->next;
  if (prev_idx == INVALID)
    {
      assert (queue->first == idx);
      queue->first = next_idx;
    }
  else
    {
      struct link *const prev = links + prev_idx;
      assert (prev->next == idx);
      prev->next = next_idx;
    }
  if (next_idx == INVALID)
    {
      assert (queue->last == idx);
      queue->last = prev_idx;
    }
  else
    {
      struct link *next = links + next_idx;
      assert (next->prev == idx);
      next->prev = prev_idx;
    }
}

#endif

/*------------------------------------------------------------------------*/

// The solver might have actually two queues (by default only one in focused
// mode though).  This could in principle be figured out at compile time but
// leads to extremely complex preprocessor macro checking code.  Instead we
// initialize the queue lazily on-demand if 'size' is not big enough.

static void
resize_queue (struct queue *queue, size_t new_capacity)
{
  RESIZE_UNINITIALIZED (queue->links);
}

static void
init_queue (struct satch *solver, struct queue *queue)
{
  if (!queue->size)
    queue->first = queue->last = queue->search = INVALID;
  if (!queue->links)
    resize_queue (queue, solver->capacity);
}

#ifndef NLAZYACTIVATION

// Put variables on the decision queue in the order in which the variables
// are activated (found in the input). Since the last activated variables is
// enqueued last, reverse activation order gives initial decision order.

static void
activate_queue (struct satch *solver, struct queue *queue,
		struct unsigned_stack *activate)
{
  init_queue (solver, queue);
  const unsigned stable = solver->stable;
  LOG ("activating %zu variables on queue[%u]", SIZE_STACK (*activate),
       stable);
  for (all_elements_on_stack (unsigned, idx, *activate))
    {
      INC (activated[stable]);
      enqueue (solver, queue, idx);
    }
  RELEASE_STACK (*activate);
  queue->size = solver->size;
}

#else

// Otherwise put variables on the decision queue in index order.  Since the
// variable with the largest index is enqueued last, reverse index order
// gives the initial decision order.

static void
fill_queue (struct satch *solver, struct queue *queue)
{
  init_queue (solver, queue);
  const unsigned stable = solver->stable;
  LOG ("filling queue[%u] with %zu variables",
       stable, (size_t) (solver->size - queue->size));
  while (queue->size < solver->size)
    {
      INC (filled[stable]);
      enqueue (solver, queue, queue->size++);
    }
}

#endif

static struct queue *
get_queue (struct satch *solver)
{
  const unsigned stable = solver->stable;
  struct queue *queue = &solver->queue[stable];
#ifndef NLAZYACTIVATION
  struct unsigned_stack *activate = &solver->put[stable];
  if (!EMPTY_STACK (*activate))
    activate_queue (solver, queue, activate);
#else
  if (queue->size < solver->size)
    fill_queue (solver, queue);
#endif
  assert (queue->size == solver->size);
  return queue;
}

#ifndef NVMTF

static void
move_variable_to_front (struct satch *solver, unsigned idx)
{
  INC (moved);
  LOG ("moving %s to front of decision queue", LOGVAR (idx));
  struct queue *queue = get_queue (solver);
  dequeue (solver, queue, idx);
  enqueue (solver, queue, idx);
}

#endif

static void
release_queue (struct queue *queue)
{
  free (queue->links);
}

/*------------------------------------------------------------------------*/
#endif
/*------------------------------------------------------------------------*/

// The solver can keep a 'capacity' of allocated variables larger than the
// number 'size' of added variables.  This capacity increases exponentially
// and avoids costly resizing operations of data structures during API
// usage. In stand-alone solver usage the number of variables is fixed and
// thus can be pre-allocated by 'satch_reserve', which avoids any resizing.
// This strategy can of course also be followed through the API if the user
// has a reasonable bound on the number of needed variables.

// This whole section of the code can be simplified substantially if we
// could assume a fixed number of variables, which unfortunately is not
// possible for incremental SAT solving.  We went through the effort to work
// out this resizing logic even though the solver is not incremental yet, as
// currently the API does not allow yet to add further clauses after the
// first call to 'satch_solve' (checked by 'REQUIRE_NON_INCREMENTAL').

// There are no global data structures. Thus multiple solvers can exist at
// the same time in the same process and clauses can be added incrementally
// without forcing the user to define a maximum variable up-front.

/*------------------------------------------------------------------------*/

// In principle we could use an unsigned stack for the trail but we can also
// just pre-allocate it, since it will never contain more literals than the
// number of variables.  In 'C' this allocation will not necessarily occupy
// real memory (in terms of resident set size) even for large instances,
// since for instance Linux would map those allocated pages to real pages
// lazily on-demand.  The pre-allocated trail makes the related code in
// 'assign' and 'boolean_constraint_propagation' more efficient.

static void
resize_trail (struct trail *trail, size_t new_capacity)
{
  assert (new_capacity);
  const size_t size = SIZE_STACK (*trail);
  const size_t bytes = new_capacity * sizeof (unsigned);
  const unsigned propagate = trail->propagate - trail->begin;
  trail->begin = realloc (trail->begin, bytes);
  if (!trail->begin)
    out_of_memory (bytes);
  trail->end = trail->begin + size;
  trail->propagate = trail->begin + propagate;
}

// Here we increase the capacity, i.e., the number of allocated data in
// terms of allocated variables, while 'increase_size' might just activate
// this data to be used if the number of variables increases (the 'size' of
// the solver) but otherwise stays below the allocated capacity.

// Note that, this use of 'size' and 'capacity' follows the same terminology
// as for 'std::vector' in the C++ standard template library.

static void
increase_capacity (struct satch *solver, unsigned new_capacity)
{
  const unsigned old_capacity = solver->capacity;
  LOG ("increasing capacity from %u to %u", old_capacity, new_capacity);
  assert (old_capacity < new_capacity);
  assert (new_capacity <= 1u << 31);
  RESIZE_ZERO_INITIALIZED (2, solver->watches, 0);
  RESIZE_ZERO_INITIALIZED (1, solver->reasons, 0);
  RESIZE_ZERO_INITIALIZED (1, solver->levels, 0);
  RESIZE_ZERO_INITIALIZED (2, solver->values, 0);
#ifndef NSAVE
  RESIZE_ZERO_INITIALIZED (1, solver->saved, 0);
#endif
#ifndef NTARGET
  RESIZE_ZERO_INITIALIZED (1, solver->targets, 0);
#endif
#ifndef NBEST
  RESIZE_ZERO_INITIALIZED (1, solver->bests, 0);
#endif
  RESIZE_ZERO_INITIALIZED (1, solver->marks, 0);
  RESIZE_ZERO_INITIALIZED (1, solver->flags, 0);
  RESIZE_ZERO_INITIALIZED (1, solver->frames, 1);
#ifndef NSHRINK
  RESIZE_UNINITIALIZED (solver->position);
#endif
  resize_trail (&solver->trail, new_capacity);

#ifndef NQUEUE
#ifndef NQUEUE0
  if (solver->queue[0].size)
    resize_queue (&solver->queue[0], new_capacity);
#else
  assert (!solver->queue[0].links);
#endif
#ifndef NQUEUE1
  if (solver->queue[1].size)
    resize_queue (&solver->queue[1], new_capacity);
#else
  assert (!solver->queue[1].links);
#endif
#endif

#ifndef NHEAP
#ifndef NHEAP0
  if (solver->scores[0].size)
    resize_heap (&solver->scores[0], old_capacity, new_capacity);
#else
  assert (!solver->scores[0].begin);
#endif
#ifndef NHEAP1
  if (solver->scores[1].size)
    resize_heap (&solver->scores[1], old_capacity, new_capacity);
#else
  assert (!solver->scores[1].begin);
#endif
#endif

  solver->capacity = new_capacity;
}

// This function activates all variables with index 'old_size' until
// 'new_size-1'.   After calling this function there are 'new_size' active
// variables (except for already root-level assigned variables).

static void
increase_size (struct satch *solver, unsigned new_size)
{
#if defined(LOGGING)
  const unsigned old_size = solver->size;
  assert (solver->size < new_size);
#endif
  const unsigned old_capacity = solver->capacity;
  assert (new_size <= 1u << 31);
  if (new_size > old_capacity)
    {
      unsigned new_capacity;
      if (new_size > 1u << 30)
	new_capacity = 1u << 31;	// Maximum capacity reached.
      else
	{
	  // Otherwise pick as 'new_capacity' the smallest power of two
	  // larger than 'new_size'.  This ensures a geometric increase.

	  assert (old_capacity <= 1u << 30);
	  new_capacity = 1;

	  while (new_size > new_capacity)
	    {
	      assert (new_capacity <= 1u << 30);
	      new_capacity *= 2;
	    }
	}
      increase_capacity (solver, new_capacity);
    }
  assert (new_size <= solver->capacity);
  LOG ("increase solver size from %u to %u", old_size, new_size);
  solver->size = new_size;
}

/*------------------------------------------------------------------------*/

// Signed marking of a literal in essence marks variables as negative or
// positive and is used in checking clauses or resolvents to contain both
// a positive and a negative occurrence of a literal.

static void
mark_literal (signed char *marks, unsigned lit)
{
  const unsigned idx = INDEX (lit);
  assert (!marks[idx]);
  marks[idx] = INT_SIGN (lit);
}

static signed char
marked_literal (const signed char *marks, unsigned lit)
{
  const unsigned idx = INDEX (lit);
  signed char res = marks[idx];
  if (SIGN_BIT (lit))
    res = -res;
  return res;
}

static void
unmark_literal (signed char *marks, unsigned lit)
{
  const unsigned idx = INDEX (lit);
  marks[idx] = 0;
}

/*------------------------------------------------------------------------*/

// Check whether the imported clause contains a literal and its negation or
// is satisfied by a root-level assigned literal.  If neither is the case
// this function removes duplicated and root-level falsified literals.

static bool
imported_clause_trivial_or_satisfied (struct satch *solver)
{
  assert (!solver->level);
  const unsigned *const end_clause = solver->clause.end;
  unsigned *const begin_clause = solver->clause.begin;
  unsigned *q = begin_clause;
  bool trivial = false;
  signed char *const marks = solver->marks;
  const signed char *const values = solver->values;
  for (const unsigned *p = begin_clause; p != end_clause; p++)
    {
      const unsigned lit = *p;
      const signed char value = values[lit];
      if (value < 0)
	{
	  LOG ("skipping falsified literal %s", LOGLIT (lit));
	  continue;
	}
      if (value > 0)
	{
	  LOG ("found satisfied literal %s", LOGLIT (lit));
	  trivial = true;
	  break;
	}
      const signed char prev = marked_literal (marks, lit);
      if (prev > 0)
	{
	  LOG ("skipping duplicated literal %s", LOGLIT (lit));
	  continue;
	}
      if (prev < 0)
	{
	  LOG ("clause contains both literal %s and its negation %s",
	       LOGLIT (NOT (lit)), LOGLIT (lit));
	  trivial = true;
	  break;
	}
      *q++ = lit;
      mark_literal (marks, lit);
    }
  solver->clause.end = q;
  for (const unsigned *p = begin_clause; p != q; p++)
    unmark_literal (marks, *p);
  return trivial;
}

/*------------------------------------------------------------------------*/

// The logic for importing literals follows the description above:

// 'elit' signed external literal (as in API and DIMACS format)
// 'eidx' signed external variable index (in the range '1...INT_MAX')
// 'iidx' unsigned internal variable index (in the range '0...(INT_MAX-1)')
// 'ilit' unsigned internal literal (in the range '0...2*(INT_MAX-1)+1')

static unsigned
import_literal (struct satch *solver, int elit)
{
  assert (elit);
  assert (elit != INT_MIN);	// Otherwise 'abs(elit)' might be undefined.
  const int eidx = abs (elit);
  const unsigned iidx = eidx - 1;
  if (iidx >= solver->size)
    increase_size (solver, iidx + 1);
  unsigned ilit = LITERAL (iidx);
  if (elit < 0)
    ilit = NOT (ilit);
  LOG ("imported external literal %d as internal literal %u", elit, ilit);
  return ilit;
}

/*------------------------------------------------------------------------*/

// Estimate the number of cache lines spanning the given array.

// We could use the numerical vales of the 'begin' and 'end' pointers of the
// array but that would make the code dependent on memory addresses which
// should be avoided.  Therefore we fall back to an estimation, which in
// essence assumes that the start address is cache-line-size aligned.

// Typical size of a cache line is 128 bytes, but even if your processor has
// less or more, this computation is anyhow just a rough estimate and by
// keeping it machine independent we also keep scheduling of for instance
// the focused and stable phases and thus the whole solver execution machine
// independent (does not vary for different cache-line size).

#define log2_bytes_per_cache_line	7
#define bytes_per_cache_line		(1u << log2_bytes_per_cache_line)

static inline size_t
cache_lines (const void *begin, const void *end)
{
  assert (begin <= end);
  const size_t round = bytes_per_cache_line - 1;
  const size_t bytes = (char *) end - (char *) begin;
  const size_t res = (bytes + round) >> log2_bytes_per_cache_line;
  return res;
}

// Short-cut for further usage on stacks.

#define CACHE_LINES_OF_STACK(S) cache_lines ((S)->begin, (S)->end)

/*------------------------------------------------------------------------*/

#ifndef NWATCHES

// ------------------------ //
// Propagation with watches //
// ------------------------ //

// Propagating a literal over the clauses in which it occurs negatively,
// more precisely for which its negation is watched, is the hot-spot of
// CDCL solving.  This is further pronounced by learning many long clauses.

static struct clause *
propagate_literal (struct satch *solver, unsigned lit)
{
  LOG ("propagating %s", LOGLIT (lit));

  const unsigned not_lit = NOT (lit);
  struct watches *const watches = solver->watches + not_lit;
  signed char *const values = solver->values;

  // We traverse all the watches of the literal 'not_lit' and remove those
  // for which we stop watching the clause (since we found a replacement).
  // The updated watches pointer 'q' follows the traversal pointer 'p'.

  union watch *q = watches->begin;
  const union watch *p = q;

  struct clause *conflict = 0;

  const union watch *const end_watches = watches->end;

  // By counting 'tick's we approximate the number of cache lines read in
  // 'propagation' focusing on accessing memory of watch stacks, and clause
  // memory.  And assignment is also counted as one cache line access
  // ('tick') but we do not take reading assigned values into account,
  // assuming those single byte accesses are shared.

  // Since the size of watches differs with and without 'NVIRTUAL' defined,
  // the size of the accessed memory changes too which in turn changes the
  // global scheduling of focused and stable mode based on ticks.

  // Trying to avoid this kind of non-determinism with respect to using
  // virtual clause or not would require to sort reason literals of binary
  // clauses in order to avoid different traversals during conflict
  // analysis.  It also changes when compiling on a 32-bit machine.

  // Furthermore it is pretty difficult to keep the same behaviour with and
  // without blocking literals (avoiding different watch replacement).

  uint64_t ticks = 1 + cache_lines (q, end_watches);

  while (!conflict && p != end_watches)
    {
#ifndef NBLOCK
      const union watch watch = *q++ = *p++;	// Keep header by default.
      const struct header header = watch.header;
      const unsigned blocking_lit = header.blocking;
      const signed char blocking_value = values[blocking_lit];

      // There is dedicated code for propagating over binary clauses.  With
      // the blocking literal stored in the watcher-stack there is no need
      // to access the actual binary clauses here (even if non-virtual).

      if (header.binary)
	{
	  if (blocking_value < 0)
	    {
	      conflict = binary_clause (solver, 0,
					header.redundant,
					not_lit, blocking_lit);
	      LOGCLS (conflict, "conflicting");
	    }
	  else if (!blocking_value)
	    {
	      assert (!blocking_value);
	      assign (solver, blocking_lit,
		      tag_binary_clause (header.redundant, not_lit));
	      ticks++;
	    }
#ifdef NVIRTUAL
	  *q++ = *p++;		// Copy clause too.
#endif
	  continue;
	}
      else
#endif
	// Handle larger non-binary clause in case blocking literals are
	// enabled or both cases (binary and non-binary clauses) if they are.

	{
	  struct clause *clause = (*q++ = *p++).clause;	// Copy clause.
	  assert (!clause->garbage);
#ifndef NBLOCK
	  if (blocking_value > 0)
	    continue;
#endif
	  unsigned *const literals = clause->literals;

	  // At this point we have to access the large clause. This is the
	  // real hot-spot of the solver.  Up-to 80% of the time can be
	  // spent here in the first pointer access without the blocking
	  // literal idea (and specialized binary clause propagation above).

	  // In the source code below with the assertion above disabled the
	  // first pointer access would be accessing the first literal
	  // 'literals[0]' of the clause.  The main purpose of the 'blocking
	  // literal' idea is to reduce the need for this costly pointer
	  // dereference as much as possible.

	  ticks++;		// We mainly count these accesses.

	  // The two watched literals of a clause are stored as the first
	  // two literals but we do not know at which position.  In order to
	  // avoid introducing a 'branch' (if-then-else) we simply use the
	  // trick to compute the XOR of the first two literals and the
	  // watched literal 'not_lit', which gives the other literal.

	  const unsigned other = literals[0] ^ literals[1] ^ not_lit;
	  const signed char other_value = values[other];

	  // Another common situation is that the other watched literal in
	  // that clause is different from the blocking literal, but is
	  // assigned true.  Then we also can stop here after updating the
	  // blocking literal for this watch to this other literal.

	  if (other_value > 0)
	    {
#ifndef NBLOCK
	      q[-2].header.blocking = other;
#endif
	      continue;
	    }

	  // Normalize the position where 'not_lit' sits to position '1'.

	  literals[0] = other;
	  literals[1] = not_lit;

	  const unsigned size = clause->size;
	  const unsigned *const end_literals = literals + size;

	  // Now search for a non-false ('true' or unassigned) replacement
	  // for the watched literal 'not_lit' starting with the third.

	  unsigned replacement = INVALID;
	  signed char replacement_value = -1;
	  const unsigned *end_search = end_literals;
	  unsigned *start_search = literals + 2, *r;
#ifndef NCACHE

	  // Use and remember the old offset were we found a replacement
	  // watch or a satisfied blocking literal and resume next search of
	  // replacement literals in this clause at that position (relative
	  // to 'literals + 2').

	  start_search += clause->search;
#endif
	  for (r = start_search; r != end_search; r++)
	    {
	      replacement = *r;
	      replacement_value = values[replacement];
	      if (replacement_value >= 0)
		break;
	    }
#ifndef NCACHE
	  if (replacement_value < 0)
	    {
	      end_search = start_search;
	      start_search = literals + 2;

	      for (r = start_search; r != end_search; r++)
		{
		  replacement = *r;
		  replacement_value = values[replacement];
		  if (replacement_value >= 0)
		    {
		      clause->search = r - start_search;
		      break;
		    }
		}
	    }
	  else
	    clause->search = r - start_search;
#endif
	  if (replacement_value > 0)	// Replacement literal true.
	    {
#ifndef NBLOCK
	      // Update blocking literal only.

	      q[-2].header.blocking = replacement;
#endif
	    }
	  else if (!replacement_value)	// Replacement literal unassigned.
	    {
	      // First log the untouched clause, then stop watching the
	      // originally watched literal by simply decreasing 'q'.

	      // Depending on whether blocking literals are disabled the
	      // actual decrement is either '2' (if 'NBLOCK' is defined) or
	      // '1' (if 'NBLOCK' is undefined). This difference is hidden
	      // in the definition of 'long_clause_watch_size'.

	      LOGCLS (clause, "unwatching %s in", LOGLIT (not_lit));
	      q -= long_clause_watch_size;

	      // Swap watched literal with its replacement.

	      literals[1] = replacement;
	      *r = not_lit;

#ifndef NBLOCK
	      const bool redundant = clause->redundant;
	      watch_literal (solver, redundant, replacement, other, clause);
#else
	      watch_literal (solver, replacement, clause);
#endif
	      ticks++;
	    }
	  else if (other_value)
	    {
	      // Clause is conflicting, since all literals are false!

	      assert (other_value < 0);
	      LOGCLS (clause, "conflicting");
	      conflict = clause;
	    }
	  else
	    {
	      // All literals are false except 'other' which is unassigned
	      // and thus it is now assigned with this clause as reason.

	      assert (!other_value);
	      assign (solver, other, clause);
	      ticks++;
	    }
	}
    }

  ADD (ticks, ticks);

  // After a conflicting clause is found we break out of the propagation but
  // still need to copy the rest of the watches and reset the stack size.

  while (p != end_watches)
    *q++ = *p++;
  watches->end = q;

  return conflict;
}

#else // of '#ifndef NWATCHES'

// ------------------------- //
// Propagation with counters //
// ------------------------- //

// Updating the non-false literal counters of literals in clauses is the
// hot-spot for CDCL with counters (instead of watches).  This effort occurs
// during propagation in this function and then also during backtracking.

struct clause *
propagate_literal (struct satch *solver, unsigned lit)
{
  LOG ("propagating %s", LOGLIT (lit));

  const unsigned not_lit = NOT (lit);
  struct watches *const watches = solver->watches + not_lit;
  signed char *const values = solver->values;

  // We traverse all clauses containing literal 'not_lit' and decrement the
  // non-false literal counters and update the sum of non-false literals in
  // order to find a conflict as well as detecting new units.

  uint64_t ticks = 1 + cache_lines (watches->begin, watches->end);
  struct clause *conflict = 0;

  for (all_elements_on_stack (union watch, watch, *watches))
    {
      struct clause * const clause = watch.clause;
      assert (clause->count > 0);
      clause->count--;
      clause->sum -= not_lit;
      LOGCLS (clause, "count decreased to %u in", clause->count);
      ticks++;
      if (conflict)
	continue;
      if (!clause->count)
	{
	  LOGCLS (clause, "conflicting");
	  conflict = clause;
	}
      else if (clause->count == 1)
	{
	  const unsigned unit = clause->sum;
	  const signed char value = values[unit];
	  if (!value)
	    {
	      assign (solver, unit, clause);
	      ticks++;
	    }
	  else if (value  < 0)
	    {
	      LOGCLS (clause, "conflicting");
	      conflict = clause;
	    }
	}
    }

  ADD (ticks, ticks);

  return conflict;
}

// Without watches and just counters we have to update the counters of
// propagated literals during backtracking, which we call 'unpropagating'.

static void
unpropagate_literal (struct satch * solver, unsigned lit)
{
  LOG ("unpropagating %s", LOGLIT (lit));

  const unsigned not_lit = NOT (lit);
  struct watches *const watches = solver->watches + not_lit;

  // We traverse all clauses containing literal 'not_lit' and increment the
  // non-false literal counters and adjust the non-false literal sum as well.

  uint64_t ticks = 1 + cache_lines (watches->begin, watches->end);

  for (all_elements_on_stack (union watch, watch, *watches))
    {
      struct clause * const clause = watch.clause;
      assert (clause->count < clause->size);
      clause->count++;
      clause->sum += not_lit;
      LOGCLS (clause, "count increased to %u in", clause->count);
      ticks++;
    }

  ADD (ticks, ticks);
}

#endif

/*------------------------------------------------------------------------*/

// Flush unit clauses from trail after root-level propagation.  Otherwise
// the statistics of the saved trail become incorrect and the assumption
// that there are no root-level assigned units on the trail break (for
// instance in 'reuse_trail').

static void
flush_units (struct satch *solver)
{
  assert (!solver->level);
  assert (solver->trail.propagate == solver->trail.end);
  LOG ("flushing %zu root-level units on trail", SIZE_STACK (solver->trail));
  solver->trail.propagate = solver->trail.end = solver->trail.begin;
}

/*------------------------------------------------------------------------*/

// While 'propagate_literal' propagates the assignment of one literal, the
// process of 'boolean constraint propagation' (BCP) implemented in the next
// function propagates all not yet propagated literals pushed on the trail.

// Note that propagation of a literal might produce new assigned literals
// (beside finding conflicting clauses) and thus the following loop can be
// seen as breadth-first search over the unit implied literals of the
// current assignment.

static struct clause *
boolean_constraint_propagation (struct satch *solver)
{
  struct trail *trail = &solver->trail;
  unsigned *propagate = trail->propagate;
  unsigned *p;

  assert (trail->begin <= propagate);
  assert (propagate <= trail->begin + VARIABLES);

  struct clause *conflict = 0;

  for (p = propagate; !conflict && p != trail->end; p++)
    conflict = propagate_literal (solver, *p);

  solver->trail.propagate = p;
  const unsigned propagated = p - propagate;

  ADD (propagations, propagated);

  if (conflict)
    INC (conflicts);
  else if (!solver->level)
    flush_units (solver);

  return conflict;
}

/*------------------------------------------------------------------------*/

// Update target and best-phases from a consistent trail.  The user has to
// make sure that the trail is consistent though.  For instance in conflict
// analysis we first have to backtrack one level.

#ifndef NTARGET

static void
save_phases (struct satch *solver, signed char *phases)
{
  const signed char *end = solver->values + LITERALS;
  signed char *q = phases, tmp;
  for (const signed char *p = solver->values; p != end; p += 2, q++)
    if ((tmp = *p))
      *q = tmp;
  assert (q == phases + VARIABLES);
}

static void
update_target_phases (struct satch *solver, const unsigned assigned)
{
  const uint64_t targets = INC (targets);
  save_phases (solver, solver->targets);
  solver->target = assigned;
  message (solver, 3, "target", targets, "targeting %u assigned variables "
	   "%.0f%% after %" PRIu64 " conflicts", assigned,
	   percent (assigned, VARIABLES), CONFLICTS);
}

#ifndef NBEST

static void
update_best_phases (struct satch *solver, const unsigned assigned)
{
  const uint64_t bests = INC (bests);
  save_phases (solver, solver->bests);
  solver->best = assigned;
  message (solver, 3, "best", bests, "best trail %u assigned variables "
	   "%.0f%% after %" PRIu64 " conflicts", assigned,
	   percent (assigned, VARIABLES), CONFLICTS);
}

#endif

// Make sure to care for root-level assigned variables when computing the
// number of assigned variables.  Those are flushed from the trail after
// unit propagation on the root-level completes. The trail size itself is
// not correct and makes target and stable phases actually behave badly.

static inline unsigned
assigned_variables (struct satch *solver)
{
  assert (VARIABLES >= solver->unassigned);
  return VARIABLES - solver->unassigned;
}

static void
update_phases (struct satch *solver)
{
  assert (solver->stable);
  const unsigned assigned = assigned_variables (solver);
  if (assigned > solver->target)
    update_target_phases (solver, assigned);
#ifndef NBEST
  if (assigned > solver->best)
    update_best_phases (solver, assigned);
#endif
}

#endif

/*------------------------------------------------------------------------*/

// Backtracking to a certain decision level in essence just unassigns the
// literals assigned on higher decision level. Then it reset the decision
// level and the propagation pointer.

// This procedure is slightly more complicated though since we first need to
// put back unassigned variables back to the binary heap for (E)VSIDS and
// second update the search index for the VMTF queue. Third without clause
// learning ('NLEARN' defined) learned clauses are only used for computing
// scores and back-jumping and during backtracking have to be deleted.

// Unfortunately this leads to rather complex code due to conditional
// compilation and allowing all combinations of features, including various
// ways to use EVSIDS scores and VMTF queue in stable and focused mode,
// disabling learning and blocking literals.

static void
backtrack (struct satch *solver, unsigned new_level)
{
  LOG ("backtracking to level %u", new_level);
  assert (new_level < solver->level);
  const unsigned *levels = solver->levels;
  signed char *values = solver->values;

#ifndef NQUEUE
  struct queue *queue = 0;
  const struct link *links = 0;
  unsigned search = INVALID;
  unsigned max_stamp = INVALID;
#ifndef NHEAP
  if (!solver->stable)
#endif
    {
      queue = get_queue (solver);
      links = queue->links;
      search = queue->search;
      max_stamp = search == INVALID ? 0 : links[search].stamp;
    }
#endif

#ifndef NHEAP
  struct heap *scores = 0;
  const unsigned *pos = 0;
#ifndef NQUEUE
  if (solver->stable)
#endif
    {
      scores = get_scores (solver);
      pos = scores->pos;
    }
#endif

#ifdef NLEARN
  struct clause *const *const reasons = solver->reasons;
#endif

#ifdef NWATCHES
  const unsigned * const propagated = solver->trail.propagate;
#endif
  struct trail *trail = &solver->trail;
  const unsigned * const begin = trail->begin;
  unsigned * p = trail->end;

  while (p != begin)
    {
      unsigned * next = p - 1;
      const unsigned lit = *next;
      const unsigned idx = INDEX (lit);
      const unsigned lit_level = levels[idx];
      if (lit_level == new_level)
	break;

      p = next;
      LOG ("unassign %s", LOGLIT (lit));
      assert (solver->unassigned < solver->size);
      solver->unassigned++;

      const unsigned not_lit = NOT (lit);

#if !defined(NELIMINATION) && !defined(NLEARN)
      assert (values[lit] > 0);
      assert (values[not_lit] < 0);
#else
      // Both Might be flipped in 'extend_solution'.
      //
      assert (values[lit]);
      assert (values[not_lit]);
#endif
      assert (values[lit] == -values[not_lit]);

      values[lit] = 0;
      values[not_lit] = 0;

#ifdef NLEARN
      struct clause *reason = reasons[idx];
      if (reason &&
#ifndef NBLOCK
	  !is_tagged_clause (reason) &&
#endif
	  reason->redundant)
	(void) delete_clause (solver, reason);
#endif
#ifndef NQUEUE
      if (links)
	{
	  const unsigned stamp = links[idx].stamp;
	  if (stamp > max_stamp)
	    search = idx, max_stamp = stamp;
	}
#endif
#ifndef NHEAP
      if (pos && pos[idx] == INVALID)
	push_heap (solver, scores, idx);
#endif
#ifdef NWATCHES
      if (p < propagated)
	unpropagate_literal (solver, lit);
#endif
    }
#ifndef NQUEUE
  if (queue)
    {
      LOG ("searched variable index %u", search);
      queue->search = search;
    }
#endif
  trail->propagate = trail->end = p;
  solver->level = new_level;
}

#if !defined(NREDUCE) || !defined(NELIMINATION)

static void
update_phases_and_backtrack_to_root_level (struct satch *solver)
{
  if (!solver->level)
    return;
#ifndef  NTARGET
  if (solver->stable)
    update_phases (solver);
#endif
  backtrack (solver, 0);
}

#endif

/*------------------------------------------------------------------------*/

// We have fast and slow-moving exponential averages, all updated during
// conflict clause analysis.  The slow moving averages are biased towards
// their initial value (zero) and we use a method described in the
// literature (the well known ADAM machine learning paper) to correct the
// bias by multiplying with '1/(1-beta^n)' where 'beta = 1 - alpha' and
// 'beta' is the smoothing factor (decay) and 'n' is the number of updates
// to the exponential moving average.  The alphas are defined above as
// macros since some compilers will otherwise not allow the following line.

const double slow_beta = 1.0 - slow_alpha;

// We have two sets of independent averages for stable and focused mode.
// During mode switching the 'stable' bit is flipped which makes the other
// set of averages active.  However if stable mode is disabled we only have
// one set of averages and only update and use that.  To hide this logic we
// use the following function which returns the active set of averages.

static struct averages *
averages (struct satch *solver)
{
  return solver->averages + solver->stable;
}

static void
update_slow_average (double *average, unsigned value)
{
  *average += slow_alpha * (value - *average);
}

static double
unbiased_slow_average (struct averages *a, double avg)
{
  const double div = 1 - a->slow_exp;
  return !div ? 0 : div == 1 ? avg : avg / div;
}

#ifndef NRESTART

// Only 'restarting' needs a fast moving average ('fast_glue').

const double fast_beta = 1.0 - fast_alpha;

static void
update_fast_average (double *average, unsigned value)
{
  *average += fast_alpha * (value - *average);
}

static double
unbiased_fast_average (struct averages *a, double avg)
{
  const double div = 1 - a->fast_exp;
  return !div ? 0 : div == 1 ? avg : avg / div;
}

#endif

// We assume that all fast and slow moving averages are updated at the same
// time and then just update 'beta^n' for both too (even though there is a
// fast one and a slow one).

static void
update_betas (struct satch *solver)
{
  struct averages *a = averages (solver);
#ifndef NRESTART
  if (a->fast_exp)
    a->fast_exp *= fast_beta;
#endif
  if (a->slow_exp)
    a->slow_exp *= slow_beta;
}

static void
init_one_set_of_averages (struct averages *a)
{
  a->slow_exp = 1.0;
#ifndef NRESTART
  a->fast_exp = 1.0;
#endif
}

static void
init_averages (struct satch *solver)
{
  for (int i = 0; i < 2; i++)
    init_one_set_of_averages (&solver->averages[i]);
}

/*------------------------------------------------------------------------*/

#ifndef NSORTDEDUCED

// Shrinking requires that the temporary learned clause is partitioned into
// its decision levels.  Each such partition is called a block and we
// require the blocks to be in descending level order.  It is in general
// beneficial to sort literals in descending level order in learned clauses
// too and thus we sort the deduced clause even if shrinking is disabled.

#ifndef NRADIXSORT

#define RANK_LITERAL_BY_INVERSE_LEVEL(LIT)	(~levels[INDEX (LIT)])

static void
sort_deduced_clause (struct satch *solver)
{
  const unsigned *const levels = solver->levels;
  RSORT (unsigned, unsigned, solver->clause, RANK_LITERAL_BY_INVERSE_LEVEL);
}

#else

// Without radix sort we need to get the levels from the sorted array and
// thus have to allocate a temporary array with literals and their levels.

// Since we want stable sorting (to match the radix-sort version) we also
// add a position argument and thus keep literals in their original order
// in the clause within one block (literals with the same level).

struct lit_level_pos
{
  unsigned lit, level, pos;
};

static int
cmp_lit_level_pos (const void *p, const void *q)
{
  struct lit_level_pos *l = (struct lit_level_pos *) p;
  struct lit_level_pos *k = (struct lit_level_pos *) q;
  if (l->level > k->level)
    return -1;
  if (l->level < k->level)
    return 1;
  assert (l->pos != k->pos);
  return l->pos < k->pos ? -1 : 1;
}

static void
sort_deduced_clause (struct satch *solver)
{
  struct unsigned_stack *clause = &solver->clause;
  const unsigned size = SIZE_STACK (*clause);
  const size_t bytes = size * sizeof (struct lit_level_pos);
  struct lit_level_pos *a = malloc (bytes);
  if (!a)
    out_of_memory (bytes);
  const unsigned *levels = solver->levels;
  unsigned pos = 0;
  for (all_elements_on_stack (unsigned, lit, *clause))
    {
      struct lit_level_pos *p = a + pos;
      p->lit = lit;
      p->level = levels[INDEX (lit)];
      p->pos = pos++;
    }
  qsort (a, size, sizeof *a, cmp_lit_level_pos);
  const struct lit_level_pos *const end = a + size;
  unsigned *c = clause->begin;
  for (const struct lit_level_pos * p = a; p != end; p++)
    *c++ = p->lit;
  free (a);
}

#endif

#endif

/*------------------------------------------------------------------------*/

// The 'ANALYZED' flag is used for 'analyze' but also during minimization.

#define ANALYZED 1		// Literal seen during conflict analysis.

// Conflict clause minimization is implemented here.

#ifndef NMINIMIZE

// The following two flags can be set independently of 'ANALYZED' and thus
// have different bits.  During shrinking we additionally have 'SHRUNKEN'.

#define REMOVABLE 2		// Literal can be be minimized.
#define POISONED 4		// Literal can not be minimized.

static void
mark_removable (struct satch *solver, unsigned idx)
{
  assert (!(solver->marks[idx] & REMOVABLE));
  solver->marks[idx] |= REMOVABLE;
  PUSH (solver->removable, idx);
  LOG ("removable %s", LOGVAR (idx));
}

static void
mark_poisoned (struct satch *solver, unsigned idx)
{
  assert (!(solver->marks[idx] & POISONED));
  solver->marks[idx] |= POISONED;
  PUSH (solver->poisoned, idx);
  LOG ("poisoned %s", LOGVAR (idx));
}

// Return either 'REMOVABLE' (literal can be removed) or 'POISONED'.

// This recursive function is guarded against stack-overflow by providing an
// additional 'depth' parameter, which is increase with each recursive call.
// If 'depth' hits the 'minimize_depth' limit the procedure conservatively
// assumes that the literal can not be minimized away.

// Previously computed results are cached in mark flags. Root-level
// assigned literals are ignored.  The function aborts negatively if a
// decision variable is reached which has not been marked as being in the
// clause before (marked 'REMOVABLE') or the decision level of the literal
// is not in the learned clause.

static int
minimize_literal (struct satch *solver, unsigned lit, unsigned depth)
{
  const unsigned idx = INDEX (lit);
  signed char mark = solver->marks[idx];
  assert (mark >= 0);
  if (mark & POISONED)
    return POISONED;		// Previously shown not to be removable.
  if (mark & REMOVABLE)
    return REMOVABLE;		// Previously shown to be removable.
  if (depth && (mark & ANALYZED))
    return REMOVABLE;		// Analyzed thus removable (unless start).
  const unsigned level = solver->levels[idx];
  if (!level)
    return REMOVABLE;		// Root-level units can be removed.
  if (depth > minimize_depth)
    return POISONED;		// Avoids deep recursion (stack overflow).
  assert (solver->values[lit] < 0);
  struct clause *reason = solver->reasons[idx];
  if (!reason)
    return POISONED;		// Decisions can not be removed.
  if (!solver->frames[level])
    return POISONED;		// Level not pulled into clause.
  int res = REMOVABLE;
#ifndef NBLOCK
  if (is_tagged_clause (reason))
    reason = untag_clause (solver, 0, NOT (lit), reason);
  else
#endif
    INC (ticks);
  const unsigned not_lit = NOT (lit);
  LOGCLS (reason, "trying to minimize %s at depth %u along",
	  LOGLIT (not_lit), depth);
  for (all_literals_in_clause (other, reason))
    {
      if (other == not_lit)
	continue;
      if (minimize_literal (solver, other, depth + 1) == REMOVABLE)
	continue;
      res = POISONED;
      break;
    }
  if (depth)
    {
      if (res == REMOVABLE)
	mark_removable (solver, idx);
      else
	mark_poisoned (solver, idx);
    }
  LOG ("%s %s at depth %u",
       (res == REMOVABLE ? "removable" : "poisoned"), LOGLIT (lit), depth);
  return res;
}

#ifdef NSHRINK

// Minimize the deduced first unique implication point (1st UIP) clause.

// By default ('NSHRINK' undefined) we employ all-UIP shrinking though which
// minimizes (in 'minimize_block') each block of literals in the learned
// clause with the same decision level in the deduced clause separately
// after shrinking unless shrinking was able to replace the whole block by a
// single literal.  Thus with shrinking this function becomes obsolete.

static void
minimize_deduced_clause (struct satch *solver)
{
  assert (EMPTY_STACK (solver->poisoned));
  assert (EMPTY_STACK (solver->removable));

  unsigned *const end = solver->clause.end;
  unsigned *const begin = solver->clause.begin;
  for (unsigned *p = end - 1; p != begin; p--)
    if (minimize_literal (solver, *p, 0) == REMOVABLE)
      *p = INVALID;

  unsigned *q = begin, lit;
  for (const unsigned *p = q; p != end; p++)
    if ((lit = *p) != INVALID)
      *q++ = lit;

  const size_t minimized = end - q;
  solver->clause.end = q;

  LOG ("minimized %zu literals", minimized);
  ADD (minimized, minimized);

  LOGTMP ("minimized");
}

#endif

// Reset the 'POISONED' and 'REMOVABLE' flags set during minimization.

static void
reset_removable_and_poisoned (struct satch *solver)
{
  for (all_elements_on_stack (unsigned, idx, solver->poisoned))
      solver->marks[idx] &= ~POISONED;
  CLEAR_STACK (solver->poisoned);

  for (all_elements_on_stack (unsigned, idx, solver->removable))
      solver->marks[idx] &= ~REMOVABLE;
  CLEAR_STACK (solver->removable);
}

#endif

/*------------------------------------------------------------------------*/

// Mark a literal as 'ANALYZED' if it has not been visited yet during
// conflict analysis (or during reason-side-bumping).  Since the 'analyze'
// function below needs the assignment level of the literal to mark decision
// levels and decide whether the literal is added to the learned clause we
// use that level as return value or 'INVALID' as result if the literal has
// been marked before (or has been assigned on the root-level zero).

static void
mark_analyzed (struct satch *solver, unsigned idx)
{
  assert (!(solver->marks[idx] & ANALYZED));
  solver->marks[idx] |= ANALYZED;
  struct analyzed analyzed;
  analyzed.idx = idx;
#ifndef NSORTANALYZED
  analyzed.stamp = INVALID;
#endif
  PUSH (solver->analyzed, analyzed);
  LOG ("analyzed %s", LOGVAR (idx));
}

static inline unsigned
analyze_literal (struct satch *solver, unsigned lit)
{
  const unsigned idx = INDEX (lit);
  const unsigned lit_level = solver->levels[idx];
  if (!lit_level)
    return INVALID;
  if (solver->marks[idx])
    return INVALID;
  mark_analyzed (solver, idx);
  return lit_level;
}

/*------------------------------------------------------------------------*/

// More thorough shrinking than classical clause minimization by trying to
// find unique implication points on all previous decision levels without
// introducing new decision levels into the learned clause.

#ifndef NSHRINK

// Mark-bit different from 'ANALYZED', 'REMOVABLE', and 'POISONED'.

#define SHRUNKEN 8

static void
mark_shrunken (struct satch *solver, unsigned idx)
{
  assert (!(solver->marks[idx] & SHRUNKEN));
  solver->marks[idx] |= SHRUNKEN;
  PUSH (solver->shrunken, idx);
  LOG ("shrunken %s", LOGVAR (idx));
}

// Reset literals marked 'SHRUNKEN' in any case (successful or unsuccessful).

static void
reset_shrunken (struct satch *solver)
{
  LOG ("resetting %zu shrunken variables", SIZE_STACK (solver->shrunken));
  signed char *marks = solver->marks;
  for (all_elements_on_stack (unsigned, idx, solver->shrunken))
      marks[idx] &= ~SHRUNKEN;
  CLEAR_STACK (solver->shrunken);
}

// Positive case: literals can be shrunken to one unique implication point.

static void
mark_shrunken_as_removable (struct satch *solver)
{
  signed char *marks = solver->marks;
  for (all_elements_on_stack (unsigned, idx, solver->shrunken))
    if (!(marks[idx] & REMOVABLE))
        mark_removable (solver, idx);
}

// Return '0' if literal is removable or has already been shrunken. Return
// '-1' if it can definitely not be shrunken, and '1' if it can in principle
// be shrunken and thus has been marked as such.

// The encoding of these result values has the idea that it matches the
// number of new additionally marked literals by which 'open' is increased
// in 'shrink_block' except that if '-1' is returned the search is aborted.

// On lower decision level than the given level of the considered block we
// use 'minimize_literal' which tries to resolve the literal away based on
// other literals already in the (partially) minimized and shrunken clause.

static int
shrink_literal (struct satch *solver, unsigned block_level, unsigned lit)
{
  const unsigned idx = INDEX (lit);
  const unsigned lit_level = solver->levels[idx];
  if (!lit_level)
    return 0;
  if (solver->marks[idx] & SHRUNKEN)
    return 0;
  if (lit_level < block_level)
    return (minimize_literal (solver, lit, 1) == REMOVABLE) ? 0 : -1;
  mark_shrunken (solver, idx);
  return 1;
}

// In case 'shrink_block' is successful it calls this function and shrinks
// the literals in the clause from 'begin' to 'end' to the given unique
// implication point and further resets the shrunken literals.

static void
shrunken_block (struct satch *solver,
		unsigned *begin, unsigned *end, unsigned uip)
{
  for (unsigned *p = begin; p != end; p++)
    *p = INVALID;
  *begin = NOT (uip);
  const unsigned idx = INDEX (uip);
  if (!(solver->marks[idx] & ANALYZED))
    mark_analyzed (solver, idx);
  mark_shrunken_as_removable (solver);
  reset_shrunken (solver);
}

// Get start of the level-block ending right before 'end' in the temporary
// clause which is assumed to be sorted by decreasing decision levels.

static unsigned *
next_block (struct satch *solver, unsigned *end)
{
  const unsigned *const levels = solver->levels;
  unsigned block_level = INVALID;
  unsigned *begin = end;
  while (solver->clause.begin < begin)
    {
      const unsigned lit = begin[-1];
      const unsigned idx = INDEX (lit);
      const unsigned lit_level = levels[idx];
      if (lit_level > block_level)
	break;
      block_level = lit_level;
      begin--;
    }
  return begin;
}

// Find a first unique implication point of the given block of literals with
// the same decision level in the deduced clause.

static bool
shrink_block (struct satch *solver, unsigned *begin, unsigned *end)
{
  assert (begin < end);
  unsigned open = end - begin;
  if (open < 2)
    return true;		// Already shrunken so avoid 'minimize_block'.

  const unsigned block_level = solver->levels[INDEX (*begin)];
  LOG ("trying to shrink block of size %u at level %u", open, block_level);

  // First mark all literals in the block as 'SHRUNKEN' and also compute
  // the maximum trail position of the literals in this block.

  unsigned trail = 0;
  {
    const unsigned *const position = solver->position;
    assert (EMPTY_STACK (solver->shrunken));
    for (unsigned *p = begin; p != end; p++)
      {
	const unsigned lit = *p;
	const unsigned idx = INDEX (lit);
	mark_shrunken (solver, idx);

	const unsigned pos = position[idx];
	assert (solver->trail.begin[pos] == NOT (lit));
	if (pos > trail)
	  trail = pos;
      }
    assert (SIZE_STACK (solver->shrunken) == open);
  }

  // Now we can start traversing the trail for this block going backward
  // from the last its literal on the trail.  This traversal follows a
  // topological order, i.e., an inverse assignment order, and is similar to
  // the trail traversal in 'analyze' which deduces the learned clause in
  // the first place.  This order allows us to properly maintain 'open', the
  // number of literals marked 'SHRUNKEN' and not yet resolved.  If this
  // number drops to one we have found a unique implication point for this
  // block.  An alternative to this linear traversal along the trail is
  // to use a binary heap (we actually tried a radix heap) or some clever
  // depth first search. The latter however would need to be aborted early
  // if a literal can not be shrunken and probably is more complicated.

  const unsigned *t = solver->trail.begin + trail;
  unsigned uip = INVALID;
  bool failed = false;

  const signed char *const marks = solver->marks;
  struct clause *const *const reasons = solver->reasons;

  while (!failed)
    {
      unsigned idx;
      do
	assert (t >= solver->trail.begin), uip = *t--;
      while (!(marks[idx = INDEX (uip)] & SHRUNKEN));
      if (!--open)
	break;
      struct clause *reason = reasons[idx];
      assert (reason);
#ifndef NBLOCK
      if (is_tagged_clause (reason))
	reason = untag_clause (solver, 0, uip, reason);
      else
#endif
	INC (ticks);
      LOGCLS (reason, "trying to shrink %s along", LOGLIT (uip));
      for (all_literals_in_clause (lit, reason))
	if (lit != uip)
	  {
	    int tmp = shrink_literal (solver, block_level, lit);
	    if ((failed = (tmp < 0)))
	      break;
	    open += (tmp > 0);
	  }
    }

  if (failed)
    reset_shrunken (solver);
  else
    shrunken_block (solver, begin, end, uip);

  LOG ("shrinking of block of size %zu at level %u %s",
       (size_t) (end - begin), block_level, failed ? "failed" : "succeeded");

  return !failed;
}

// Minimize the block if it could not be shrunken.

static void
minimize_block (struct satch *solver, unsigned *begin, unsigned *end)
{
  unsigned minimized = 0;
  for (unsigned *p = begin; p != end; p++)
    if (minimize_literal (solver, *p, 0) == REMOVABLE)
      *p = INVALID, minimized++;
  ADD (minimized, minimized);
  LOG ("minimized %u literals", minimized);
}

// This is the main shrinking function.  It requires the temporary clause to
// be sorted with respect to decreasing decision level of its literals (thus
// 'sort_deduced_clause' has to be called first).

static void
shrink_deduced_clause (struct satch *solver)
{
  assert (EMPTY_STACK (solver->poisoned));
  assert (EMPTY_STACK (solver->removable));

  {
    unsigned *end = solver->clause.end;
    while (end != solver->clause.begin)
      {
	unsigned *begin = next_block (solver, end);
	if (!shrink_block (solver, begin, end))
	  minimize_block (solver, begin, end);
	end = begin;
      }
  }

  // Removed literals of each block are overwritten with 'INVALID' in place
  // and in a last pass we have to flush these invalid literals.

  {
    const unsigned *const end = solver->clause.end;
    unsigned *q = solver->clause.begin, lit;
    for (const unsigned *p = q; p != end; p++)
      if ((lit = *p) != INVALID)
	*q++ = lit;

    const unsigned shrunken = end - q;
    solver->clause.end = q;
    LOG ("shrunken %u literals", shrunken);
    ADD (shrunken, shrunken);
  }

  LOGTMP ("shrunken");
}

#endif

/*------------------------------------------------------------------------*/

// Bumping reason side literals was introduced in the Maple solver in 2016.

// The idea is to also bump those literals in the reason of the literals in
// the learned clauses.  It seems that using target phases during stable
// mode really needs this technique in order to be effective (and the same
// applies to rephasing to best-phases and probably rephasing in general).

#ifndef NBUMPREASONS

static inline void
bump_reason_side_literals (struct satch *solver)
{
  struct averages *a = averages (solver);
  if (unbiased_slow_average (a, a->decision_rate) >=
      bump_reason_decision_rate_limit)
    return;

  struct clause *const *const reasons = solver->reasons;
  for (all_elements_on_stack (unsigned, lit, solver->clause))
    {
      const unsigned idx = INDEX (lit);
      struct clause *reason = reasons[idx];
#ifndef NBLOCK
      if (is_tagged_clause (reason))
	reason = untag_clause (solver, 0, NOT (lit), reason);
#endif
      if (!reason)
	continue;
      for (all_literals_in_clause (other, reason))
	if (analyze_literal (solver, other) != INVALID)
	  INC (reasons);
    }
}

#endif

/*------------------------------------------------------------------------*/

// Sorting the analyzed variable indices to be bumped with respect to their
// enqueue time stamp on the VMTF decision queue makes sure that they keep
// the same relative order on the queue after bumping which empirically
// improves the effectiveness of the decision heuristic (less conflicts).

#ifndef NSORTANALYZED

// The enqueue time stamps could be added to the 'analyzed' stack while
// pushing variable indices to it.  This makes that code more complex given
// all the different ways of disabling and enabling VMTF and sorting.
// Instead we simply put this here to keep that complexity out of 'analyze'.

static void
add_stamps (struct satch *solver)
{
  struct queue *queue = get_queue (solver);
  const struct link *const links = queue->links;
  const struct analyzed *const end = solver->analyzed.end;
  struct analyzed *const begin = solver->analyzed.begin;
  for (struct analyzed * p = begin; p != end; p++)
    p->stamp = links[p->idx].stamp;
}

#ifndef NRADIXSORT

// Ranking function for radix-sorting the analyzed variables stack.

// Without using radix sort the time spent in 'sort_analyzed' can reach 20%
// of the total running time (including both time spent in focused and
// stable mode) even though 'sort_analyzed' is by default only used in
// focused mode for the VMTF decision heuristic.  This might then increase
// relative time spent in focused mode since we do not want to account for
// sorting with our 'ticks' counter.  We have seen cases where this effect
// lead to 70% time spent in focused mode and only 30% time in stable mode.
// Using faster radix sorting allows to achieve a more balanced split of
// search time into focused and stable mode.

// Note that for CaDiCaL and early versions of Kissat we determined
// empirically that quick sort is faster when sorting 800 or less variables.
// With a new optimization which computes upper and lower bounds once for
// all radix rounds, this number of 800 could be reduced to only 32
// elements, where the dedicated inlined quick sort is faster.

// These numbers are with respect to a dedicated fast header only quick sort
// implementation.  For the standard 'qsort' function of the C library which
// requires comparison function call-backs instead of inlined comparison
// this number would be smaller anyhow.  Thus for 'satch' we do not
// implement quick sort at this point.  Note also that quick-sort itself
// usually has some kind of 'leaf-coarsening' and in essence switches to
// insertion sort if for instance the number of elements drops below 10.

#define rank_analyzed(A) (A).stamp

static void
sort_analyzed (struct satch *solver)
{
  add_stamps (solver);
  RSORT (struct analyzed, unsigned, solver->analyzed, rank_analyzed);
}

#else

// Comparison function for 'qsort' to sort variable indices by stamp time.
// Note that, time stamps are unique. Thus we get stable sorting for free.

static int
cmp_analyzed (const void *p, const void *q)
{
  const struct analyzed *a = p, *b = q;
  unsigned s = a->stamp, t = b->stamp;
  return (s < t) ? -1 : 1;
}

static void
sort_analyzed (struct satch *solver)
{
  add_stamps (solver);
  qsort (solver->analyzed.begin, SIZE_STACK (solver->analyzed),
	 sizeof (struct analyzed), cmp_analyzed);
}

#endif
#endif

/*------------------------------------------------------------------------*/

// The CDCL conflict analysis function.

// First we deduce the 'first unique implication point' (1st UIP) clause,
// minimize, shrink and learn it, then determine backjump level, backtrack
// and assign the 1st UIP literal to the opposite value with the learned
// clause as reason.  We also update various statistics during the analysis.

static bool
analyze_conflict (struct satch *solver, struct clause *conflict)
{
  assert (!solver->inconsistent);

  assert (EMPTY_STACK (solver->clause));	// Clause learned.

  const unsigned conflict_level = solver->level;
  if (!conflict_level)
    {
      LOG ("learned empty clause");
      trace_and_check_empty_addition (solver);
      solver->inconsistent = true;
      return false;
    }

  assert (EMPTY_STACK (solver->blocks));	// Decision levels analyzed.
  assert (EMPTY_STACK (solver->analyzed));	// Analyzed literals.

  PUSH (solver->clause, INVALID);	// Reserve room for 1st UIP.

  signed char *const marks = solver->marks;
  const unsigned *const levels = solver->levels;
  struct clause *const *const reasons = solver->reasons;
  signed char *frames = solver->frames;

  struct clause *reason = conflict;

  const unsigned *t = solver->trail.end;
  unsigned unresolved_on_current_level = 0;
  unsigned uip = INVALID;

  uint64_t ticks = 0;

  for (;;)
    {
      assert (reason);
      LOGCLS (reason, "analyzing");
#ifndef NUSED
#ifndef NBLOCK
      if (!is_temporary_binary (solver, reason))
#endif
	{
	  if (!reason->used)
	    reason->used = 1;
#ifndef NTIER2
	  else if (reason->glue <= tier2_glue_limit)
	    reason->used = 2;
#endif
	  ticks++;
	}
#endif
      for (all_literals_in_clause (lit, reason))
	{
	  if (lit == uip)
	    continue;
	  const unsigned lit_level = analyze_literal (solver, lit);
	  if (lit_level == INVALID)
	    continue;
	  assert (solver->values[lit] < 0);
	  if (lit_level < conflict_level)
	    {
	      if (!frames[lit_level])
		{
		  LOG ("analyzing decision level %u", lit_level);
		  PUSH (solver->blocks, lit_level);
		  frames[lit_level] = 1;
		}
	      PUSH (solver->clause, lit);
	    }
	  else
	    unresolved_on_current_level++;
	}
      unsigned uip_idx;
      do
	{
	  assert (solver->trail.begin < t);
	  uip = *--t;
	}
      while (!marks[uip_idx = INDEX (uip)]);
      if (!--unresolved_on_current_level)
	break;
      reason = reasons[uip_idx];
#ifndef NBLOCK
      if (is_tagged_clause (reason))
	reason = untag_clause (solver, 0, uip, reason);
#endif
    }
  assert (uip != INVALID);
  LOG ("first unique implication point %s (1st UIP)", LOGLIT (uip));
  const unsigned not_uip = NOT (uip);
  ACCESS (solver->clause, 0) = not_uip;
  ADD (ticks, ticks);

  LOGTMP ("deduced");
  unsigned size = SIZE_STACK (solver->clause);
  ADD (deduced, size);
  assert (size);

#ifndef NSORTDEDUCED
  sort_deduced_clause (solver);
#endif

#ifndef NMINIMIZE
#ifndef NSHRINK
  shrink_deduced_clause (solver);
#else
  minimize_deduced_clause (solver);
#endif
  reset_removable_and_poisoned (solver);
  size = SIZE_STACK (solver->clause);
#endif

  const unsigned glue = SIZE_STACK (solver->blocks);
  unsigned jump_level = 0;

  for (all_elements_on_stack (unsigned, lit_level, solver->blocks))
    {
      frames[lit_level] = 0;
      if (lit_level != conflict_level && jump_level < lit_level)
	jump_level = lit_level;
    }
  CLEAR_STACK (solver->blocks);

  {
    struct averages *a = averages (solver);
#ifndef NRESTART
    update_fast_average (&a->fast_glue, glue);
#endif
    update_slow_average (&a->slow_glue, glue);
    update_slow_average (&a->conflict_level, conflict_level);
    {
      const uint64_t decisions = DECISIONS;
      const uint64_t delta_decisions = decisions - a->saved_decisions;
      a->saved_decisions = decisions;
      update_slow_average (&a->decision_rate, delta_decisions);
    }
    {
      double trail_filled = percent (SIZE_STACK (solver->trail),
				     solver->statistics.remaining);
      update_slow_average (&a->trail_filled, trail_filled);
    }
    update_betas (solver);

    LOG ("determined jump level %u and glue %u", jump_level, glue);
    LOG ("exponential 'conflict_level' moving average %g",
	 unbiased_slow_average (a, a->conflict_level));
#ifndef NRESTART
    LOG ("exponential 'fast_glue' moving average %g",
	 unbiased_fast_average (a, a->fast_glue));
#endif
    LOG ("exponential 'slow_glue' moving average %g",
	 unbiased_slow_average (a, a->slow_glue));
  }

#ifndef NBUMPREASONS
  bump_reason_side_literals (solver);
#endif

#ifndef NSORTANALYZED
#ifndef NVSIDS
  if (!solver->stable)
#endif
    sort_analyzed (solver);	// Sort analyzed variables on time stamp.
#endif

  for (all_elements_on_stack (struct analyzed, analyzed, solver->analyzed))
    {
      const unsigned idx = analyzed.idx;
#ifndef NBUMP
      INC (bumped);
#if defined(NVMTF) || defined(NQUEUE)
      bump_variable_score (solver, idx);
#elif defined(NVSIDS) || defined(NHEAP)
      move_variable_to_front (solver, idx);
#else
      if (solver->stable)
	bump_variable_score (solver, idx);
      else
	move_variable_to_front (solver, idx);
#endif
#endif
      assert (marks[idx]);
      marks[idx] = 0;
    }
  CLEAR_STACK (solver->analyzed);

#ifndef NVSIDS
#ifndef NSWITCH
  if (solver->stable)
#endif
    bump_score_increment (solver);
#endif

  trace_and_check_temporary_addition (solver);

#ifndef NTARGET
  assert (solver->level);
  backtrack (solver, solver->level - 1);
  if (solver->stable)
    update_phases (solver);
  if (jump_level < solver->level)
#endif
    backtrack (solver, jump_level);

  if (size == 1)		// Learned a unit clause.
    {
      assert (!jump_level);
      solver->iterate = true;
      assign (solver, not_uip, 0);
    }
#ifndef NVIRTUAL
  else if (size == 2)
    {
      const unsigned other = ACCESS (solver->clause, 1);
      LOGBIN (true, not_uip, other, "learned");
#ifndef NLEARN
      add_new_binary_and_watch_it (solver, true);
#endif
      ADD (learned, 2);
      struct clause *reason = tag_binary_clause (true, other);
      assign (solver, not_uip, reason);
    }
#endif
  else
    {
      assert (size > 1);	// Learned and at least binary clause.
      assert (jump_level > 0);

      // First literal at jump-level becomes other watch.  Such a literal
      // has to exist and thus the 'break' below has to be hit.  We further
      // rely on backtracking not to reset the level of unassigned literals.

      for (unsigned *p = solver->clause.begin + 1, *q = p;; q++)
	{
	  assert (q != solver->clause.end);
	  const unsigned lit = *q;
	  unsigned idx = INDEX (lit);
	  unsigned lit_level = levels[idx];
	  assert (lit_level <= jump_level);
	  if (lit_level == jump_level)
	    {
	      *q = *p;
	      *p = lit;
	      break;
	    }
	}

#ifndef NGLUE
      struct clause *learned = new_redundant_clause (solver, glue);
#else
      struct clause *learned = new_redundant_clause (solver);
#endif

#ifndef NUSED
#ifndef NTIER2
      if (glue <= tier2_glue_limit)
	learned->used = 2;
      else
#endif
	learned->used = 1;
#endif
      LOGCLS (learned, "learned");
      ADD (learned, size);
#ifndef NLEARN
#ifndef NWATCHES
      watch_clause (solver, learned);
#else
      connect_clause (solver, learned);
      count_clause (solver, learned);
#endif
#endif
      assign (solver, not_uip, learned);
    }

  CLEAR_STACK (solver->clause);

  return true;
}

/*------------------------------------------------------------------------*/

#ifndef NQUEUE

static unsigned
max_stamped_unassigned_variable_on_decision_queue (struct satch *solver)
{
  struct queue *queue = get_queue (solver);
  const struct link *const links = queue->links;
  const signed char *const values = solver->values;

  unsigned idx = queue->search;

  for (;;)
    {
      assert (idx != INVALID);
      const unsigned lit = LITERAL (idx);
      const signed char value = values[lit];
      if (!value)
	break;
      idx = links[idx].prev;
    }
  queue->search = idx;		// Cache search position.

  LOG ("maximum stamped unassigned %s with stamp %u",
       LOGVAR (idx), links[idx].stamp);

  return idx;
}

#endif

#ifndef NHEAP

static unsigned
max_score_unassigned_variable_on_binary_heap (struct satch *solver)
{
  const signed char *const values = solver->values;
  struct heap *scores = get_scores (solver);

  unsigned idx;

  for (;;)
    {
      idx = max_heap (scores);
      const unsigned lit = LITERAL (idx);
      const signed char value = values[lit];
      if (!value)
	break;
      pop_heap (solver, scores);
    }

  LOG ("maximum score unassigned %s with score %g",
       LOGVAR (idx), scores->score[idx]);

  return idx;
}

#endif

/*------------------------------------------------------------------------*/

// Decision variable heuristic uses exponential 'VSIDS' in stable mode and
// 'VMTF' in focused mode unless one of these heuristics is disabled.

// The different cases in this function should match those in 'reuse_trail',
// except that the latter is only enabled if bumping is enabled too (thus we
// can replace 'NHEAP' with 'NVSIDS' and 'NQUEUE' with 'NVMTF' there).

static unsigned
decide_variable (struct satch *solver)
{
  unsigned idx;

#if defined(NHEAP)
  idx = max_stamped_unassigned_variable_on_decision_queue (solver);
#elif defined(NQUEUE)
  idx = max_score_unassigned_variable_on_binary_heap (solver);
#else
  if (solver->stable)
    idx = max_score_unassigned_variable_on_binary_heap (solver);
  else
    idx = max_stamped_unassigned_variable_on_decision_queue (solver);
#endif
  LOG ("decision %s", LOGVAR (idx));

  return idx;
}

// The decision phase is the value assigned to the decision variable. In the
// default configuration we use 'phase saving', i.e., the previous assigned
// variable to that variable and fall back to the default phase 'true' for
// never assigned variables (unless 'NTRUE' is defined, where the default
// original phase value becomes 'false').  The default value is always
// picked if phase saving is disabled ('NSAVE' is defined).

static int
original_phase (void)
{
#ifndef NTRUE
  return 1;			// Default is 'true'.
#else
  return -1;			// Otherwise 'false' (if 'NTRUE' defined).
#endif
}

static int
decide_phase (struct satch *solver, unsigned idx)
{
  signed char value = 0;
#ifndef NTARGET
  if (solver->stable)
    value = solver->targets[idx];
#endif
#ifndef NSAVE
  if (!value)
    value = solver->saved[idx];
#endif
  if (!value)
    value = original_phase ();
  LOG ("decision phase %d", (int) value);
  (void) idx;			// Prevent unused 'idx' warning.
  return value;
}

// Pick a decision variable and phase to which it is assigned as decision
// literal. Then increase decision level and assign the decision literal.

static void
decide (struct satch *solver)
{
  INC (decisions);

  assert (solver->unassigned);
  assert (!solver->inconsistent);
  assert (solver->level < solver->size);

  solver->level++;

  const unsigned idx = decide_variable (solver);
  const int value = decide_phase (solver, idx);

  const unsigned lit = LITERAL (idx);
  const unsigned decision = (value < 0 ? NOT (lit) : lit);
  LOG ("decision literal %s", LOGLIT (decision));

  assign (solver, decision, 0);
}

/*------------------------------------------------------------------------*/

// Report verbose message lines listing the following statistics. We use the
// same trick as for signal handlers in 'main.c' and for profiles above of
// listing all different reported statistics as 'REPORT' item in 'REPORTS'.
// Then we redefine 'REPORT' to instantiate 'REPORTS' accordingly.

// *INDENT-OFF*

#define REPORTS \
REPORT(seconds, "%.2f") \
REPORT(MB, "%.0f") \
REPORT(level, "%.0f") \
REPORT_IF_SWITCH(switched, "%" PRIu64) \
REPORT_IF_REDUCE(reductions, "%" PRIu64) \
REPORT_IF_RESTART(restarts, "%" PRIu64) \
REPORT(rate, "%.0f") \
REPORT(conflicts, "%" PRIu64) \
REPORT_IF_LEARN(redundant, "%" PRIu64) \
REPORT(trail, "%.0f%%") \
REPORT(glue, "%.0f") \
REPORT(irredundant, "%" PRIu64) \
REPORT(variables, "%" PRIu64) \
REPORT(remaining, "%.0f%%")

// Need to exclude 'restart' and 'reduce' reports if disabled.

#define DO_NO_REPORT(A,B) /**/

#ifdef NSWITCH
#define REPORT_IF_SWITCH DO_NO_REPORT
#else
#define REPORT_IF_SWITCH REPORT
#endif

#ifdef NLEARN
#define REPORT_IF_LEARN DO_NO_REPORT
#else
#define REPORT_IF_LEARN REPORT
#endif

#ifdef NRESTART
#define REPORT_IF_RESTART DO_NO_REPORT
#else
#define REPORT_IF_RESTART REPORT
#endif

#ifdef NREDUCE
#define REPORT_IF_REDUCE DO_NO_REPORT
#else
#define REPORT_IF_REDUCE REPORT
#endif

#define MAX_HEADER      3	// Number of header lines.
#define MAX_LINE        256	// Maximum expected line length.
#define MAX_REPORTS     16	// Maximum number of reported values.

// *INDENT-ON*

static void
report (struct satch *solver, unsigned verbose, int type)
{
  if (solver->options.verbose < verbose)
    return;

  INC (reported);

  // If you want to print a certain statistic you need to add a line to the
  // 'REPORTS' macro above and also define a matching local constant here.

  struct averages *a = averages (solver);
  const double seconds = process_time ();
  const double MB = current_resident_set_size () / (double) (1 << 20);
  const double level = unbiased_slow_average (a, a->conflict_level);
#ifndef NSWITCH
  const uint64_t switched = solver->statistics.switched;
#endif
#ifndef NREDUCE
  const uint64_t reductions = solver->statistics.reductions;
#endif
#ifndef NRESTART
  const uint64_t restarts = solver->statistics.restarts;
#endif
  const double rate = unbiased_slow_average (a, a->decision_rate);
  const uint64_t conflicts = CONFLICTS;
#ifndef NLEARN
  const uint64_t redundant = solver->statistics.redundant;
#endif
  const double trail = unbiased_slow_average (a, a->trail_filled);
  const double glue = unbiased_slow_average (a, a->slow_glue);
  const uint64_t irredundant = solver->statistics.irredundant;
  const uint64_t variables = solver->statistics.remaining;
  double remaining = percent (variables, solver->statistics.variables);

  // Start formatting the values in 'line'.

  int num_reported = 0;		// Number of reported values.

  int column[MAX_REPORTS];	// Save start of columns to format headers.
  char line[MAX_LINE];		// Actual line of values printed.
  int end_line = 0;		// End of the value line.

  line[end_line++] = 'c';

  // The values line has the following two characters less space than the
  // header lines which makes some room for the first header to stick out to
  // the left (this is also necessary for the usual 'seconds' header).

  line[end_line++] = ' ';
  line[end_line++] = type;

  // Print values to 'line' remembering starting positions and widths.

// *INDENT-OFF*

#define REPORT(NAME,FMT) \
  { \
    assert (end_line < MAX_LINE); \
    line[end_line++] = ' '; \
    column[num_reported++] = end_line; \
    char buffer[32]; \
    sprintf (buffer, FMT, NAME); \
    for (const char * p = buffer; *p; p++) \
      assert (end_line < MAX_LINE), \
      line[end_line++] = *p; \
  }
  REPORTS
#undef REPORT

// *INDENT-ON*

  // Initially and after 16 rows without printing a header we print one.
  // This gives 20 rows with 3 header lines (and one empty line) which
  // perfectly matches typical (classical small) terminal height of 24.

  COLORS (1);

  if ((solver->statistics.reported % 16) == 1)
    {
      char header[MAX_HEADER][MAX_LINE];
      int end_header[MAX_HEADER];

      for (int i = 0; i < MAX_HEADER; i++)
	{
	  header[i][0] = 'c';
	  end_header[i] = 1;
	}

      int reported = 0;

      // This is the really tricky part to get a nicely adjusted header for
      // the columns of values which vary in size.  The goal is to keep the
      // column names in the middle above the values split in different
      // header rows so that they do not overlap.  It becomes even more
      // complicated due to the possibility that strings for header names
      // can be smaller or larger than the value strings.

// *INDENT-OFF*

#define REPORT(NAME, FMT) \
      { \
        const int row = reported % MAX_HEADER; \
        assert (end_header[row] < MAX_LINE); \
        header[row][end_header[row]++] = ' '; \
        assert (reported < num_reported); \
        const int start = column[reported++]; \
        const int end = \
          (reported == num_reported ? end_line : column[reported]); \
        const int value_width = end - start - 1; \
        const int name_width = strlen (#NAME); \
        int target; \
        if (name_width > value_width) \
          target = start - (name_width - value_width + 1)/2; \
        else \
          target = start + (value_width - name_width + 1)/2; \
        assert (target <= MAX_LINE); \
        while (end_header[row] < target) \
          { \
            assert (end_header[row] < MAX_LINE); \
            header[row][end_header[row]++] = ' '; \
          } \
        for (const char * p = #NAME; *p; p++) \
          { \
            assert (end_header[row] < MAX_LINE); \
            header[row][end_header[row]++] = *p; \
          } \
      }
      REPORTS
#undef REPORT

// *INDENT-ON*

      fputs ("c\n", stdout);

      // Print the header lines.

      for (int i = 0; i < MAX_HEADER; i++)
	{
	  fputc ('c', stdout);
	  COLOR (YELLOW);
	  for (int j = 1; j < end_header[i]; j++)
	    fputc (header[i][j], stdout);
	  COLOR (NORMAL);
	  fputc ('\n', stdout);
	}

      fputs ("c\n", stdout);
    }

  // Print the values line.

  fputs ("c ", stdout);

#ifndef NCOLOR
  bool reset = false;
  if (colors)
    {
      bool magenta = false;

      switch (type)
	{
	case '0':
	case '1':
	case '?':
	case 'i':
	  fputs (BOLD_CODE, stdout);
	  reset = true;
	  break;
	case 's':
	  fputs (GREEN_CODE, stdout);
	  reset = true;
	  break;
	case 'e':
	  fputs (BOLD_GREEN_CODE, stdout);
	  reset = true;
	  break;
	case '[':
	case ']':
	  fputs (MAGENTA_CODE, stdout);
	  magenta = true;
	  break;
	}

      assert (line[2] == type);
      fputc (line[2], stdout);

      if (reset)
	fputs (NORMAL_CODE, stdout);

      if (magenta)
	reset = true;
      else if (solver->stable)
	{
	  fputs (MAGENTA_CODE, stdout);
	  reset = true;
	}
    }
  else
#endif
    fputc (line[2], stdout);

  for (int i = 3; i < end_line; i++)
    fputc (line[i], stdout);
#ifndef NCOLOR
  if (reset)
    fputs (NORMAL_CODE, stdout);
#endif
  fputc ('\n', stdout);

  fflush (stdout);
}

/*------------------------------------------------------------------------*/

// Report statistics after a unit clause has been learned and propagated.

// The reason for not reporting a unit immediately, when it is learned in
// 'analyze' above, is that such a learned root-level unit often implies
// many other literals on the root-level too and we prefer to see this
// effect of learning the unit instead of when exactly it was learned.

static void
iterate (struct satch *solver)
{
  report (solver, 1, 'i');
  solver->iterate = false;
}

/*------------------------------------------------------------------------*/

// Functions used for scaling conflict and ticks intervals.

#ifndef NRESTART

static double
logn (uint64_t n)
{
  assert (n);
  const double res = log10 (n + 9);
  assert (res >= 1);
  return res;
}

#endif

#if !defined(NELIMINATION) && !defined(NINPROCESSING)

static double
nlognlogn (uint64_t n)
{
  assert (n);
  const double tmp = log10 (n + 9);
  assert (tmp >= 1);
  const double res = n * tmp * tmp;
  assert (res >= 1);
  return res;
}

#endif

#ifndef NREPHASE

static double
nlognlognlogn (uint64_t n)
{
  assert (n);
  const double tmp = log10 (n + 9);
  assert (tmp >= 1);
  const double res = n * tmp * tmp * tmp;
  assert (res >= 1);
  return res;
}

#endif

#ifndef NREDUCE

static double
ndivlogn (uint64_t n)
{
  assert (n);
  const double div = log10 (n + 9);
  assert (div > 0);
  const double res = n / div;
  assert (res >= 1);
  return res;
}

#endif

#ifndef NSWITCH

static double
quadratic (uint64_t n)
{
  assert (n);
  const double res = n * n;
  assert (res >= 1);
  return res;
}

#endif

#if defined(NELIMINATION) || defined(NINPROCESSING)
#ifdef NREDUCE
#ifdef NREPHASE
#ifdef NSWITCH
#define NSCALE
#endif
#endif
#endif
#endif

#ifndef NSCALE

// Use one of the above scaling functions to scale the base interval based
// on the number of counts given as last argument.  For instance if you want
// to set the conflict limit for the next clause reduction in 'reduce',
// which was just was executed 'count' times, then for scaling the 'base'
// interval between 'reduce' quadratically you would  use 'quadratic' as
// argument for 'scale' (and 'base' and 'count' as further arguments).

static double
scale_interval (uint64_t base, double (*scale) (uint64_t), uint64_t count)
{
  assert (count > 0);
  double scaling = scale (count);
  assert (scaling >= 1);
  double res = base * scaling;
  assert (res >= 1);
  return res;
}

#endif

/*------------------------------------------------------------------------*/

// Before restarting we can figure out the maximum number of decisions that
// will be picked in the same way as they are currently picked.  If we find
// such a non-empty decision prefix of the trail we can reuse it and will
// not backtrack over it.  This is the strongest version of reusing the
// trail using the 'matching trail level' (MTL).  For weaker versions, both
// the 'permutation' (PTL) and 'reuse' trail level (RTL), we got worse
// results.  Thus we use the strongest one in contrast to previous solvers.

#ifndef NREUSE

#ifndef NVMTF

// Decisions are picked based on the enqueue time stamp.

static unsigned
reuse_stamped_trail (struct satch *solver)
{
  unsigned next = max_stamped_unassigned_variable_on_decision_queue (solver);
  const struct link *const links = solver->queue[solver->stable].links;
  struct clause *const *const reasons = solver->reasons;
  const unsigned next_stamp = links[next].stamp;
  unsigned decision_stamp = UINT_MAX;
  for (all_elements_on_stack (unsigned, lit, solver->trail))
    {
      const unsigned idx = INDEX (lit);
      const unsigned stamp = links[idx].stamp;
      if (decision_stamp < stamp || stamp < next_stamp)
	return solver->levels[idx] - 1;
      if (!reasons[idx])
	decision_stamp = stamp;
    }
  return solver->level;
}

#endif

#ifndef NVSIDS

// Decisions are picked based on their EVSIDS score.

static unsigned
reuse_scored_trail (struct satch *solver)
{
  unsigned next = max_score_unassigned_variable_on_binary_heap (solver);
  const double *const scores = solver->scores[solver->stable].score;
  struct clause *const *const reasons = solver->reasons;
  const double next_score = scores[next];
  double decision_score = MAX_SCORE;
  for (all_elements_on_stack (unsigned, lit, solver->trail))
    {
      const unsigned idx = INDEX (lit);
      const double score = scores[idx];
      if (decision_score < score || score < next_score)
	return solver->levels[idx] - 1;
      if (!reasons[idx])
	decision_score = score;
    }
  return solver->level;
}

#endif

// The logic of which decision heuristic to use is complex and hidden in
// this function (which needs to have the same cases as 'decide_variable').

static unsigned
reuse_trail (struct satch *solver)
{
  unsigned res;

  assert (solver->level);
  assert (!EMPTY_STACK (solver->trail));
  assert (solver->levels[INDEX (ACCESS (solver->trail, 0))]);

#ifdef NREUSESTABLE
  if (solver->stable)
    res = 0;
  else
#endif
    {
#if defined(NHEAP)
      res = reuse_stamped_trail (solver);
#elif defined(NQUEUE)
      res = reuse_scored_trail (solver);
#else
      if (solver->stable)
	res = reuse_scored_trail (solver);
      else
	res = reuse_stamped_trail (solver);
#endif
    }

  if (res)
    {
      message (solver, 4, "restart", solver->statistics.restarts,
	       "reusing trail up-to level %u out of %u levels %.0f%%",
	       res, solver->level, percent (res, solver->level));
      INC (reused);
    }
  else
    LOG ("trail not reused");

  return res;
}

#endif

/*------------------------------------------------------------------------*/

// Restarts are in principle triggered by restart intervals (measured in the
// number of conflicts passed).  However in focused mode we use exponential
// moving averages of the glucose level (glue) of learned clauses to
// determine whether we are in a phase where those levels go down or
// increase.  If the glue goes down we do not restart but if it goes up,
// that is the fast moving average is above a certain margin over the slower
// moving average, then we restart.

#ifndef NRESTART

static bool
restarting (struct satch *solver)
{
  assert (solver->unassigned);
  assert (!solver->inconsistent);

  if (!solver->level)
    return false;
  if (solver->limits.restart > CONFLICTS)
    return false;

#ifndef NSTABLE

  // Use only (large) conflict intervals in stable mode to trigger restarts.
  // However during computing the next restart limit below we use reluctant
  // doubling of the base restart interval (also called 'Luby' scheme).

  if (solver->stable)
    return true;

#endif

  struct averages *a = averages (solver);

  const double fast = unbiased_fast_average (a, a->fast_glue);
  const double slow = unbiased_slow_average (a, a->slow_glue);
  const double limit = restart_margin * slow;

  return limit <= fast;
}

static void
restart (struct satch *solver)
{
  const uint64_t restarts = INC (restarts);
  message (solver, 4, "restart", restarts,
	   "restarting after %" PRIu64 " conflicts (limit %" PRIu64 ")",
	   CONFLICTS, solver->limits.restart);
  report (solver, 3, 'r');

#ifndef NTARGET
  if (solver->stable)
    update_phases (solver);
#endif

#ifndef NREUSE
  {
    unsigned new_level = reuse_trail (solver);
    if (new_level < solver->level)
      backtrack (solver, new_level);
  }
#else
  backtrack (solver, 0);
#endif

  uint64_t interval;
#ifndef NSTABLE
  if (solver->stable)
    {
      // This is the approach of Donald Knuth to compute the 'reluctant
      // doubling' sequence. In other solvers it is called 'Luby' sequence.
      // We further use a much longer base interval than in focused mode.

      struct reluctant *r = &solver->reluctant;
      uint64_t u = r->u, v = r->v;

      // The base interval is multiplied with the reluctant doubling
      // sequence number (1,2,1,1,2,4,1,1,2,4,8,1,1,2,1,1,2,4,1,1,...).

      interval = v * stable_restart_interval;

      if ((u & -u) == v)
	u++, v = 1;
      else
	assert (UINT64_MAX / 2 >= v), v *= 2;
      r->u = u, r->v = v;
    }
  else
#endif
    {
      assert (restart_interval >= 1);
      interval = (restart_interval - 1) + logn (restarts);
      assert (restart_interval <= interval);
    }

  solver->limits.restart = CONFLICTS + interval;

  message (solver, 4, "restart", restarts,
	   "new %s restart limit %" PRIu64 " after %" PRIu64 " conflicts",
	   solver->stable ? "stable" : "focused",
	   solver->limits.restart, interval);
}

#endif

/*------------------------------------------------------------------------*/

// Rephasing is the process of resetting the saved phases of the solver in
// increasing intervals.  It can be seen as a diversification method with
// respect to the selected phases (since phase saving might be considered
// to be too stubborn).  However, in combination with reusing best-phases
// and particularly target-phases it has more an intensification flavor.

// In the past, we experimented with many variants on how to reset phases
// and now reached the following set-up, which seems to give consistent
// improvements. First it seems that rephasing is only beneficial in stable
// mode. Second we only reset to the original, the inverted-original or the
// best-phase seen. Third we schedule rephasing slightly more frequently than
// mode switching, such that for instance initially maybe the phases are
// reset twice in one stable mode interval and then this number increases
// slowly in later stable mode intervals.

// At this point we do not have local search rephasing incorporated yet
// which we do consider to give benefits.  It is also not combined with
// autarky simplification either which allows to save partial satisfying
// assignments. Both are implemented in Kissat and need to be ported.

#ifndef NREPHASE

static bool
rephasing (struct satch *solver)
{
  if (!solver->stable)
    return false;
  return solver->limits.rephase <= CONFLICTS;
}

static char
original_phases (struct satch *solver)
{
  const signed char value = original_phase ();
  memset (solver->saved, value, VARIABLES);
  return 'O';
}

#ifndef NINVERTED

static char
inverted_phases (struct satch *solver)
{
  const signed char value = -original_phase ();
  memset (solver->saved, value, VARIABLES);
  return 'I';
}

#endif

#ifndef NBEST

static char
best_phases (struct satch *solver)
{
  const signed char *const bests = solver->bests;
  const signed char *const end = bests + VARIABLES;
  signed char *const saved = solver->saved;
  signed char *q = saved, tmp;
  for (const signed char *p = bests; p != end; p++, q++)
    if ((tmp = *p))
      *q = tmp;
  solver->best = 0;
  return 'B';
}

#endif

static void
rephase (struct satch *solver)
{
  char (*functions[4]) (struct satch *);
  unsigned size_functions = 0;

#ifndef NINVERTED
  functions[size_functions++] = inverted_phases;
#ifndef NBEST
  functions[size_functions++] = best_phases;
#endif
#endif
  functions[size_functions++] = original_phases;
#ifndef NBEST
  functions[size_functions++] = best_phases;
#endif
  assert (size_functions <= sizeof functions / sizeof *functions);

  const uint64_t rephased = INC (rephased);
  const char type = functions[rephased % size_functions] (solver);

  const uint64_t interval =
    scale_interval (rephase_interval, nlognlognlogn, rephased);
  solver->limits.rephase = CONFLICTS + interval;
  message (solver, 4, "rephase", rephased,
	   "new rephase limit %" PRIu64 " conflicts after %" PRIu64,
	   solver->limits.rephase, interval);
#ifndef NTARGET
  if (solver->stable)
    {
      LOG ("reset target size");
      memcpy (solver->targets, solver->saved, VARIABLES);
      solver->target = 0;
    }
#endif
  report (solver, 1, type);
}

#endif

/*------------------------------------------------------------------------*/

// Reducing the clause data base by removing useless redundant clauses is
// important to keep the memory usage of the solver low, but also to
// speed-up propagation.  The reduction interval in terms of conflicts is
// increased (almost) arithmetically by 'reduce_interval'.  We combine
// reductions with clause data base simplifications which remove root-level
// satisfied clauses.  Removing falsified literals is not implemented yet.

#ifndef NREDUCE

static bool
reducing (struct satch *solver)
{
  return solver->limits.reduce.conflicts <= CONFLICTS;
}

// Protect reason clauses from garbage collection. The same function can
// be used afterwards to make reason clauses unprotected again.  It is
// better to lazily protect clauses during reductions instead of eagerly
// setting the 'protect' bit during assignments to avoid dereferencing
// pointers to binary clause reasons (if 'NBLOCK' is defined).

static void
set_protect_flag_of_reasons (struct satch *solver, bool protect)
{
  struct clause *const *const reasons = solver->reasons;
  for (all_elements_on_stack (unsigned, lit, solver->trail))
    {
      const unsigned idx = INDEX (lit);
      struct clause *reason = reasons[idx];
      if (!reason)
	continue;
#ifndef NBLOCK
      if (is_tagged_clause (reason))
	continue;
#endif
      LOGCLS (reason, "%sprotecting", protect ? "" : "un");
      assert (reason->protected != protect);
      reason->protected = protect;
    }
}

#endif

#if !defined(NREDUCE) || !defined(NELIMINATION)

// Check whether a clause is root-level satisfied, i.e., it contains a
// literal which is assigned to true on decision-level zero.  Otherwise
// flush (at least) virtually all root-level falsified literals.  The latter
// is important for marking flushed literals as new subsume candidates.

static bool
clause_satisfied (struct satch *solver, struct clause *c)
{
  assert (!solver->level);
#ifndef NVIRTUAL
  assert (!is_tagged_clause (c));
  assert (!is_temporary_binary (solver, c));
  assert (!c->protected);
#endif

  const signed char *const values = solver->values;
  unsigned num_false = 0;

  for (all_literals_in_clause (lit, c))
    {
      const signed char value = values[lit];
      if (value > 0)
	return true;
      if (value < 0)
	num_false++;
    }

  if (!num_false)
    return false;

  LOGCLS (c, "found %u root-level falsified in", num_false);

  assert (EMPTY_STACK (solver->clause));
  for (all_literals_in_clause (lit, c))
    if (!values[lit])
      PUSH (solver->clause, lit);

#ifndef NSUBSUMPTION
  for (all_elements_on_stack (unsigned, lit, solver->clause))
      mark_subsume_literal (solver, lit);
#endif

  if (!solver->dense)
    {
      trace_and_check_temporary_addition (solver);
      trace_and_check_clause_deletion (solver, c);

#ifndef NWATCHES
      const unsigned *old_lits = c->literals;
      const unsigned *new_lits = solver->clause.begin;

      // Unwatching might break code where we traverse watchers, which is
      // currently only the case when called in dense mode from
      // 'actual_number_of_occurrences' and thus not reached.

      unwatch_literal (solver, old_lits[0], c);
      unwatch_literal (solver, old_lits[1], c);
#else
      for (all_literals_in_clause (lit, c))
	disconnect_literal (solver, lit, c);
#endif

      const size_t size = SIZE_STACK (solver->clause);
      assert (size == c->size - num_false);
      assert (size >= 2);

      // We can not simply add a new clause since this function is called
      // while traversing the 'irredundant' or 'redundant' stacks.  Instead
      // we disconnect and add new watches.  Partially keeping unassigned
      // watches is possible but needs more complex code (it might also
      // result in blocking literals not in the clause anymore).

#ifndef NVIRTUAL
      if (size == 2)
	{
	  watch_binary (solver, c->redundant, new_lits[0], new_lits[1]);
	  watch_binary (solver, c->redundant, new_lits[1], new_lits[0]);
	  LOGCLS (c, "garbage after flushing %u literals", num_false);
	  c->garbage = true;
	}
      else
#endif
	{
#ifndef NWATCHES
#ifndef NBLOCK
	  watch_literal (solver, c->redundant, new_lits[0], new_lits[1], c);
	  watch_literal (solver, c->redundant, new_lits[1], new_lits[0], c);
#else
	  watch_literal (solver, new_lits[0], c);
	  watch_literal (solver, new_lits[1], c);
#endif
#endif
	  unsigned *p = c->literals;
	  for (all_elements_on_stack (unsigned, lit, solver->clause))
	     *p++ = lit;

	  c->size = size;
#ifndef NGLUE
	  if (c->redundant && c->size >= c->glue)
	    c->glue = size - 1;
#endif
#ifndef NCACHE
	  c->search = 0;
#endif
#ifdef NWATCHES
	  connect_clause (solver, c);
	  count_clause (solver, c);
#endif
	  LOGCLS (c, "flushing %u literals yields", num_false);
	}

      // But there is no need to update clause statistics.
    }

  CLEAR_STACK (solver->clause);

  return false;
}

// This function is called in default sparse mode from 'reduce' only and
// then (through 'clause_satisfied') also flushes falsified literals.  In
// dense mode it is only called from 'actual_number_of_occurrences' during
// variable elimination attempts.  There it only updates 'subsume'
// candidates if the clause is not garbage but contains falsified literals.

static bool
mark_garbage_if_satisfied (struct satch *solver, struct clause *c)
{
  assert (!solver->level);
#ifndef NVIRTUAL
  assert (!is_tagged_clause (c));
  assert (!is_temporary_binary (solver, c));
#endif
  if (c->garbage)
    return true;
  if (!clause_satisfied (solver, c))
    return false;
  mark_garbage (solver, c, "root-level satisfied");
  return true;
}

// Irredundant clauses are not reduced, but marked garbage if they are
// root-level satisfied clauses and can then be collected during reduction
// too.  This is only necessary if there are new root-level fixed variables
// since the last reduction though (and restricted to unprotected clauses).

// We also use this function after variable elimination since we might not
// have found and marked all the satisfied clauses during elimination.

// For subsumption an important side-effect of this function is to mark
// unassigned literals in not-satisfied irredundant clauses which contain
// false literals too as subsumption candidates.

static void
mark_irredundant_clauses_as_garbage_if_satisfied (struct satch *solver)
{
  assert (!solver->level);
  for (all_irredundant_clauses (c))
    (void) mark_garbage_if_satisfied (solver, c);
}

#endif

#ifndef NREDUCE

// Redundant clauses with large enough glucose level (glue) which have not
// been used since the last reduction are deletion candidates. If there
// are new root-level fixed variables since the last reduction we also
// mark clauses as garbage which are root-level satisfied.

static void
gather_reduce_candidates (struct satch *solver, bool new_fixed,
			  struct clauses *candidates)
{
  // Reverse order is needed for radix sort to ensure that more recently
  // learned clauses are kept if they have the same size and glue.

  // Without radix sort we need to use clause id's as tie-breaker anyhow and
  // thus reversing the redundant clauses on the candidates stack is not
  // necessary but also not harmful.

  for (all_redundant_clauses_in_reverse (c))
    {
      assert (c->redundant);
      if (c->garbage)
	continue;
      if (c->protected)
	continue;
      if (new_fixed)
	{
	  if (mark_garbage_if_satisfied (solver, c))
	    continue;
	  if (c->garbage)
	    continue;
	}
#ifndef NVIRTUAL
      assert (c->size > 2);
#else
      // As we can not protect binary reason clauses we just ignore them as.
      assert (c->size > 1);
      if (c->size == 2)
	continue;
#endif
#ifndef NTIER1
      if (c->glue <= tier1_glue_limit)
	continue;
#endif
#ifndef NUSED
      if (c->used)
	{
	  c->used--;		// Works for both 'used:1' and 'used:2'.
#ifndef NTIER2
	  if (c->glue <= tier2_glue_limit)
#endif
	    continue;
	}
#endif
      PUSH (*candidates, c);
    }

  if (solver->options.verbose < 2)
    return;

  const size_t size_candidates = SIZE_STACK (*candidates);
  const size_t redundant = SIZE_STACK (solver->redundant);
  message (solver, 2, "reduce", solver->statistics.reductions,
	   "gathered %zu reduce candidate clauses %.0f%%",
	   size_candidates, percent (size_candidates, redundant));
}

// Before actually deleting the garbage clauses we have to flush of course
// watches from the watcher lists pointing to such garbage clauses.

static void
flush_garbage_watches (struct satch *solver)
{
  struct watches *all_watches = solver->watches;
#ifndef NVIRTUAL
  signed char *const values = solver->values;
  const unsigned *const levels = solver->levels;
#endif
  for (all_literals (lit))
    {
#ifndef NVIRTUAL
      signed char lit_value = values[lit];
      if (lit_value && levels[INDEX (lit)])
	lit_value = 0;
#endif
      struct watches *const lit_watches = all_watches + lit;
      union watch *const end = lit_watches->end;
      union watch *q = lit_watches->begin;
      const union watch *p = q;
      while (p != end)
	{
#ifndef NBLOCK
	  const union watch watch = *p++;
#ifndef NVIRTUAL
	  const struct header header = watch.header;
	  if (header.binary)
	    {
	      const unsigned blocking = header.blocking;

	      signed char blocking_value = values[blocking];
	      if (blocking_value && levels[INDEX (blocking)])
		blocking_value = 0;

	      // We want to eagerly remove root-level satisfied binary
	      // clauses as well, but since those sit in watch lists only
	      // (if 'NVIRTUAL' and 'NBLOCK' are undefined) we have to check
	      // whether the literal or the other blocking literal are
	      // root-level assigned.  In both cases (since we assume
	      // propagation went to completion on the root-level) we know
	      // that the binary clause has to be satisfied.

	      if (lit_value || blocking_value)
		{
		  assert (lit_value > 0 || blocking_value > 0);
		  delete_binary (solver, header.redundant, lit, blocking);
		  continue;	// Drop header by not copying it.
		}
	      *q++ = watch;	// Keep header and skip non-existing clause.
	      continue;
	    }
#endif
	  *q++ = watch;		// Keep blocking literal header.
#endif
	  const struct clause *const clause = (*q++ = *p++).clause;
	  if (clause->garbage)
	    q -= long_clause_watch_size;	// Stop watching clause.
	}
      lit_watches->end = q;
    }
}

#endif

#if !defined(NREDUCE) || !defined(NELIMINATION)

// After removing garbage watches we can finally delete garbage clauses.

static void
delete_garbage_clauses (struct satch *solver, struct clauses *clauses,
			size_t *bytes_ptr, size_t *count_ptr)
{
  size_t bytes = 0;
  size_t count = 0;

  struct clause *const *const end = clauses->end;
  struct clause **q = clauses->begin;

  for (struct clause ** p = q; p != end; p++)
    {
      struct clause *const c = *p;
      if (c->garbage)
	{
	  assert (!c->protected);
	  bytes += delete_clause (solver, c);
	  count++;
	}
      else
	*q++ = c;
    }
  clauses->end = q;

  *bytes_ptr += bytes;
  *count_ptr += count;
}

#endif

#ifndef NREDUCE

/*------------------------------------------------------------------------*/

// Candidate clauses considered to be reduced are sorted with respect to
// their potential usefulness in the future.  Clauses are considered more
// useful if they have a smaller glue or smaller size with the same glue.
// If both glue and size are the same we keep more recently learned clauses.

#ifndef NRADIXSORT

#ifndef NGLUE

static uint64_t
rank_clause (struct clause *c)
{
  return ((uint64_t) c->glue << 32) + c->size;
}

static void
sort_reduce_candidates (struct clauses *candidates)
{
  RSORT (struct clause *, uint64_t, *candidates, rank_clause);
}

#else

static unsigned
rank_clause (struct clause *c)
{
  return c->size;
}

static void
sort_reduce_candidates (struct clauses *candidates)
{
  RSORT (struct clause *, unsigned, *candidates, rank_clause);
}

#endif

#else

// This the actual comparison functions for 'qsort' to order reduce
// candidates.  The result is negative if the first argument is more useful
// than the second.  The result is positive, if the second argument is more
// useful.  Since 'qsort is not stable we make comparison deterministic by
// using clause id's as tie-breaker which also makes sure that more recently
// learned clauses are considered to be more useful in the future if they
// happen to have the same glue and size.

static int
cmp_reduce (const void *p, const void *q)
{
  const struct clause *const c = *(const struct clause * const *) p;
  const struct clause *const d = *(const struct clause * const *) q;
#ifndef NGLUE
  if (c->glue < d->glue)
    return -1;
  if (c->glue > d->glue)
    return 1;
#endif
  if (c->size < d->size)
    return -1;
  if (c->size > d->size)
    return 1;
  if (c->id < d->id)
    return 1;
  assert (c->id > d->id);
  return -1;
}

static void
sort_reduce_candidates (struct clauses *candidates)
{
  struct clause **begin = candidates->begin;
  qsort (begin, SIZE_STACK (*candidates), sizeof *begin, cmp_reduce);
}

#endif

/*------------------------------------------------------------------------*/

// From the remaining candidates we reduce 'reduce_fraction' of clauses.

static void
mark_garbage_candidates (struct satch *solver, struct clauses *candidates)
{
  const size_t size = SIZE_STACK (*candidates);
  assert (0.0 <= reduce_fraction);
  const size_t reduce = reduce_fraction * size;

  message (solver, 4, "reduce", solver->statistics.reductions,
	   "target is to reduce %zu out of %zu clauses %.0f%%",
	   reduce, size, percent (reduce, size));

  const double keep_fraction = 1.0 - reduce_fraction;
  const size_t keep = keep_fraction * size;

  size_t reduced = 0;

  while (SIZE_STACK (*candidates) > keep)
    {
      struct clause *c = POP (*candidates);
      assert (!c->protected);
      mark_garbage (solver, c, "reducing");
      reduced++;
    }

  ADD (reduced, reduced);

  message (solver, 3, "reduce", solver->statistics.reductions,
	   "reducing %zu out of %zu clauses %.0f%%",
	   reduced, size, percent (reduced, size));

}

/*------------------------------------------------------------------------*/

#ifndef NDEBUG

// Even though the 'irredundant' and 'redundant' clause statistics are only
// used for reporting we still want to accurately measure and maintain them,
// which unfortunately is not trivial.  These reports are very useful for
// engineering heuristics (and sometimes debugging).

// Thus we perform this explicit check before and after 'reduce'.

static void
check_clause_statistics (struct satch *solver)
{
  assert (!solver->dense);

  uint64_t irredundant = 0;
  uint64_t redundant = 0;

#ifndef NVIRTUAL
  for (all_literals (lit))
    {
      const struct watches *const watches = solver->watches + lit;
      const union watch *const end = watches->end;
      const union watch *p = watches->begin;
      while (p != end)
	{
	  const union watch watch = *p++;
	  const struct header header = watch.header;
	  if (header.binary)
	    {
	      const unsigned other = header.blocking;
	      if (lit < other)
		{
		  if (header.redundant)
		    redundant++;
		  else
		    irredundant++;
		}
	    }
	  else
	    p++;
	}
    }
#endif

  for (all_irredundant_clauses (c))
    if (!c->garbage)
      irredundant++;

  for (all_redundant_clauses (c))
    if (!c->garbage)
      redundant++;

  assert (irredundant == solver->statistics.irredundant);
  assert (redundant == solver->statistics.redundant);
}

#endif

/*------------------------------------------------------------------------*/

// Reduce less useful redundant clauses frequently.

static void
reduce (struct satch *solver)
{
#ifndef NDEBUG
  check_clause_statistics (solver);
#endif
  START (reduce);
  const uint64_t reductions = INC (reductions);

  // If there are new fixed (root-level assigned) variables since the last
  // reduction, we remove both satisfied irredundant clauses here and later
  // satisfied redundant clauses in 'gather_reduce_candidates'.  Both call
  // 'mark_garbage_if_satisfied' for large clauses, which in turn calls
  // 'clause_satisfied' and thus also flushes falsified literals.

  // Without new fixed variable we do not backtrack but protect reasons.

  const bool new_fixed =
    solver->limits.reduce.fixed < solver->statistics.fixed;

  if (new_fixed)
    {
      update_phases_and_backtrack_to_root_level (solver);
      mark_irredundant_clauses_as_garbage_if_satisfied (solver);
    }
  else
    set_protect_flag_of_reasons (solver, true);

  // At the core of reduction is to first gather potential redundant reduce
  // candidate clauses (omitting those that are definitely kept).  Then
  // these candidates are sorted with respect to a metric which is supposed
  // to reflect potential usefulness. From the less useful clauses a large
  // fraction ('reduce_fraction') is then marked as garbage to be collected.

  {
    struct clauses candidates;
    INIT_STACK (candidates);

    gather_reduce_candidates (solver, new_fixed, &candidates);
    sort_reduce_candidates (&candidates);
    mark_garbage_candidates (solver, &candidates);

    RELEASE_STACK (candidates);
  }

  // Before we can delete the garbage clauses we first have to remove
  // references to those clauses marked as garbage from the watch lists.

  flush_garbage_watches (solver);

  // As next to final step we delete garbage clauses and print statistics.

  {
    size_t bytes = 0, count = 0;
    if (new_fixed)
      delete_garbage_clauses (solver, &solver->irredundant, &bytes, &count);
    delete_garbage_clauses (solver, &solver->redundant, &bytes, &count);

    // We report on how many clauses we collected during reduction.

    message (solver, 2, "reduce", reductions,
	     "collected %zu clauses (%zu bytes, %.0f MB)",
	     count, bytes, bytes / (double) (1u << 20));

    ADD (collected, bytes);
  }

  // No we can mark reasons of literals on the trail as unprotected.

  if (!new_fixed)
    set_protect_flag_of_reasons (solver, false);

  // Finally we compute and report the next conflict limit for reduction.

  {
    solver->limits.reduce.fixed = solver->statistics.fixed;
    const uint64_t interval =
      scale_interval (reduce_interval, ndivlogn, reductions);
    solver->limits.reduce.conflicts = CONFLICTS + interval;
    message (solver, 4, "reduce", reductions,
	     "next limit at %" PRIu64 " after %" PRIu64 " conflicts",
	     solver->limits.reduce.conflicts, interval);
  }

  report (solver, 1, '-');
  STOP (reduce);
#ifndef NDEBUG
  check_clause_statistics (solver);
#endif
}

#endif

/*------------------------------------------------------------------------*/

// Switch between focused mode with aggressive restarting and stable mode
// with almost no restarting.  At the same time switch between two different
// decision variable schemes (by default VMTF vs (E)VSIDS).  During stable
// mode we also enable rephasing and target phases.  The two modes have
// separate averages ('glue', 'rate', 'level' and 'trail').

// Starting and ending a mode is indicated by a '{' and '}' pair for focused
// mode (the initial mode) and '[' and ']' for stable mode.

#ifndef NSWITCH

static void
start_mode (struct satch *solver)
{
  if (solver->stable)
    {
      START (stable);
      report (solver, 1, '[');
      LOG ("start stable mode");
    }
  else
    {
      START (focused);
      report (solver, 1, '{');
      LOG ("start focused mode");
    }
}

static void
stop_mode (struct satch *solver)
{
  if (solver->stable)
    {
      STOP (stable);
      LOG ("stop stable mode");
      report (solver, 1, ']');
    }
  else
    {
      STOP (focused);
      LOG ("stop focused mode");
      report (solver, 1, '}');
    }
}

// Initially (for the first focused mode phase) we use a non-zero conflict
// limit ('initial_mode_conflicts_interval') and then compute the number of
// 'ticks' spent in this first mode.  This is then used as base ticks
// interval for the length of the remaining mode phases.

// To indicate that we moved to a ticks based limits we set
// 'limits->mode.conflicts' to zero after the first mode switch.
// Accordingly when testing for switching we first check whether that is
// zero and then use ticks instead of conflicts.

// As you can see we still use a ticks limit for the first round since we
// encountered cases were relying on conflicts only took too much time.

static bool
switching (struct satch *solver)
{
  struct limits *limits = &solver->limits;
  if (limits->mode.conflicts && limits->mode.conflicts <= CONFLICTS)
    return true;
  return limits->mode.ticks.limit <= TICKS;
}

static void
set_new_mode_switching_limit (struct satch *solver, uint64_t switched)
{
  struct limits *limits = &solver->limits;
  const uint64_t interval = limits->mode.ticks.interval;
  const uint64_t count = (switched + 1) / 2;
  const uint64_t scaled = scale_interval (interval, quadratic, count);
  solver->limits.mode.ticks.limit = TICKS + scaled;
  message (solver, 3, "switch", switched,
	   "new %s mode limit of %" PRIu64 " ticks after %" PRIu64 " ticks",
	   solver->stable ? "focused" : "stable",
	   limits->mode.ticks.limit, scaled);
}

static void
mode_ticks_limit_hit (struct satch *solver, uint64_t switched)
{
  message (solver, 2, "switch", switched,
	   "limit of %" PRIu64 " ticks hit at %" PRIu64 " ticks",
	   solver->limits.mode.ticks.limit, TICKS);
}

static void
switch_to_focused_mode (struct satch *solver, uint64_t switched)
{
  assert (solver->stable);
  mode_ticks_limit_hit (solver, switched);
  solver->stable = false;
  assert (switched >= 2);
  assert (!(switched & 1));
}

static void
switch_to_stable_mode (struct satch *solver, uint64_t switched)
{
  assert (!solver->stable);

  struct limits *limits = &solver->limits;

  if (limits->mode.conflicts)
    {
      message (solver, 2, "switch", switched,
	       "limit of %" PRIu64 " conflicts hit at %"
	       PRIu64 " conflicts and %" PRIu64 " ticks",
	       limits->mode.conflicts, CONFLICTS, TICKS);

      limits->mode.ticks.interval = TICKS;
      limits->mode.conflicts = 0;
    }
  else
    mode_ticks_limit_hit (solver, switched);

  solver->stable = true;
  assert ((switched & 1));

#ifndef NRESTART
  solver->reluctant.u = solver->reluctant.v = 1;
  solver->limits.restart = CONFLICTS + stable_restart_interval;
#endif

#ifndef NTARGET
  LOG ("reset target size");
  solver->target = 0;
#endif
}

static void
switch_mode (struct satch *solver)
{
  stop_mode (solver);
  const uint64_t switched = INC (switched);

  // Make sure to push back all assigned variables to the scores heap and
  // reset the VMTF queue if there are still variables on the trail.
  // Otherwise the scores heap respectively the queue is not really saved.
  // There is even the danger to violate the invariant that unassigned
  // literals are not all on the binary heap when switching back etc.

  if (solver->level)
    backtrack (solver, 0);

  if (solver->stable)
    switch_to_focused_mode (solver, switched);
  else
    switch_to_stable_mode (solver, switched);

  // Save the number of decisions when entering the new mode to compute the
  // mode specific 'decision rate' exponential moving average.

  struct averages *a = averages (solver);
  a->saved_decisions = DECISIONS;

  set_new_mode_switching_limit (solver, switched);
  start_mode (solver);
}

#endif

/*------------------------------------------------------------------------*/
#ifndef NELIMINATION
/*------------------------------------------------------------------------*/

static bool
more_elimination_candidates (struct satch *solver)
{
  return solver->statistics.marked_eliminate >
    solver->limits.eliminate.marked;
}

#ifndef NSUBSUMPTION

static bool
more_subsumption_candidates (struct satch *solver)
{
  return solver->statistics.marked_subsume > solver->limits.subsume.marked;
}

#endif

static bool
eliminating (struct satch *solver)
{
  if (!more_elimination_candidates (solver))
#ifndef NSUBSUMPTION
    if (!more_subsumption_candidates (solver))
#endif
      return false;
#ifndef NINPROCESSING
  return solver->limits.eliminate.conflicts < CONFLICTS;
#else
  return !solver->statistics.eliminations;
#endif
}

/*------------------------------------------------------------------------*/

// The code for switching from sparse to dense mode and back heavily relies
// on how watches are organized ('NVIRTUAL' or even 'NBLOCK' is defined).

#ifndef NVIRTUAL

// This is the default routine for flushing all redundant watches where we
// use virtual binary clauses and blocking literals.

// It is the most complex variant because binary clauses reside in watches
// only and thus the redundant binary clauses have to be saved while the
// irredundant ones are kept.  The redundant-clause watches are flushed
// completely, while for the redundant-clause watches we remove the header.

// Furthermore, since in dense mode we only have clause references as watches
// we need to use the same mechanism as for reasons to store binary clauses
// (actually only the other literal) through tagged clause pointers.

static void
flush_redundant_watches (struct satch *solver, bool new_fixed)
{
  assert (EMPTY_STACK (solver->binaries));
  const struct flags *const flags = solver->flags;
  for (all_literals (lit))
    {
      struct watches *watches = solver->watches + lit;
      const union watch *const end = watches->end;
      union watch *q = watches->begin, *p = q;
      const bool lit_active = new_fixed ? true : flags[INDEX (lit)].active;
      while (p != end)
	{
	  struct header header = p->header;
	  if (header.binary)
	    {
	      const unsigned other = header.blocking;
	      const bool redundant = header.redundant;
	      const bool other_active =
		new_fixed ? true : flags[INDEX (other)].active;

	      if (lit_active && other_active)
		{
		  if (header.redundant)
		    {
		      if (lit < other)
			{
			  PUSH (solver->binaries, lit);
			  PUSH (solver->binaries, other);
			}
		    }
		  else
		    q++->clause = tag_binary_clause (false, other);
		}
	      else
		delete_binary (solver, redundant, lit, other);

	      p++;
	    }
	  else
	    {
	      if (!header.redundant)
		{
		  struct clause *c = p[1].clause;
		  if (!new_fixed || !c->garbage)
		    q++->clause = c;
		}

	      p += 2;
	    }
	}
      watches->end = q;
      if (EMPTY_STACK (*watches))
	RELEASE_STACK (*watches);
    }
  LOG ("saved %zu redundant binary clauses",
       SIZE_STACK (solver->binaries) / 2);
}

#elif !defined(NBLOCK)

// With blocking literals but without virtual clauses the watches all have
// both a header and a clause.  We always drop the header (the blocking
// literal) and in addition flush the reference to redundant clauses.

static void
flush_redundant_watches (struct satch *solver, bool new_fixed)
{
  for (all_literals (lit))
    {
      struct watches *watches = solver->watches + lit;
      const union watch *const end = watches->end;
      union watch *q = watches->begin;
      for (const union watch * p = q; p != end; p += 2)
	if (!p->header.redundant)
	  {
	    struct clause *c = p[1].clause;
	    if (!new_fixed || !c->garbage)
	      *q++ = p[1];
	  }
      watches->end = q;
      if (EMPTY_STACK (*watches))
	RELEASE_STACK (*watches);
    }
}

#else

// The simplest case without blocking literals (and also without virtual
// binary clauses) we just flush redundant clauses. This has the same effect
// as in the previous case (no virtual binary clauses but with blocking
// literals) and thus when working in dense mode code we only need to
// distinguish between having virtual binary clauses or not.

static void
flush_redundant_watches (struct satch *solver, bool new_fixed)
{
  for (all_literals (lit))
    {
      struct watches *watches = solver->watches + lit;
      const union watch *const end = watches->end;
      union watch *q = watches->begin;
      struct clause *c;
      for (const union watch * p = q; p != end; p++)
	if (!(c = p->clause)->redundant && (!new_fixed || !c->garbage))
	  *q++ = *p;
      watches->end = q;
      if (EMPTY_STACK (*watches))
	RELEASE_STACK (*watches);
    }
}

#endif

static void
connect_occurrences_in_irredundant_clauses (struct satch *solver)
{
  assert (solver->dense);
  for (all_irredundant_clauses (c))
    {
      const unsigned *const lits = c->literals;
      const unsigned *const end = lits + c->size;
      for (const unsigned *p = lits + 2; p != end; p++)
       if (!c->garbage)
         connect_literal (solver, *p, c);
    }
}

static void
switch_to_dense_mode (struct satch *solver)
{
  LOG ("switching to dense mode");
  assert (!solver->dense);
  bool new_fixed = solver->limits.eliminate.fixed < solver->statistics.fixed;
  if (new_fixed)
    mark_irredundant_clauses_as_garbage_if_satisfied (solver);
  flush_redundant_watches (solver, new_fixed);
  solver->dense = true;
  connect_occurrences_in_irredundant_clauses (solver);
}

/*------------------------------------------------------------------------*/

#ifndef NVIRTUAL

// With virtual binary clauses we need to make sure to keep the irredundant
// binary clauses in the watcher stacks but otherwise drop all references.

static void
disconnect_all_clauses (struct satch *solver)
{
  assert (solver->dense);
  const struct flags *const flags = solver->flags;
  for (all_literals (lit))
    {
      struct watches *watches = solver->watches + lit;
      const union watch *const end = watches->end;
      union watch *q = watches->begin;
      struct clause *c;
      bool lit_eliminated = flags[INDEX (lit)].eliminated;
      for (const union watch * p = q; p != end; p++)
	if (is_tagged_clause (c = p->clause))
	  {
	    const unsigned other = tagged_clause_to_literal (c);
	    const bool other_eliminated = flags[INDEX (other)].eliminated;
	    if (!lit_eliminated && !other_eliminated)
	      {
		union watch watch;
		watch.header.binary = true;
		watch.header.redundant = false;
		watch.header.blocking = other;
		*q++ = watch;
	      }
	    else
	      delete_binary (solver, false, lit, other);
	  }
      watches->end = q;
    }
}

#else

static void
disconnect_all_clauses (struct satch *solver)
{
  assert (solver->dense);
  for (all_literals (lit))
    CLEAR_STACK (solver->watches[lit]);
}

#endif

#ifndef NVIRTUAL

static void
watch_saved_redundant_binaries (struct satch *solver)
{
  const unsigned *begin = solver->binaries.begin;
  const unsigned *end = solver->binaries.end;
  const struct flags *const flags = solver->flags;
  for (const unsigned *p = begin; p != end; p += 2)
    {
      const unsigned i[2] = { INDEX (p[0]), INDEX (p[1]) };
      const struct flags f[2] = { flags[i[0]], flags[i[1]] };
      const bool eliminated[2] = { f[0].eliminated, f[1].eliminated };
      if (!eliminated[0] && !eliminated[1])
	{
	  watch_binary (solver, true, p[0], p[1]);
	  watch_binary (solver, true, p[1], p[0]);
	}
      else
	delete_binary (solver, true, p[0], p[1]);
    }
  CLEAR_STACK (solver->binaries);
}

#endif

static void
watch_clauses (struct satch *solver, struct clauses *clauses)
{
  for (all_pointers_on_stack (struct clause, c, *clauses))
      watch_clause (solver, c);
}

static void
switch_to_sparse_mode (struct satch *solver)
{
  LOG ("switching back to sparse mode");
  assert (solver->dense);
  disconnect_all_clauses (solver);
  solver->dense = false;
#ifndef NVIRTUAL
  watch_saved_redundant_binaries (solver);
#endif
  watch_clauses (solver, &solver->irredundant);
  watch_clauses (solver, &solver->redundant);
}

/*------------------------------------------------------------------------*/

// Check whether a (redundant) clause contains an eliminated literal.

static bool
clause_eliminated (struct satch *solver, struct clause *c)
{
  assert (c->redundant);	// Coincidentally.
  assert (!solver->level);
  const struct flags *const flags = solver->flags;
  for (all_literals_in_clause (lit, c))
    if (flags[INDEX (lit)].eliminated)
      return true;
  return false;
}

static void
mark_satisfied_eliminated_redundant_clauses_garbage (struct satch *solver)
{
  for (all_redundant_clauses (c))
    if (!c->garbage)
      {
	if (clause_eliminated (solver, c))
	  mark_garbage (solver, c, "eliminated");
	else if (clause_satisfied (solver, c))
	  mark_garbage (solver, c, "root-level satisfied");
      }
}

// The irredundant eliminated clauses have been marked explicitly already
// but we still need to mark redundant clauses with eliminated variables.

static void
mark_and_collect_garbage_clauses_after_elimination (struct satch *solver)
{
  assert (solver->dense);	// No flushing in 'clause_satisfied'!

  if (solver->limits.eliminate.fixed < solver->statistics.fixed)
    mark_irredundant_clauses_as_garbage_if_satisfied (solver);

  mark_satisfied_eliminated_redundant_clauses_garbage (solver);

  {
    size_t bytes = 0, count = 0;
    delete_garbage_clauses (solver, &solver->irredundant, &bytes, &count);
    delete_garbage_clauses (solver, &solver->redundant, &bytes, &count);

    // We report on how many clauses we collected during elimination.

    message (solver, 2, "elimination", solver->statistics.eliminations,
	     "collected %zu clauses (%zu bytes, %.0f MB)",
	     count, bytes, bytes / (double) (1u << 20));

    ADD (collected, bytes);
  }
}

/*------------------------------------------------------------------------*/

#ifndef NSUBSUMPTION

// Assume 'size' literals have been marked.  Then try to find a clause
// different from 'skip' in which the literal 'lit' occurs and has all the
// marked literals.  This clause is then subsumed and marked garbage.  We also
// perform strengthening through self-subsuming resolution, which removes
// individual literals from clauses which are almost subsumed except for one
// literal which occurs negated.

// The clause literal 'traversed' denotes a literal whose watches are
// currently traversed (the 'lit' in 'backward_subsume_literal').  If we
// modify its watches we have to abort that traversals since iterators
// (pointers into the stack) become invalid.

static bool
backward_subsume_marked (struct satch *solver,
			 unsigned size, unsigned lit,
			 struct clause *skip, unsigned traversed)
{
#ifdef NSTRENGTHENING
  (void) traversed;
#endif
  assert (solver->flags[INDEX (lit)].active);

  struct watches *const watches = solver->watches + lit;
  const signed char *const values = solver->values;
  const signed char *const marks = solver->marks;

  bool touched = false;		// Traversed literal watches touched.

  assert (!solver->level);

  uint64_t ticks = 1 + CACHE_LINES_OF_STACK (watches);

  ADD (subsumption_ticks, ticks);

  const union watch *const end_of_watches = watches->end, *p;
  union watch *q = watches->begin;

  for (p = q; p != end_of_watches; p++)
    {
      const union watch watch = *q++ = *p;
#ifdef NVIRTUAL
      if (solver->inconsistent)
	continue;
#endif
      struct clause *c = watch.clause;
      if (c == skip)
	continue;

#ifndef NVIRTUAL
      if (is_tagged_clause (c))
	{
	  // We use 'remove_duplicated_virtual_binary_clauses' instead.
	  continue;
	}
      else
#endif
	{
	  ticks++;
	  if (c->garbage)
	    continue;
	}

      if (c->size < size)
	continue;

      bool satisfied = false;	// Clause actually satisfied.
      unsigned clashed = 0;	// How many clashing literals.
      unsigned found = 0;	// How many literals found.
#ifndef NSTRENGTHENING
      unsigned clashing = INVALID;	// The last clashing literal.
#endif
      for (all_literals_in_clause (other, c))
	{
	  const signed char value = values[other];
	  if (value > 0)
	    {
	      satisfied = true;
	      break;
	    }
	  if (value < 0)
	    continue;
	  const signed char mark = marked_literal (marks, other);
	  if (!mark)
	    continue;
	  if (mark < 0)
	    {
#ifndef NSTRENGTHENING
	      if (clashed++)
		break;
	      clashing = other;
#else
	      clashed = 1;
	      break;
#endif
	    }
	  else
	    assert (mark > 0);
	  found++;
	}

#ifndef NSTRENGTHENING
      if (clashed > 1)
	continue;
#else
      if (clashed)
	continue;
#endif
      if (satisfied)
	{
	  mark_garbage (solver, c, "root-level satisfied");
	  continue;
	}

      if (found < size)
	continue;

      assert (found == size);

#ifndef NSTRENGTHENING		// Begin of strengthening code.

      if (clashed)
	{
#ifndef NSUBSUMPTIONLIMITS
	  {
	    const size_t occs = SIZE_STACK (solver->watches[clashing]);
	    if (occs >= strengthening_occurrence_limit)
	      continue;
	  }
#endif
	  assert (clashed == 1);
	  assert (clashing != INVALID);
	  LOGCLS (c, "single clashing literal %s", LOGLIT (clashing));

	  // The negation of this assertion as a coverage hole was never
	  // triggered, It could be accommodated by setting 'touched = true'
	  // in this case, but as it never happens we added this assertion.

	  assert (clashing != traversed);

#ifdef NVIRTUAL
	  unsigned unit = INVALID;
	  if (c->size == 2)
	    {
	      for (all_literals_in_clause (other, c))
		if (other != clashing)
		  assert (unit == INVALID), unit = other;
	      assert (unit != INVALID);

	      const signed char value = solver->values[unit];
	      assert (value <= 0);
	      if (value < 0)
		{
		  trace_and_check_empty_addition (solver);
		  LOG ("inconsistent unit %s resolved", LOGLIT (unit));
		  solver->inconsistent = true;
		  touched = true;
		  continue;
		}
	    }
#endif
	  trace_and_check_clause_addition (solver, c, clashing);
	  trace_and_check_clause_deletion (solver, c);

	  mark_eliminate_literal (solver, clashing);
#ifdef NVIRTUAL
	  if (c->size == 2)
	    {
	      LOG ("resolved unit %s", LOGLIT (unit));
	      assert (unit != INVALID);
	      assert (!solver->values[unit]);
	      assign (solver, unit, 0);
	    }
	  else
#endif
	    {
	      assert (c->size > 2);
	      if (lit == clashing)
		{
		  LOGCLS (c, "disconnecting %s from", LOGLIT (lit));
		  q--;
		}
	      else
		{
		  ticks++;
		  disconnect_literal (solver, clashing, c);
		}

	      for (all_literals_in_clause (other, c))
		if (other != clashing)
		  mark_subsume_literal (solver, other);
	    }

#ifndef NVIRTUAL

	  // Ternary clauses become virtual binary clauses.

	  if (c->size == 3)
	    {
	      c->garbage = true;
	      unsigned first = INVALID, second = INVALID;

	      for (all_literals_in_clause (other, c))
		if (other != clashing)
		  {
		    if (first == INVALID)
		      first = other;
		    else
		      {
			assert (second == INVALID);
			second = other;
		      }
		    disconnect_literal (solver, other, c);
		  }
	      assert (first != INVALID);
	      assert (second != INVALID);
	      connect_literal (solver, first, tag_binary_clause (0, second));
	      connect_literal (solver, second, tag_binary_clause (0, first));
	      touched = (first == traversed || second == traversed);
	      ticks += 2;
	    }
	  else
#else
	  if (c->size > 2)
#endif
	    {
	      // Keep clause as is but remove a literal and reduce size.

	      unsigned *r = c->literals;
	      const unsigned *end_of_literals = r + c->size;
	      while (assert (r != end_of_literals), *r != clashing)
		r++;
	      while (++r != end_of_literals)
		r[-1] = *r;

	      c->size--;
#ifndef NGLUE
	      assert (!c->glue);
#endif
#ifndef NCACHE
	      c->search = 0;
#endif
	      LOGCLS (c, "strengthened");
	      INC (strengthened);
	    }
	}
      else
#endif // if '#ifndef NSTRENGTHENING' so end of strengthening code.

	{
	  mark_garbage (solver, c, "subsumed");
	  INC (subsumed);
	}
    }
  watches->end = q;
  if (EMPTY_STACK (*watches))
    RELEASE_STACK (*watches);

  ADD (subsumption_ticks, ticks);

#ifdef LOGGING
  if (touched)
    LOG ("watches of traversed literal %s touched", LOGLIT (traversed));
#endif

  return touched;
}

// Use the given clause to subsume other connected clauses.

// We only traverse the occurrence list of a single literal in the clause
// with the smallest number of occurrences to find subsumed clauses and also
// bound the maximum size of that list as well as the size of clauses.

// Furthermore only clauses with all literals (actually variables) marked as
// subsume candidate will be considered, since newly added clauses will mark
// their variables as subsume candidates.

// If the watch list of the 'traversed' literals is modified we return 'true'
// in order for the calling function ('backward_subsume_literal') to restart
// the watch list traversal (because its iterators became invalid).

static bool
backward_subsume_with_clause (struct satch *solver,
			      struct clause *c, unsigned traversed)
{
#ifndef NVIRTUAL
  if (!is_temporary_binary (solver, c))
#endif
    {
      assert (!c->subsumed);
      c->subsumed = true;
    }

  assert (!solver->level);
  LOGCLS (c, "backward subsumption with");
  assert (!c->redundant);

  bool satisfied = false;	// Clause 'c' satisfied.
  bool touched = false;		// Literal 'traverse' watches touched.
  bool subsume = true;		// All literals in 'c' marked 'subsume'.

  uint64_t min_pos_occs = UINT64_MAX;
  uint64_t min_neg_occs = UINT64_MAX;
  unsigned min_pos_lit = INVALID;
  unsigned min_neg_lit = INVALID;

  unsigned actual_size = 0;

  const struct watches *const watches = solver->watches;
  const struct flags *const flags = solver->flags;
  const signed char *values = solver->values;
  signed char *marks = solver->marks;

  uint64_t ticks = 2;		// Clause plus watch list.

  for (all_literals_in_clause (lit, c))
    {
      signed char value = values[lit];

      if (value > 0)
	{
	  LOG ("contains satisfied literal %s", LOGLIT (lit));
	  satisfied = true;
	  break;
	}

      if (value < 0)
	continue;

      const unsigned idx = INDEX (lit);
      if (!flags[idx].subsume)
	{
	  LOG ("contains non-subsumption candidate %s", LOGVAR (idx));
	  subsume = false;
	  break;
	}

      // Otherwise mark the literal for the subsumption check.

      mark_literal (marks, lit);
      actual_size++;

      ticks++;

      const size_t pos_occs = SIZE_STACK (watches[lit]);
      if (pos_occs < min_pos_occs)
	min_pos_occs = pos_occs, min_pos_lit = lit;

      const unsigned not_lit = NOT (lit);

      const size_t neg_occs = SIZE_STACK (watches[not_lit]);
      if (neg_occs < min_neg_occs)
	min_neg_occs = neg_occs, min_neg_lit = not_lit;
    }

  ADD (subsumption_ticks, ticks);

  if (satisfied)
    {
#ifndef NVIRTUAL
      if (!is_temporary_binary (solver, c))
#endif
	mark_garbage (solver, c, "root-level satisfied");
    }
  else if (subsume)
    {
      LOG ("actual size %u %s clause size %u", actual_size,
	   actual_size < c->size ? "smaller" : "matches", c->size);

#ifndef NSUBSUMPTIONLIMITS
      if (min_pos_occs <= subsumption_occurrence_limit)
#endif
	{
	  COVER (min_pos_lit == INVALID);
	  assert (min_pos_lit != INVALID);

	  LOG ("minimum positive occurrences %" PRIu64 " literal %s",
	       min_pos_occs, LOGLIT (min_pos_lit));

	  if (backward_subsume_marked (solver, actual_size,
				       min_pos_lit, c, traversed))
	    touched = true;
	}
#ifdef NVIRTUAL
      if (!solver->inconsistent && !solver->values[min_neg_lit])
#endif
#ifndef NSUBSUMPTIONLIMITS
	if (min_neg_occs <= subsumption_occurrence_limit)
#endif
	  {
	    COVER (min_neg_lit == INVALID);
	    assert (min_neg_lit != INVALID);

	    LOG ("minimum negative occurrences %" PRIu64 " literal %s",
		 min_neg_occs, LOGLIT (min_neg_lit));

	    if (backward_subsume_marked (solver, actual_size,
					 min_neg_lit, c, traversed))
	      touched = true;
	  }
    }

  for (all_literals_in_clause (lit, c))
    unmark_literal (marks, lit);

  return touched;
}

static void
backward_subsume_literal (struct satch *solver, unsigned lit)
{
#ifdef NVIRTUAL
  if (solver->inconsistent || solver->values[lit])
    return;
#endif

  INC (subsumption_ticks);

  const struct watches *const watches = solver->watches + lit;
#ifndef NSUBSUMPTIONLIMITS
  if (SIZE_STACK (*watches) > subsumption_occurrence_limit)
    return;
#endif

  LOG ("backward subsumption with clauses containing literal %s",
       LOGLIT (lit));

  uint64_t ticks = CACHE_LINES_OF_STACK (watches);

RESTART:			// If 'watches' touched (added or removed watches).

  for (all_elements_on_stack (union watch, watch, *watches))
    {
      struct clause *c = watch.clause;
#ifndef NVIRTUAL
      if (is_tagged_clause (c))
	c = untag_clause (solver, 0, lit, c);	// 1st temporary
      else
#endif
	{
	  ticks++;
	  if (c->garbage || c->subsumed)
	    continue;
	}
#ifndef NSUBSUMPTIONLIMITS
      if (c->size <= subsumption_clause_size_limit)
#endif
	if (backward_subsume_with_clause (solver, c, lit))
	  {
#ifdef NVIRTUAL
	    if (solver->inconsistent || solver->values[lit])
	      break;
#endif
	    LOG ("need to restart traversing %s watches", LOGLIT (lit));
	    goto RESTART;
	  }
    }

  ADD (subsumption_ticks, ticks);
}

#ifndef NVIRTUAL

// In 'backward_subsume_marked' we skip over tagged clauses because if such a
// tagged clause is subsumed the watch has to be removed immediately instead
// of marking it 'garbage'.  This is pretty awkward in that context and thus
// we implement a dedicated routine below to just do that.  It actually does
// all virtual binary clause (self-) subsumption of that literal in one go
// and thus we also do not enforce an occurrence limit.

static bool
remove_duplicated_virtual_binary_clauses (struct satch *solver, unsigned lit)
{
  LOG ("removing duplicated virtual binary clauses with %s", LOGLIT (lit));
  assert (solver->flags[INDEX (lit)].active);
  assert (!solver->level);

  struct watches *const watches = solver->watches + lit;
  const union watch *const end = watches->end;
  union watch *q = watches->begin, *p = q;

  uint64_t ticks = 1 + cache_lines (watches->begin, watches->end);

  signed char *marks = solver->marks;
  bool assigned = false;

  while (!assigned && p != end)
    {
      const union watch watch = *p++;
      struct clause *c = watch.clause;
      if (is_tagged_clause (c))
	{
	  const unsigned other = tagged_clause_to_literal (c);
	  const signed char mark = marked_literal (marks, other);
	  if (mark > 0)
	    {
	      really_delete_binary (solver, false, lit, other);
	      struct clause *d = tag_binary_clause (false, lit);
	      disconnect_literal (solver, other, d);
	      INC (subsumed);
	      ticks++;
	      continue;
	    }
	  if (mark < 0)
	    {
	      LOG ("self-subsuming virtual binary unit %s", LOGLIT (lit));
	      trace_and_check_unit_addition (solver, lit);
	      INC (strengthened);
	      assign (solver, lit, 0);
	      assigned = true;
	    }
	  else
	    mark_literal (marks, other);
	}
      *q++ = watch;
    }

  for (const union watch * r = watches->begin; r != q; r++)
    if (is_tagged_clause (r->clause))
      unmark_literal (marks, tagged_clause_to_literal (r->clause));

  while (p != end)
    *q++ = *p++;

  watches->end = q;

  ADD (subsumption_ticks, ticks);

  return !assigned;
}

#endif

static void
backward_subsume_variable (struct satch *solver, unsigned idx)
{
  LOG ("backward subsumption with clauses containing %s", LOGVAR (idx));
  assert (solver->flags[idx].subsume);
  assert (solver->flags[idx].active);

  const unsigned lit = LITERAL (idx);
  const unsigned not_lit = NOT (lit);
#ifndef NVIRTUAL
  if (!remove_duplicated_virtual_binary_clauses (solver, lit))
    return;
  if (!remove_duplicated_virtual_binary_clauses (solver, not_lit))
    return;
#endif
  backward_subsume_literal (solver, lit);
  backward_subsume_literal (solver, not_lit);

  solver->flags[idx].subsume = 2;
}

#ifndef NSUBSUMPTIONLIMITS

static bool
subsumption_ticks_limit_hit (struct satch *solver)
{
  return solver->statistics.subsumption_ticks > solver->limits.subsume.ticks;
}

#endif

static void
full_backward_subsumption (struct satch *solver)
{
  if (!more_subsumption_candidates (solver))
    return;

  START (subsume);
  const uint64_t subsumptions = INC (subsumptions);

  LOG ("backward subsumption with clauses containing subsume candidates");

  struct flags *flags = solver->flags;

  uint64_t total_subsumed = 0, total_strengthened = 0;
  uint64_t strengthened;
  unsigned round = 0;

  do
    {
      round++;

      const uint64_t subsumed_before = solver->statistics.subsumed;
      const uint64_t strengthened_before = solver->statistics.strengthened;
      const unsigned remaining = solver->statistics.remaining;
      unsigned scheduled = 0, tried = 0;

      for (all_variables (idx))
	{
	  struct flags *f = flags + idx;
	  if (f->active && (f->subsume &= 1))
	    scheduled++;
	}

      for (all_variables (idx))
	{
	  struct flags *f = flags + idx;
	  if (f->active && f->subsume)
	    {
	      backward_subsume_variable (solver, idx);
	      tried++;
#ifndef NSUBSUMPTIONLIMITS
	      if (subsumption_ticks_limit_hit (solver))
		{
		  message (solver, 4, "subsumption", subsumptions,
			   "subsumption ticks limit hit");
		  break;
		}
#endif
	    }
	}

      message (solver, 3, "subsumption", subsumptions,
	       "tried %u variables %.0f%% of %u scheduled %.0f%%"
	       " in round %u", tried, percent (tried, scheduled),
	       scheduled, percent (scheduled, remaining), round);

      uint64_t subsumed = solver->statistics.subsumed - subsumed_before;
      strengthened = solver->statistics.strengthened - strengthened_before;

      total_subsumed += subsumed;
      total_strengthened += strengthened;

      message (solver, 3, "subsumption", subsumptions,
	       "subsumed %" PRIu64 " and strengthened %" PRIu64
	       " clauses in round %u", subsumed, strengthened, round);

      report (solver, 1 + !(subsumed + strengthened), 's');
#ifndef NSUBSUMPTIONLIMITS
      if (round >= subsumption_rounds)
	break;
      if (subsumption_ticks_limit_hit (solver))
	break;
#endif
    }
  while (!solver->inconsistent && strengthened);

  for (all_irredundant_clauses (c))
    c->subsumed = false;

  unsigned kept = 0;
  for (all_variables (idx))
    {
      struct flags *f = flags + idx;
      if (f->active & (f->subsume & 1))
	kept++;
    }

  message (solver, 3, "subsumption", subsumptions,
	   "keeping %u variables scheduled %.0f%%",
	   kept, percent (kept, solver->statistics.remaining));

  if (!kept)
    solver->limits.subsume.marked = solver->statistics.marked_subsume;

  message (solver, 2, "subsumption", subsumptions,
	   "subsumed %" PRIu64 " and strengthened %" PRIu64
	   " clauses in %u rounds",
	   total_subsumed, total_strengthened, round);

  STOP (subsume);
}

#endif

/*------------------------------------------------------------------------*/

// Flush out garbage (satisfied and eliminated) clause occurrences.  Returns
// the remaining number of occurrences or 'elimination_occurrence_limit + 1'
// if a clause exceeds the elimination clause size limit or there are too
// many, i.e., more than 'elimination_occurrence_limit' remaining.

static unsigned
actual_number_of_occurrences (struct satch *solver, unsigned lit)
{
#ifndef NELIMINATIONLIMITS
  assert (elimination_occurrence_limit < UINT_MAX);
#endif
  assert (!solver->flags[INDEX (lit)].fixed);

  struct watches *watches = solver->watches + lit;
#ifndef NVIRTUAL
  signed char *values = solver->values;
#endif

  union watch *begin = watches->begin, *q = begin;
  const union watch *end = watches->end, *p = q;

  uint64_t ticks = 1;		// To access 'watches'.
  unsigned res = 0;

  while (p != end)
    {
      const union watch watch = *p++;

      struct clause *c = watch.clause;
#ifndef NVIRTUAL
      if (is_tagged_clause (c))
	{
	  const unsigned other = tagged_clause_to_literal (c);
	  if (values[other] > 0)
	    {
	      really_delete_binary (solver, false, lit, other);
	      struct clause *d = tag_binary_clause (false, lit);
	      disconnect_literal (solver, other, d);
	      ticks++;
	      continue;
	    }
	}
      else
#endif
	{
	  ticks++;
	  if (mark_garbage_if_satisfied (solver, c))
	    continue;
	}

      *q++ = watch;
      res++;

#ifndef NELIMINATIONLIMITS
      if (res > elimination_occurrence_limit)
	break;
#ifndef NVIRTUAL
      if (!is_tagged_clause (c))
#endif
	if (c->size > elimination_clause_size_limit)
	  {
	    res = elimination_occurrence_limit + 1;
	    break;
	  }
#endif
    }

  ticks += cache_lines (begin, q);
  ADD (elimination_ticks, ticks);

  while (p != end)
    *q++ = *p++;

  watches->end = q;
  if (EMPTY_STACK (*watches))
    RELEASE_STACK (*watches);

  return res;
}

// Check if the given variable matches is still active, its clauses stay
// below the clause size limit and it does not occur too often.

static bool
can_be_eliminated (struct satch *solver, unsigned pivot_idx)
{
  const struct flags *const f = solver->flags + pivot_idx;
  if (!f->active)
    return false;
  if (!f->eliminate)
    return false;

  const unsigned lit = LITERAL (pivot_idx);
  const unsigned not_lit = NOT (lit);

#ifndef NELIMINATIONLIMITS

  const uint64_t pos = actual_number_of_occurrences (solver, lit);
  const uint64_t neg = actual_number_of_occurrences (solver, not_lit);

  if (pos && neg > elimination_occurrence_limit)
    return false;

  if (neg && pos > elimination_occurrence_limit)
    return false;

#else

  (void) actual_number_of_occurrences (solver, lit);
  (void) actual_number_of_occurrences (solver, not_lit);

#endif

  return true;
}

// Check whether the given variable produces few resolvents and add them to
// the resolvents stack.  The limit is the number of original clauses.

// Process unit and empty clauses eagerly though which also requires that we
// need to check antecedent clauses (again) and later also the saved
// resolvents for being satisfied (or falsified).

static bool
produces_few_resolvents (struct satch *solver, unsigned pivot_idx)
{
  assert (!solver->inconsistent);

  const unsigned pivot = LITERAL (pivot_idx);
  const unsigned not_pivot = NOT (pivot);

  struct watches *const pos_watches = solver->watches + pivot;
  struct watches *const neg_watches = solver->watches + not_pivot;

  assert (EMPTY_STACK (solver->resolvents));

  LOG ("trying to eliminate %s", LOGVAR (pivot_idx));

  const size_t pos_count = SIZE_STACK (*pos_watches);
  const size_t neg_count = SIZE_STACK (*neg_watches);

  const uint64_t limit = pos_count + neg_count;
  uint64_t resolvents = 0;

  uint64_t ticks = 2;
  ticks += CACHE_LINES_OF_STACK (pos_watches);
  ticks += CACHE_LINES_OF_STACK (neg_watches);

  signed char *marks = solver->marks;

  assert (!solver->level);
  assert (!solver->values[pivot]);

  // Go over all clauses 'c' in which the variable occurs positively (outer
  // loop) and all clauses 'd' in which it occurs negative (inner loop) and
  // resolve 'c' with 'd' on the given variable.  Make sure to skip
  // satisfied clauses and tautological resolvents.  Save the resolvents on
  // the resolvents stack but eagerly add units (and the empty clause).

  for (all_elements_on_stack (union watch, pos_watch, *pos_watches))
    {
      struct clause *c = pos_watch.clause;
#ifndef NVIRTUAL
      if (is_tagged_clause (c))
	c = untag_clause (solver, 0, pivot, c);
      else
#endif
	{
	  ticks++;
	  if (c->garbage)
	    continue;
	}

      // Mark literals in 'c' to detect if a literal in 'c' occurs negated
      // in a 'd' clause which would produce a tautological resolvent.

      for (all_literals_in_clause (lit, c))
	mark_literal (marks, lit);

      for (all_elements_on_stack (union watch, neg_watch, *neg_watches))
	{
	  struct clause *d = neg_watch.clause;
#ifndef NVIRTUAL
	  if (is_tagged_clause (d))
	    d = untag_clause (solver, 1, not_pivot, d);
	  else
#endif
	    {
	      ticks++;
	      if (d->garbage)
		continue;
	    }

	  LOGCLS (c, "1st antecedent");
	  LOGCLS (d, "2nd antecedent");

	  INC (resolutions);

	  bool tautological = false;
	  for (all_literals_in_clause (lit, d))
	    if (lit != not_pivot && marked_literal (marks, lit) < 0)
	      {
		LOG ("tautological resolvent with clashing %s and %s",
		     LOGLIT (NOT (lit)), LOGLIT (lit));
		tautological = true;
		break;
	      }

	  if (tautological)
	    continue;

	  LOG ("resolvent non-tautological");

	  if (++resolvents > limit)
	    break;

	  // Copy literals of 'c' and 'd' to the resolvent stack skipping
	  // over the pivot and duplicated literals.

	  for (all_literals_in_clause (lit, c))
	    if (lit != pivot)
	      PUSH (solver->resolvents, lit);

	  for (all_literals_in_clause (lit, d))
	    if (!marks[INDEX (lit)])
	      PUSH (solver->resolvents, lit);

	  PUSH (solver->resolvents, INVALID);
	}

      for (all_literals_in_clause (lit, c))
	unmark_literal (marks, lit);

      if (resolvents > limit)
	break;

      if (solver->inconsistent)
	break;
    }

  ADD (elimination_ticks, ticks);

  if (solver->inconsistent)
    return false;

  if (resolvents > limit)
    {
      CLEAR_STACK (solver->resolvents);
      LOG ("many resolvents %" PRIu64 " > limit %" PRIu64, resolvents, limit);
      return false;
    }

  LOG ("few resolvents %" PRIu64 " <= limit %" PRIu64, resolvents, limit);
  return true;
}

// Add and connect the temporary resolvent clause.

static void
add_and_connect_resolvent (struct satch *solver)
{
  const size_t size = SIZE_STACK (solver->clause);
  assert (size <= UINT_MAX);

  if (!size)
    {
      LOG ("empty resolvent");
      solver->inconsistent = true;
    }
  else if (size == 1)
    {
      const unsigned unit = ACCESS (solver->clause, 0);
      LOG ("unit resolvent %s", LOGLIT (unit));
      assign (solver, unit, 0);
    }
#ifndef NVIRTUAL
  else if (size == 2)
    {
      const unsigned lit = ACCESS (solver->clause, 0);
      const unsigned other = ACCESS (solver->clause, 1);
      LOGBIN (false, lit, other, "resolvent");
      connect_literal (solver, lit, tag_binary_clause (false, other));
      connect_literal (solver, other, tag_binary_clause (false, lit));
      INC (irredundant);
    }
#endif
  else
    {
      struct clause *resolvent = new_irredundant_clause (solver);
      LOGCLS (resolvent, "resolvent");
      connect_clause (solver, resolvent);
    }

#ifndef NSUBSUMPTION

  // Mark variables in resolvent as subsumption candidates.

  for (all_elements_on_stack (unsigned, lit, solver->clause))
      mark_subsume_literal (solver, lit);

#endif
}

// Push the clause on the extension stack with 'eliminated' literal first.
// See 'extend_solution' for more explanations on why we need this.

static void
push_clause_on_extension_stack (struct satch *solver,
				unsigned eliminated, struct clause *c)
{
#ifndef NVIRTUAL
  if (is_tagged_clause (c))
    c = untag_clause (solver, 0, eliminated, c);
#endif
  PUSH (solver->extend, INVALID);	// Clause separator.
  PUSH (solver->extend, eliminated);
  for (all_literals_in_clause (lit, c))
    if (lit != eliminated)
      PUSH (solver->extend, lit);
}

static void
push_unit_on_extension_stack (struct satch *solver, unsigned eliminated)
{
  PUSH (solver->extend, INVALID);	// Clause separator.
  PUSH (solver->extend, eliminated);
}

static void
push_clauses_on_extension_stack (struct satch *solver,
				 unsigned eliminated, struct watches *watches)
{
  for (all_elements_on_stack (union watch, watch, *watches))
      push_clause_on_extension_stack (solver, eliminated, watch.clause);
}

// Eliminate clause and push it on extension stack with 'eliminated' first.

static void
eliminate_watched_clause (struct satch *solver,
			  unsigned eliminated, struct clause *c)
{
#ifndef NVIRTUAL
  if (is_tagged_clause (c))
    {
      const unsigned other = tagged_clause_to_literal (c);
      really_delete_binary (solver, false, eliminated, other);
      struct clause *d = tag_binary_clause (false, eliminated);
      disconnect_literal (solver, other, d);
      INC (elimination_ticks);
      c = untag_clause (solver, 0, eliminated, c);
    }
  else
#endif
  if (c->garbage)
    return;
#ifndef NVIRTUAL
  else
#endif
    mark_garbage (solver, c, "eliminated");

#ifdef NVIRTUAL
  (void) eliminated;
#endif
}

// Eliminate clauses with literal 'eliminated' by flushing their occurrence
// lists, marking them as garbage, and pushing them on the extension stack.

static void
eliminate_watched_clauses (struct satch *solver,
			   unsigned eliminated, struct watches *watches)
{
  for (all_elements_on_stack (union watch, watch, *watches))
      eliminate_watched_clause (solver, eliminated, watch.clause);
  RELEASE_STACK (*watches);
}

// Now eliminate the variable by adding all the saved resolvents from the
// resolvents stack and then eliminate the clauses in which it occurs.

// Since we might have generated units in the mean time we have to check for
// satisfied and falsified clauses again (the second time).

static void
eliminate_variable (struct satch *solver, unsigned pivot_idx)
{
  assert (!solver->inconsistent);
  assert (EMPTY_STACK (solver->clause));

  const unsigned pivot = LITERAL (pivot_idx);
  const unsigned not_pivot = NOT (pivot);

  LOG ("eliminating %s", LOGVAR (pivot_idx));

  // First mark the variable as eliminated and update counters.

  {
    struct flags *f = solver->flags + pivot_idx;
    assert (f->active);
    assert (!f->eliminated);
    f->eliminated = true;
    f->active = false;
    DEC (remaining);
    INC (eliminated);
  }

  // Now copy and add the clauses from the resolvents stack.

  uint64_t ticks = 0;

  {
    const signed char *const values = solver->values;
    bool satisfied = false;

    for (all_elements_on_stack (unsigned, lit, solver->resolvents))
      {
	if (lit != INVALID)
	  {
	    signed char value = values[lit];
	    if (value > 0)
	      satisfied = true;
	    else if (!satisfied && !value)
	      PUSH (solver->clause, lit);
	  }
	else if (satisfied)
	  {
	    CLEAR_STACK (solver->clause);
	    satisfied = false;
	  }
	else
	  {
	    LOGTMP ("previously resolved");
	    trace_and_check_temporary_addition (solver);
	    add_and_connect_resolvent (solver);
	    ticks += SIZE_STACK (solver->clause);
	    CLEAR_STACK (solver->clause);
	    ticks++;
	    if (solver->inconsistent)
	      break;
	  }
      }
  }

  if (solver->inconsistent)
    return;

  CLEAR_STACK (solver->resolvents);

  {
    struct watches *const pos_watches = solver->watches + pivot;
    struct watches *const neg_watches = solver->watches + not_pivot;

    const size_t pos_lines = 1 + CACHE_LINES_OF_STACK (pos_watches);
    const size_t neg_lines = 1 + CACHE_LINES_OF_STACK (neg_watches);

    // Push eliminated clauses on the extension stack.

#if 1
    // For non-incremental SAT solving we can push only one set of the two
    // clauses to the stack and simulate the other by pushing a unit.

    if (SIZE_STACK (*pos_watches) < SIZE_STACK (*neg_watches))
      {
	ticks += 1 + pos_lines;
	push_clauses_on_extension_stack (solver, pivot, pos_watches);
	push_unit_on_extension_stack (solver, not_pivot);
      }
    else
      {
	ticks += 1 + neg_lines;
	push_clauses_on_extension_stack (solver, not_pivot, neg_watches);
	push_unit_on_extension_stack (solver, pivot);
      }
#else
    // For incremental SAT solving we would need to save all clauses.

    push_clauses_on_extension_stack (solver, pivot, pos_watches);
    push_clauses_on_extension_stack (solver, not_pivot, neg_watches);
#endif

    // Finally remove all the clauses with the eliminated variables and
    // release their watcher stacks.

    ticks += 2 + pos_lines + neg_lines;

    eliminate_watched_clauses (solver, pivot, pos_watches);
    eliminate_watched_clauses (solver, not_pivot, neg_watches);
  }

  ADD (elimination_ticks, ticks);
}

/*------------------------------------------------------------------------*/

#ifndef NELIMINATIONLIMITS

// Variable elimination and particularly subsumption have to be bounded for
// large instances.  Otherwise almost all time is spent in these procedures.
// We bound the time spent by 'ticks' (predicted cache line accesses) as for
// propagation during search and allow a fixed fraction (10%) in terms of
// search ticks since the last variable elimination. We have separate limits
// for subsumption and elimination to allow each a fair share of the time.
// The limits are set at the start of variable elimination (for both).

static void
set_elimination_ticks_limit (struct satch *solver)
{
  struct limits *const limits = &solver->limits;
  const struct statistics *const statistics = &solver->statistics;
  const uint64_t eliminations = statistics->eliminations;
#ifndef NINPROCESSING
  const uint64_t delta = statistics->ticks - limits->eliminate.search;
  uint64_t limit = delta * elimination_ticks_fraction;
  message (solver, 2, "elimination", eliminations,
	   "elimination limit of %" PRIu64 " ticks = %g * search ticks %"
	   PRIu64, limit, (double) elimination_ticks_fraction, delta);
  limits->eliminate.ticks = statistics->elimination_ticks + limit;
#else
  limits->eliminate.ticks = UINT64_MAX;
  message (solver, 2, "elimination", eliminations,
	   "no elimination ticks-limit during preprocessing "
	   "(inprocessing disabled)");
#endif
}

static bool
elimination_ticks_limit_hit (struct satch *solver)
{
  return solver->statistics.elimination_ticks >
    solver->limits.eliminate.ticks;
}

#endif

#ifndef NSUBSUMPTIONLIMITS

static void
set_subsumption_ticks_limit (struct satch *solver)
{
  struct limits *const limits = &solver->limits;
  const struct statistics *const statistics = &solver->statistics;
  const uint64_t eliminations = statistics->eliminations;
#ifndef NINPROCESSING
  const uint64_t delta = statistics->ticks - limits->subsume.search;
  uint64_t limit = delta * subsumption_ticks_fraction;
  message (solver, 2, "elimination", eliminations,
	   "subsumption limit of %" PRIu64 " ticks = %g * search ticks %"
	   PRIu64, limit, (double) subsumption_ticks_fraction, delta);
  limits->subsume.ticks = statistics->subsumption_ticks + limit;
#else
  limits->subsume.ticks = UINT64_MAX;
  message (solver, 2, "elimination", eliminations,
	   "no subsumption ticks-limit during preprocessing "
	   "(inprocessing disabled)");
#endif
}

#endif

/*------------------------------------------------------------------------*/

// The main bounded variable elimination function.

static int
eliminate_variables (struct satch *solver)
{
  START (eliminate);
  const uint64_t eliminations = INC (eliminations);

  // First backtrack to decision level zero.

  update_phases_and_backtrack_to_root_level (solver);

#ifndef NELIMINATIONLIMITS
  set_elimination_ticks_limit (solver);
#endif
#ifndef NSUBSUMPTIONLIMITS
  set_subsumption_ticks_limit (solver);
#endif

  // Switch to dense mode which flushes all watches to redundant clauses and
  // connects all occurrences of literals in irredundant clauses.

  switch_to_dense_mode (solver);

  // Main elimination loop.

  unsigned eliminated, total = 0, round = 0;
  const unsigned original = solver->statistics.remaining;

  do
    {
#ifndef NSUBSUMPTION
      full_backward_subsumption (solver);
      if (!more_elimination_candidates (solver))
	break;
#endif
      const unsigned remaining = solver->statistics.remaining;
      eliminated = 0;
      round++;

      for (all_variables (idx))
	{
	  if (can_be_eliminated (solver, idx) &&	// Check limits.
	      produces_few_resolvents (solver, idx))	// Save resolvents.
	    {
	      eliminate_variable (solver, idx);	// Add resolvents.
	      eliminated++;
	    }
	  else
	    solver->flags[idx].eliminate = false;

	  if (solver->inconsistent)
	    break;

#ifndef NELIMINATIONLIMITS
	  if (elimination_ticks_limit_hit (solver))
	    {
	      message (solver, 4, "elimination", eliminations,
		       "elimination ticks limit hit");
	      break;
	    }
#endif
	}

      total += eliminated;
      message (solver, 3, "elimination", eliminations,
	       "eliminated %u variables %.0f%% of remaining %u in round %u",
	       eliminated, percent (eliminated, remaining), remaining, round);

      report (solver, 1 + !eliminated, 'e');
#ifndef NELIMINATIONLIMITS
      if (round >= elimination_rounds)
	break;
      if (elimination_ticks_limit_hit (solver))
	break;
#endif
    }
  while (!solver->inconsistent && eliminated);

  unsigned kept = 0;
  const struct flags *const flags = solver->flags;
  for (all_variables (idx))
    {
      const struct flags *const f = flags + idx;
      if (!f->active)
	continue;
      if (f->eliminate)
	kept++;
    }

  message (solver, 3, "elimination", eliminations,
	   "keeping %u variables scheduled %.0f%%",
	   kept, percent (kept, solver->statistics.remaining));

  message (solver, 2, "elimination", eliminations,
	   "eliminated %u variables %.0f%% in total in %u rounds",
	   total, percent (total, original), round);

  // Collect clauses which are marked garbage, i.e., are root-level
  // satisfied or contain an eliminated variable.

  mark_and_collect_garbage_clauses_after_elimination (solver);

  // Switch back to sparse mode watching all clauses.

  switch_to_sparse_mode (solver);

  // Need to propagate over redundant clauses too.

  solver->trail.propagate = solver->trail.begin;

#ifndef NINPROCESSING

  // Finally update limits.

  {
    const struct statistics *const statistics = &solver->statistics;
    struct limits *const limits = &solver->limits;

    if (!kept)
      {
	limits->eliminate.fixed = statistics->fixed;
	limits->eliminate.marked = statistics->marked_eliminate;
      }

#ifndef NELIMINATIONLIMITS
    limits->eliminate.search = statistics->ticks;
#endif
#ifndef NSUBSUMPTIONLIMITS
    limits->subsume.search = statistics->ticks;
#endif

    const uint64_t interval =
      scale_interval (elimination_interval, nlognlogn, eliminations);
    limits->eliminate.conflicts = CONFLICTS + interval;

    message (solver, 4, "elimination", eliminations,
	     "next limit at %" PRIu64 " after %" PRIu64 " conflicts",
	     limits->eliminate.conflicts, interval);
  }
#endif

  STOP (eliminate);

  return solver->inconsistent ? 20 : 0;
}

static void
extend_solution (struct satch *solver)
{
  const unsigned *const begin = solver->extend.begin;
  signed char *const values = solver->values;

  const unsigned *p = solver->extend.end;

  unsigned last = INVALID;
  bool satisfied = false;
  signed char value = -1;

  while (p != begin)
    {
      const unsigned lit = *--p;
      if (lit != INVALID)
	{
	  value = values[lit];
	  assert (value);
	  if (value > 0)
	    satisfied = true;
	}
      else if (!satisfied)
	{
	  assert (last != INVALID);
	  values[last] = 1;
	  values[NOT (last)] = -1;
	  LOG ("flipped value of %s", LOGLIT (last));
	}
      else
	satisfied = false;
      last = lit;
    }
}

/*------------------------------------------------------------------------*/
#endif // of '#ifndef NELIMINATION'
/*------------------------------------------------------------------------*/

#ifndef NLIMITS

static void
init_limits (struct satch *solver)
{
  // First initialize all limits.

#ifndef NELIMINATION
#ifndef NINPROCESSING
  solver->limits.eliminate.conflicts = elimination_interval;
#endif
#endif
#ifndef NREDUCE
  solver->limits.reduce.conflicts = reduce_interval;
#endif
#ifndef NREPHASE
  solver->limits.rephase = rephase_interval;
#endif
#ifndef NRESTART
  solver->limits.restart = restart_interval;
#endif
#ifndef NSWITCH
  solver->limits.mode.conflicts = initial_focused_mode_conflicts;
  solver->limits.mode.ticks.limit = initial_focused_mode_ticks;
#endif

  // Some sanity checking.

#ifdef NSTABLE
  assert (!solver->stable);
#endif
#ifdef NFOCUSED
  assert (solver->stable);
#endif

  (void) solver;
}

#endif

/*------------------------------------------------------------------------*/

// This is the main CDCL solving loop.

static int
solve (struct satch *solver, int delta_limit)
{
  START (solve);
  report (solver, 1, '*');

  int res = solver->inconsistent ? 20 : 0;
  struct clause *conflict;

  uint64_t conflict_limit =
    delta_limit < 0 ? UINT64_MAX : CONFLICTS + delta_limit;

#ifndef NSWITCH
  start_mode (solver);
#endif
  while (!res)
    if ((conflict = boolean_constraint_propagation (solver)))
      {
	if (!analyze_conflict (solver, conflict))
	  res = 20;
      }
    else
      {
	if (solver->iterate)
	  iterate (solver);

	if (!solver->unassigned)
	  res = 10;
	else
	  {
	    if (CONFLICTS >= conflict_limit)
	      break;
	    else
#ifndef NRESTART
	    if (restarting (solver))
	      restart (solver);
	    else
#endif
#ifndef NSWITCH
	    if (switching (solver))
	      switch_mode (solver);
	    else
#endif
#ifndef NREDUCE
	    if (reducing (solver))
	      reduce (solver);
	    else
#endif
#ifndef NREPHASE
	    if (rephasing (solver))
	      rephase (solver);
	    else
#endif
#ifndef NELIMINATION
	    if (eliminating (solver))
	      res = eliminate_variables (solver);
	    else
#endif
	      decide (solver);
	  }
      }
#ifndef NSWITCH
  stop_mode (solver);
#endif

  report (solver, 1, !res ? '?' : res == 10 ? '1' : '0');
  STOP (solve);

  return res;
}

/*------------------------------------------------------------------------*/

#ifndef NDEBUG

// This witness checker goes over the saved original clauses and checks that
// each of them is satisfied.  If not a fatal error message is triggered
// after printing an original clause which was found to be unsatisfied.

static void
check_witness (struct satch *solver)
{
  const int *const begin_original = solver->original.begin;
  const int *const end_original = solver->original.end;
  size_t clauses = 0;
  for (const int *p = begin_original, *c = p; c != end_original; c = p)
    {
      clauses++;
      bool satisfied = false;
      int lit;
      while (assert (p != end_original), (lit = *p++))
	if (satch_val (solver, lit) == lit)
	  satisfied = true;
      if (satisfied)
	continue;
      COLORS (2);
      fflush (stdout);
      fprintf (stderr,
	       "%slibsatch: %sfatal error: %sclause[%zd] unsatisfied:\n",
	       BOLD, RED, NORMAL, clauses);
      for (const int *q = c; (lit = *q); q++)
	fprintf (stderr, "%d ", *q);
      fputs ("0\n", stderr);
      fflush (stderr);
      abort ();
    }
  LOG ("checked witness successfully");
}

#endif

/*------------------------------------------------------------------------*/

// The API functions below have several requirements (contracts) and those
// need to be enforced even in optimized code, particularly in order to help
// library users to detect, test and debug invalid API usage.

static void
invalid_usage (const char *message, const char *function)
{
  COLORS (2);
  fprintf (stderr,
	   "%slibsatch: %sfatal error: %sinvalid API usage in '%s': %s\n",
	   BOLD, RED, NORMAL, function, message);
  fflush (stderr);
  abort ();
}

// Macros to enforce valid API usage.

#define REQUIRE(CONDITION,MESSAGE) \
do { \
  if (!(CONDITION)) \
    invalid_usage (MESSAGE, __func__); \
} while (0)

#define REQUIRE_NON_ZERO_SOLVER() \
  REQUIRE (solver, "zero solver argument")

#define REQUIRE_VALID_LITERAL(ELIT) \
do { \
  REQUIRE ((ELIT) != INT_MIN, "'INT_MIN' literal argument"); \
  REQUIRE (sizeof (void*) > 4 || abs (ELIT) <= (1<<29), \
           "maximum of '2^29' variables exceeded on 32-bit system"); \
} while (0)

#define REQUIRE_NON_ZERO_VALID_LITERAL(ELIT) \
do { \
  REQUIRE ((ELIT), "zero literal argument"); \
  REQUIRE ((ELIT) != INT_MIN, "'INT_MIN' literal argument"); \
} while (0)

#define REQUIRE_NON_INCREMENTAL() \
  REQUIRE (!solver->statistics.solved, \
           "incremental usage not implemented yet")

/*------------------------------------------------------------------------*/

static struct satch *
internal_init (void)
{
  struct satch *solver = calloc (1, sizeof (struct satch));
  if (!solver)
    fatal_error ("could not allocate solver");
#ifdef NFOCUSED
  solver->stable = 1;
#endif
#ifndef NDEBUG
  solver->checker = checker_init ();
#endif
#ifndef NBLOCK
  init_binary (solver);
#endif

#ifndef NVSIDS
#ifndef NFOCUSED
  solver->scores[0].factor = focused_score_increment_factor;
#endif
#ifndef NSTABLE
  solver->scores[1].factor = stable_score_increment_factor;
#endif
#endif

  init_averages (solver);
#ifndef NLIMITS
  init_limits (solver);
#endif
  init_profiles (solver);
  return solver;
}

/*------------------------------------------------------------------------*/

static void
internal_release (struct satch *solver)
{
#ifdef NLEARN
  if (solver->level)
    backtrack (solver, 0);	// To delete reason clauses.
#endif

  solver->proof = 0;
  for (all_literals (lit))
    {
      struct watches *watches = solver->watches + lit;
#if !defined(NDEBUG) && !defined(NVIRTUAL)
      const union watch *const end = watches->end;
      for (const union watch * p = watches->begin; p != end; p++)
	if (p->header.binary)
	  delete_header (solver, lit, p->header);
	else
	  p++;
#endif
      RELEASE_STACK (*watches);
    }

  free (solver->watches);

  free (solver->levels);
  free (solver->values);
#ifndef NSAVE
  free (solver->saved);
#endif
#ifndef NTARGET
  free (solver->targets);
#endif
#ifndef NBEST
  free (solver->bests);
#endif
  free (solver->marks);
  free (solver->flags);
  free (solver->frames);
#ifndef NSHRINK
  free (solver->position);
#endif
  free (solver->reasons);
  free (solver->trail.begin);

#ifndef NQUEUE
#ifndef NQUEUE0
  release_queue (&solver->queue[0]);
#else
  assert (!solver->queue[0].links);
#endif
#ifndef NQUEUE1
  release_queue (&solver->queue[1]);
#else
  assert (!solver->queue[1].links);
#endif
#endif

#ifndef NHEAP
#ifndef NHEAP0
  release_heap (&solver->scores[0]);
#else
  assert (!solver->scores[0].begin);
#endif
#ifndef NHEAP1
  release_heap (&solver->scores[1]);
#else
  assert (!solver->scores[1].begin);
#endif
#endif

#ifndef NLAZYACTIVATION
#ifndef NFOCUSED
  RELEASE_STACK (solver->put[0]);
#else
  assert (EMPTY_STACK (solver->put[0]));
#endif
#ifndef NSTABLE
  RELEASE_STACK (solver->put[1]);
#else
  assert (EMPTY_STACK (solver->put[1]));
#endif
#endif

#ifndef NELIMINATION
  RELEASE_STACK (solver->extend);
  RELEASE_STACK (solver->resolvents);
#endif

#ifndef NMINIMIZE
  RELEASE_STACK (solver->poisoned);
  RELEASE_STACK (solver->removable);
#endif
#ifndef NSHRINK
  RELEASE_STACK (solver->shrunken);
#endif
  RELEASE_STACK (solver->analyzed);
  RELEASE_STACK (solver->clause);
  RELEASE_STACK (solver->blocks);
#ifndef NBINARIES
  RELEASE_STACK (solver->binaries);
#endif

  for (all_pointers_on_stack (struct clause, c, solver->irredundant))
      (void) delete_clause (solver, c);
  RELEASE_STACK (solver->irredundant);
#ifndef NLEARN
  for (all_pointers_on_stack (struct clause, c, solver->redundant))
      (void) delete_clause (solver, c);
  RELEASE_STACK (solver->redundant);
#endif
  assert (!solver->statistics.irredundant);
  assert (!solver->statistics.redundant);
#ifndef NBLOCK
  release_binary (solver);
#endif

  RELEASE_STACK (solver->added);
#ifndef NDEBUG
  RELEASE_STACK (solver->original);

#ifndef NLEARN
  checker_enable_leak_checking (solver->checker);
#endif
  checker_release (solver->checker);
#endif

  free (solver);
}

/*------------------------------------------------------------------------*/

static void
internal_add (struct satch *solver, int elit)
{
#ifndef NDEBUG
  PUSH (solver->original, elit);
#endif

  // If an empty clause has been added or derived we do not need to add
  // anything and just return for the rest of time this solver is used.

  if (solver->inconsistent)
    return;

  if (elit)
    {
      // Add the literal to the internal temporary 'clause' after importing
      // it, i.e., adjusting the 'size' (number of active variables) if its
      // variable has never been seen before.  Also turn the external signed
      // DIMACS 'int' literal into and internal 'unsigned' literal.

      const unsigned ilit = import_literal (solver, elit);
      PUSH (solver->clause, ilit);
      PUSH (solver->added, elit);
#ifndef NDEBUG
      checker_add_literal (solver->checker, elit);
#endif
    }
  else
    {
#ifndef NDEBUG
      checker_add_original_clause (solver->checker);
#endif
      bool remove_original_clause;

      // First check whether the imported clause is already (root-level)
      // satisfied or trivial (contains both a literal and its negation).
      // During this check falsified and duplicated literals are removed.

      if (!imported_clause_trivial_or_satisfied (solver))
	{
	  // Activate variables in the order they appear in the input CNF.
	  // This gives an implicit order of the variables in the decision
	  // queue as well as in the binary heap keeping variables in the
	  // same clauses close to each other which seems beneficial.

	  activate_literals (solver);

	  // We need special treatment for empty and unary clauses since all
	  // internally allocated clauses have at least two literals.

	  const size_t size = SIZE_STACK (solver->clause);

	  if (!size)
	    {
	      LOG ("empty thus inconsistent imported clause");
	      solver->inconsistent = true;
	    }
	  else if (size == 1)
	    {
	      // It is a common technique to represent unit clauses by just
	      // assigning its literal on the root-level.  This makes sure
	      // that all allocated clauses are at least binary, but for
	      // instance requires that 'analyze' treats root-level literals
	      // in a special way, 'reduce' and thus 'assign' ignore
	      // clauses forcing root-level assigned literals and finally
	      // (and maybe really the most severe consequence), makes proof
	      // tracing semantics rather complex (particularly regarding the
	      // situation of deleting unit clauses in RUP / DRAT proofs).

	      const unsigned unit = ACCESS (solver->clause, 0);
	      const signed char value = solver->values[unit];
	      if (value > 0)
		{
		  LOG ("skipping redundant unit clause %s", LOGLIT (unit));
		}
	      else if (value < 0)
		{
		  LOG ("found inconsistent unit clause %s", LOGLIT (unit));
		  solver->inconsistent = true;
		}
	      else
		{
		  LOG ("found unit clause %s", LOGLIT (unit));
		  assign (solver, unit, 0);
		  remove_original_clause = true;
		}
	    }
#ifndef NVIRTUAL
	  else if (size == 2)
	    {
	      add_new_binary_and_watch_it (solver, false);
#ifdef LOGGING
	      const unsigned lit = ACCESS (solver->clause, 0);
	      const unsigned other = ACCESS (solver->clause, 1);
	      LOGBIN (false, lit, other, "imported");
#endif
	    }
#endif
	  else
	    {
	      struct clause *clause = new_irredundant_clause (solver);
	      LOGCLS (clause, "imported");
#ifndef NWATCHES
	      watch_clause (solver, clause);
#else
	      connect_clause (solver, clause);
	      count_clause (solver, clause);
#endif
	    }

	  const size_t added = SIZE_STACK (solver->added);
	  assert (size <= added);

	  if (size < added)
	    {
	      trace_and_check_temporary_addition (solver);
	      remove_original_clause = true;
	    }
	  else
	    remove_original_clause = false;
	}
      else
	remove_original_clause = true;

      CLEAR_STACK (solver->clause);
      if (remove_original_clause)
	{
	  if (solver->proof)
	    {
	      start_deletion_proof_line (solver);
	      for (all_elements_on_stack (int, lit, solver->added))
		  add_external_literal_to_proof_line (solver, lit);
	      end_proof_line (solver);
	    }
#ifndef NDEBUG
	  for (all_elements_on_stack (int, lit, solver->added))
	      checker_add_literal (solver->checker, lit);
	  checker_delete_clause (solver->checker);
#endif
	}
      CLEAR_STACK (solver->added);
    }
}

/*========================================================================*/
//    Below are the non-static functions accessible through the API.      //
/*========================================================================*/

struct satch *
satch_init (void)
{
  return internal_init ();
}

void
satch_release (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  internal_release (solver);
}

/*------------------------------------------------------------------------*/

// Add a literal to an internal temporary clause or if the literal argument
// is zero then add a new irredundant / original clause to the solver which
// consists of all the previously literals added to the temporary clause.

void
satch_add (struct satch *solver, int elit)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_NON_INCREMENTAL ();
  REQUIRE_VALID_LITERAL (elit);
  internal_add (solver, elit);
}

/*------------------------------------------------------------------------*/

// Short hand for adding empty, unit, binary, ternary, or quaternay clauses.

void
satch_add_empty (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_NON_INCREMENTAL ();
  internal_add (solver, 0);
}

void
satch_add_unit (struct satch *solver, int unit)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_NON_INCREMENTAL ();
  REQUIRE_NON_ZERO_VALID_LITERAL (unit);
  internal_add (solver, unit);
  internal_add (solver, 0);
}

void
satch_add_binary_clause (struct satch *solver, int a, int b)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_NON_INCREMENTAL ();
  REQUIRE_NON_ZERO_VALID_LITERAL (a);
  REQUIRE_NON_ZERO_VALID_LITERAL (b);
  internal_add (solver, a);
  internal_add (solver, b);
  internal_add (solver, 0);
}

void
satch_add_ternary_clause (struct satch *solver, int a, int b, int c)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_NON_INCREMENTAL ();
  REQUIRE_NON_ZERO_VALID_LITERAL (a);
  REQUIRE_NON_ZERO_VALID_LITERAL (b);
  REQUIRE_NON_ZERO_VALID_LITERAL (c);
  internal_add (solver, a);
  internal_add (solver, b);
  internal_add (solver, c);
  internal_add (solver, 0);
}

void
satch_add_quaternary_clause (struct satch *solver, int a, int b, int c, int d)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_NON_INCREMENTAL ();
  REQUIRE_NON_ZERO_VALID_LITERAL (a);
  REQUIRE_NON_ZERO_VALID_LITERAL (b);
  REQUIRE_NON_ZERO_VALID_LITERAL (c);
  REQUIRE_NON_ZERO_VALID_LITERAL (d);
  internal_add (solver, a);
  internal_add (solver, b);
  internal_add (solver, c);
  internal_add (solver, d);
  internal_add (solver, 0);
}

/*------------------------------------------------------------------------*/

// Reserve at least 'max_var' variables that is the size of the solver. If
// the users knows this number then pre-allocating everything to that size
// avoids resizing the solver data.

void
satch_reserve (struct satch *solver, int max_var)
{
  REQUIRE_NON_ZERO_SOLVER ();
  assert (0 <= max_var);
  const size_t requested_capacity = max_var;
  if (requested_capacity > solver->capacity)
    increase_capacity (solver, requested_capacity);
}

int
satch_maximum_variable (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  assert (solver->size <= (unsigned) INT_MAX);
  return solver->size;
}

/*------------------------------------------------------------------------*/

// The IPASIR interface returns '-elit' if 'elit' is assigned 'false' and
// 'elit' if it is assigned to 'true'.  Otherwise it returns zero.  We do
// not want to use 'import_literal' here, since this forces to adapt the
// size (and capacity) of the solver to this literal even though it did not
// occur in a clause yet.  So we only import here implicitly.

int
satch_val (struct satch *solver, int elit)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE_NON_ZERO_VALID_LITERAL (elit);
  REQUIRE (solver->status == 10,
	   (solver->status == 20 ?
	    "expected status to be '10' and not '20'" :
	    !solver->status ?
	    "expected status to be '10' and not '0'" :
	    "expected status to be '10'"));
  int eidx = abs (elit);
  assert (eidx > 0);
  assert (eidx != INT_MIN);
  const unsigned iidx = eidx - 1;
  if (iidx >= solver->size)
    return eidx;		// By default assigned to 'true'.
  const unsigned ilit = LITERAL (iidx);
  signed char tmp = solver->values[ilit];
  if (!tmp)
    return eidx;		// By default assigned to 'true'.
  int res = (tmp > 0) ? elit : -elit;
  if (elit < 0)
    res = -res;
  assert (res == elit || res == -elit);
  return res;
}

int
satch_solve (struct satch *solver, int conflict_limit)
{
  REQUIRE_NON_ZERO_SOLVER ();
  REQUIRE (EMPTY_STACK (solver->clause),
	   "incomplete clause (zero literal missing)");
  REQUIRE (!solver->status, "no incremental solving yet");
  INC (solved);
  if (solver->options.verbose)
    internal_section (solver, "solving");
  int res = solve (solver, conflict_limit);
  LOG ("internal solving procedure returns '%d'", res);
  solver->status = res;
  if (res == 10)
    {
#ifndef NELIMINATION
      extend_solution (solver);
#endif
#ifndef NDEBUG
      check_witness (solver);
#endif
    }
  return res;
}

/*------------------------------------------------------------------------*/

void
satch_set_verbose_level (struct satch *solver, int new_verbose_level)
{
  REQUIRE_NON_ZERO_SOLVER ();
  if (new_verbose_level < 0)
    new_verbose_level = 0;
#ifndef NDEBUG
  if (new_verbose_level > 1)
    checker_verbose (solver->checker);
#endif
  solver->options.verbose = new_verbose_level;
}

void
satch_enable_logging_messages (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
#ifndef NDEBUG
  checker_logging (solver->checker);
  checker_verbose (solver->checker);
#endif
#ifdef LOGGING
  solver->options.logging = true;
#endif
  solver->options.verbose = INT_MAX;
}

void
satch_ascii_proof (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  solver->options.ascii = true;
}

void
satch_trace_proof (struct satch *solver, FILE * proof)
{
  REQUIRE_NON_ZERO_SOLVER ();
  solver->proof = proof;
}

/*------------------------------------------------------------------------*/

double
satch_process_time (void)
{
  return process_time ();
}

void
satch_start_profiling_parsing (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  START (parse);
}

double
satch_stop_profiling_parsing (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  return STOP (parse);
}

void
satch_section (struct satch *solver, const char *name)
{
  REQUIRE_NON_ZERO_SOLVER ();
  internal_section (solver, name);
}

void
satch_statistics (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  const double stop = print_profiles (solver);
  print_statistics (solver, stop);
  print_resource_usage (solver, stop);
}

int
satch_conflicts (struct satch *solver)
{
  REQUIRE_NON_ZERO_SOLVER ();
  const uint64_t conflicts = solver->statistics.conflicts;
  return (conflicts > (uint64_t) INT_MAX) ? INT_MAX : conflicts;
}
